{"argv": ["train.py", "--seed", "79", "--optimizer", "SGD", "--run_name", "sgd_0.001.json", "--output_path", "experiments/nonconvex_mnist_deep/sgd-0.001.json", "--dataset", "MNIST", "--layer_sizes", "784", "600", "300", "10", "--batch_size", "10", "--learning_rate", "0.001", "--weight_decay", "0.001", "--num_epochs", "300", "--device", "cuda"], "args": {"seed": 79, "optimizer": "SGD", "run_name": "sgd_0.001.json", "output_path": "experiments/nonconvex_mnist_deep/sgd-0.001.json", "device": "cuda", "dataset": "MNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": false, "layer_sizes": [784, 600, 300, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.001, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 1.9539591583410898, "grad_norm": 0.5608721375465393, "test_error": 0.231}, {"epoch": 2, "train_loss": 0.7665351577276985, "grad_norm": 0.2652234435081482, "test_error": 0.138}, {"epoch": 3, "train_loss": 0.4769637381186088, "grad_norm": 0.17998835444450378, "test_error": 0.1112}, {"epoch": 4, "train_loss": 0.3968980181217194, "grad_norm": 0.1893312931060791, "test_error": 0.1012}, {"epoch": 5, "train_loss": 0.35742907044446715, "grad_norm": 0.18220987915992737, "test_error": 0.093}, {"epoch": 6, "train_loss": 0.33188040663534774, "grad_norm": 0.18906742334365845, "test_error": 0.0884}, {"epoch": 7, "train_loss": 0.31251868717675096, "grad_norm": 0.12122685462236404, "test_error": 0.084}, {"epoch": 8, "train_loss": 0.296631292838448, "grad_norm": 0.1616068184375763, "test_error": 0.0802}, {"epoch": 9, "train_loss": 0.28286220883981633, "grad_norm": 0.21501466631889343, "test_error": 0.0763}, {"epoch": 10, "train_loss": 0.2706578847280083, "grad_norm": 0.1703776717185974, "test_error": 0.0716}, {"epoch": 11, "train_loss": 0.25951000570055716, "grad_norm": 0.1305100917816162, "test_error": 0.0703}, {"epoch": 12, "train_loss": 0.249289167416282, "grad_norm": 0.11604439467191696, "test_error": 0.0667}, {"epoch": 13, "train_loss": 0.23932776868754688, "grad_norm": 0.14276936650276184, "test_error": 0.064}, {"epoch": 14, "train_loss": 0.2303805597149767, "grad_norm": 0.11668404936790466, "test_error": 0.0628}, {"epoch": 15, "train_loss": 0.2217175260723258, "grad_norm": 0.24655205011367798, "test_error": 0.0619}, {"epoch": 16, "train_loss": 0.21382795550410325, "grad_norm": 0.11425961554050446, "test_error": 0.0581}, {"epoch": 17, "train_loss": 0.2062611233423231, "grad_norm": 0.12396236509084702, "test_error": 0.0561}, {"epoch": 18, "train_loss": 0.1991997128125901, "grad_norm": 0.14317958056926727, "test_error": 0.0559}, {"epoch": 19, "train_loss": 0.1924491683290495, "grad_norm": 0.11212482303380966, "test_error": 0.0542}, {"epoch": 20, "train_loss": 0.18618140322264906, "grad_norm": 0.20920902490615845, "test_error": 0.0528}, {"epoch": 21, "train_loss": 0.1803589510609939, "grad_norm": 0.1169765442609787, "test_error": 0.0514}, {"epoch": 22, "train_loss": 0.17481665056734347, "grad_norm": 0.08693752437829971, "test_error": 0.0506}, {"epoch": 23, "train_loss": 0.16932535652684358, "grad_norm": 0.11857195198535919, "test_error": 0.0484}, {"epoch": 24, "train_loss": 0.16424685575211576, "grad_norm": 0.09903866797685623, "test_error": 0.0476}, {"epoch": 25, "train_loss": 0.15948844930927347, "grad_norm": 0.08792253583669662, "test_error": 0.0458}, {"epoch": 26, "train_loss": 0.15495418583473655, "grad_norm": 0.11216970533132553, "test_error": 0.0451}, {"epoch": 27, "train_loss": 0.1506277896160415, "grad_norm": 0.08697943389415741, "test_error": 0.0443}, {"epoch": 28, "train_loss": 0.1467264289749631, "grad_norm": 0.1418335884809494, "test_error": 0.0429}, {"epoch": 29, "train_loss": 0.1427749609144327, "grad_norm": 0.07054318487644196, "test_error": 0.0415}, {"epoch": 30, "train_loss": 0.13907207558952117, "grad_norm": 0.10885351896286011, "test_error": 0.0413}, {"epoch": 31, "train_loss": 0.13557727154592672, "grad_norm": 0.08404724299907684, "test_error": 0.0394}, {"epoch": 32, "train_loss": 0.13212107641870777, "grad_norm": 0.1024901270866394, "test_error": 0.0398}, {"epoch": 33, "train_loss": 0.12895310613668212, "grad_norm": 0.1422465592622757, "test_error": 0.0388}, {"epoch": 34, "train_loss": 0.12585073754990783, "grad_norm": 0.12310796231031418, "test_error": 0.0376}, {"epoch": 35, "train_loss": 0.12290896896146782, "grad_norm": 0.08168190717697144, "test_error": 0.0371}, {"epoch": 36, "train_loss": 0.12022765654176086, "grad_norm": 0.0793103575706482, "test_error": 0.0364}, {"epoch": 37, "train_loss": 0.11754678513957575, "grad_norm": 0.109653539955616, "test_error": 0.0357}, {"epoch": 38, "train_loss": 0.11492743806161645, "grad_norm": 0.1424543708562851, "test_error": 0.0358}, {"epoch": 39, "train_loss": 0.11252574805587452, "grad_norm": 0.09442450851202011, "test_error": 0.0354}, {"epoch": 40, "train_loss": 0.11000437943241559, "grad_norm": 0.08153504133224487, "test_error": 0.0353}, {"epoch": 41, "train_loss": 0.1078693948861134, "grad_norm": 0.0830758810043335, "test_error": 0.0343}, {"epoch": 42, "train_loss": 0.10563720773955962, "grad_norm": 0.06187088042497635, "test_error": 0.0341}, {"epoch": 43, "train_loss": 0.10348939305817476, "grad_norm": 0.07547333091497421, "test_error": 0.0333}, {"epoch": 44, "train_loss": 0.10160423511134771, "grad_norm": 0.07815831899642944, "test_error": 0.0335}, {"epoch": 45, "train_loss": 0.0996529233919961, "grad_norm": 0.0689612329006195, "test_error": 0.0325}, {"epoch": 46, "train_loss": 0.09775651697581635, "grad_norm": 0.05487149953842163, "test_error": 0.033}, {"epoch": 47, "train_loss": 0.09607045018228624, "grad_norm": 0.08287573605775833, "test_error": 0.032}, {"epoch": 48, "train_loss": 0.09415688256102536, "grad_norm": 0.1360756754875183, "test_error": 0.0319}, {"epoch": 49, "train_loss": 0.09255542378146978, "grad_norm": 0.07689429819583893, "test_error": 0.0308}, {"epoch": 50, "train_loss": 0.09103248561581131, "grad_norm": 0.11860557645559311, "test_error": 0.0302}, {"epoch": 51, "train_loss": 0.08946042318174538, "grad_norm": 0.0656164363026619, "test_error": 0.0306}, {"epoch": 52, "train_loss": 0.0879036979987189, "grad_norm": 0.09689036756753922, "test_error": 0.03}, {"epoch": 53, "train_loss": 0.08641648669748489, "grad_norm": 0.12218039482831955, "test_error": 0.0299}, {"epoch": 54, "train_loss": 0.08507428105811898, "grad_norm": 0.10884298384189606, "test_error": 0.0285}, {"epoch": 55, "train_loss": 0.08372844248061301, "grad_norm": 0.07506360858678818, "test_error": 0.0292}, {"epoch": 56, "train_loss": 0.08241914730791662, "grad_norm": 0.09367690980434418, "test_error": 0.0287}, {"epoch": 57, "train_loss": 0.08120787060432486, "grad_norm": 0.0809161514043808, "test_error": 0.0283}, {"epoch": 58, "train_loss": 0.07989570851992661, "grad_norm": 0.08288207650184631, "test_error": 0.0278}, {"epoch": 59, "train_loss": 0.078673809828974, "grad_norm": 0.047185685485601425, "test_error": 0.0275}, {"epoch": 60, "train_loss": 0.07757506649853894, "grad_norm": 0.06390256434679031, "test_error": 0.028}, {"epoch": 61, "train_loss": 0.07644246287734131, "grad_norm": 0.07386985421180725, "test_error": 0.027}, {"epoch": 62, "train_loss": 0.07528158095859301, "grad_norm": 0.07112181186676025, "test_error": 0.0269}, {"epoch": 63, "train_loss": 0.07427174274512799, "grad_norm": 0.07953628152608871, "test_error": 0.0271}, {"epoch": 64, "train_loss": 0.07317735474385942, "grad_norm": 0.039569105952978134, "test_error": 0.0264}, {"epoch": 65, "train_loss": 0.07220514822390396, "grad_norm": 0.06984008103609085, "test_error": 0.0262}, {"epoch": 66, "train_loss": 0.07127337579369972, "grad_norm": 0.0620809905230999, "test_error": 0.0259}, {"epoch": 67, "train_loss": 0.07036716049172295, "grad_norm": 0.07133928686380386, "test_error": 0.0253}, {"epoch": 68, "train_loss": 0.0693599785665962, "grad_norm": 0.09415027499198914, "test_error": 0.0263}, {"epoch": 69, "train_loss": 0.06850046411933727, "grad_norm": 0.0648883804678917, "test_error": 0.0255}, {"epoch": 70, "train_loss": 0.06765935406995899, "grad_norm": 0.06951045244932175, "test_error": 0.0251}, {"epoch": 71, "train_loss": 0.06684475184839296, "grad_norm": 0.0873454362154007, "test_error": 0.0266}, {"epoch": 72, "train_loss": 0.06610707046761914, "grad_norm": 0.07317027449607849, "test_error": 0.0247}, {"epoch": 73, "train_loss": 0.06527452295015489, "grad_norm": 0.07024373859167099, "test_error": 0.0249}, {"epoch": 74, "train_loss": 0.06435914083905907, "grad_norm": 0.05271172150969505, "test_error": 0.0251}, {"epoch": 75, "train_loss": 0.06364880276238546, "grad_norm": 0.07883162051439285, "test_error": 0.0242}, {"epoch": 76, "train_loss": 0.06298703845661173, "grad_norm": 0.08824463188648224, "test_error": 0.0252}, {"epoch": 77, "train_loss": 0.06221155786158245, "grad_norm": 0.09644965082406998, "test_error": 0.0239}, {"epoch": 78, "train_loss": 0.06163495105518572, "grad_norm": 0.06031455472111702, "test_error": 0.0236}, {"epoch": 79, "train_loss": 0.060997166081549946, "grad_norm": 0.061269812285900116, "test_error": 0.024}, {"epoch": 80, "train_loss": 0.06029405102310314, "grad_norm": 0.08878655731678009, "test_error": 0.0241}, {"epoch": 81, "train_loss": 0.05968034853993837, "grad_norm": 0.07401064783334732, "test_error": 0.0239}, {"epoch": 82, "train_loss": 0.05900856919763222, "grad_norm": 0.08984823524951935, "test_error": 0.0229}, {"epoch": 83, "train_loss": 0.05842923920944061, "grad_norm": 0.06885560601949692, "test_error": 0.0228}, {"epoch": 84, "train_loss": 0.057863850748408975, "grad_norm": 0.0800725445151329, "test_error": 0.0245}, {"epoch": 85, "train_loss": 0.05728062571617193, "grad_norm": 0.04354540631175041, "test_error": 0.0238}, {"epoch": 86, "train_loss": 0.056708475475315934, "grad_norm": 0.06974136829376221, "test_error": 0.0233}, {"epoch": 87, "train_loss": 0.05618551221109616, "grad_norm": 0.04621021822094917, "test_error": 0.0235}, {"epoch": 88, "train_loss": 0.05566437781775797, "grad_norm": 0.0850546658039093, "test_error": 0.0235}, {"epoch": 89, "train_loss": 0.05519294488793821, "grad_norm": 0.06620502471923828, "test_error": 0.023}, {"epoch": 90, "train_loss": 0.05448256442711378, "grad_norm": 0.10956156998872757, "test_error": 0.0231}, {"epoch": 91, "train_loss": 0.054204099393614646, "grad_norm": 0.06538235396146774, "test_error": 0.0234}, {"epoch": 92, "train_loss": 0.05362384825796471, "grad_norm": 0.1204088106751442, "test_error": 0.0219}, {"epoch": 93, "train_loss": 0.053136750931104565, "grad_norm": 0.1039874330163002, "test_error": 0.0236}, {"epoch": 94, "train_loss": 0.05266248173219113, "grad_norm": 0.08539049327373505, "test_error": 0.0228}, {"epoch": 95, "train_loss": 0.052228989058009274, "grad_norm": 0.09063614159822464, "test_error": 0.023}, {"epoch": 96, "train_loss": 0.05174423017886875, "grad_norm": 0.03466130420565605, "test_error": 0.0226}, {"epoch": 97, "train_loss": 0.05130868463555817, "grad_norm": 0.04848739877343178, "test_error": 0.0227}, {"epoch": 98, "train_loss": 0.05087944573163986, "grad_norm": 0.07255802303552628, "test_error": 0.023}, {"epoch": 99, "train_loss": 0.050401251794110674, "grad_norm": 0.07540068030357361, "test_error": 0.023}, {"epoch": 100, "train_loss": 0.05004007586782003, "grad_norm": 0.06367114931344986, "test_error": 0.0221}, {"epoch": 101, "train_loss": 0.04971343291640611, "grad_norm": 0.0567675344645977, "test_error": 0.0216}, {"epoch": 102, "train_loss": 0.049307172046940344, "grad_norm": 0.056972574442625046, "test_error": 0.0222}, {"epoch": 103, "train_loss": 0.04884203411727989, "grad_norm": 0.11878872662782669, "test_error": 0.023}, {"epoch": 104, "train_loss": 0.04854811310673055, "grad_norm": 0.07409743219614029, "test_error": 0.0216}, {"epoch": 105, "train_loss": 0.04815794526270474, "grad_norm": 0.08948744088411331, "test_error": 0.022}, {"epoch": 106, "train_loss": 0.047775931500601776, "grad_norm": 0.0665808767080307, "test_error": 0.0217}, {"epoch": 107, "train_loss": 0.04743238997233372, "grad_norm": 0.05138213559985161, "test_error": 0.0213}, {"epoch": 108, "train_loss": 0.047048936055817954, "grad_norm": 0.05612548440694809, "test_error": 0.0218}, {"epoch": 109, "train_loss": 0.04671317033448334, "grad_norm": 0.054231662303209305, "test_error": 0.0223}, {"epoch": 110, "train_loss": 0.046444938679264546, "grad_norm": 0.032775215804576874, "test_error": 0.0213}, {"epoch": 111, "train_loss": 0.04602300470370877, "grad_norm": 0.08998291939496994, "test_error": 0.0213}, {"epoch": 112, "train_loss": 0.04575627646194577, "grad_norm": 0.06843841820955276, "test_error": 0.0216}, {"epoch": 113, "train_loss": 0.045410439583899766, "grad_norm": 0.0660448968410492, "test_error": 0.0209}, {"epoch": 114, "train_loss": 0.045233023977207874, "grad_norm": 0.04316151514649391, "test_error": 0.0205}, {"epoch": 115, "train_loss": 0.044882488872450874, "grad_norm": 0.05262548103928566, "test_error": 0.0215}, {"epoch": 116, "train_loss": 0.04466001384253226, "grad_norm": 0.0398748517036438, "test_error": 0.0212}, {"epoch": 117, "train_loss": 0.04432697029132396, "grad_norm": 0.08584198355674744, "test_error": 0.0214}, {"epoch": 118, "train_loss": 0.043922915962296735, "grad_norm": 0.10026693344116211, "test_error": 0.0219}, {"epoch": 119, "train_loss": 0.04382012955991862, "grad_norm": 0.06364846974611282, "test_error": 0.0212}, {"epoch": 120, "train_loss": 0.04354845637914453, "grad_norm": 0.04052786901593208, "test_error": 0.0213}, {"epoch": 121, "train_loss": 0.04324009662301493, "grad_norm": 0.05496162176132202, "test_error": 0.0207}, {"epoch": 122, "train_loss": 0.04294127870893377, "grad_norm": 0.09277136623859406, "test_error": 0.0209}, {"epoch": 123, "train_loss": 0.04271989889651983, "grad_norm": 0.06014866754412651, "test_error": 0.0206}, {"epoch": 124, "train_loss": 0.0424351936939153, "grad_norm": 0.11607292294502258, "test_error": 0.0215}, {"epoch": 125, "train_loss": 0.042217179299526224, "grad_norm": 0.08711342513561249, "test_error": 0.0204}, {"epoch": 126, "train_loss": 0.0420119406979987, "grad_norm": 0.04940585419535637, "test_error": 0.0207}, {"epoch": 127, "train_loss": 0.04173042234251625, "grad_norm": 0.08312706649303436, "test_error": 0.0209}, {"epoch": 128, "train_loss": 0.041466588807457204, "grad_norm": 0.06326575577259064, "test_error": 0.0203}, {"epoch": 129, "train_loss": 0.04127657466832898, "grad_norm": 0.0630144476890564, "test_error": 0.0202}, {"epoch": 130, "train_loss": 0.04106169332327166, "grad_norm": 0.09661614894866943, "test_error": 0.02}, {"epoch": 131, "train_loss": 0.04089203915108616, "grad_norm": 0.0507044717669487, "test_error": 0.0201}, {"epoch": 132, "train_loss": 0.04067124021069806, "grad_norm": 0.049519333988428116, "test_error": 0.0205}, {"epoch": 133, "train_loss": 0.04038588649649561, "grad_norm": 0.051014650613069534, "test_error": 0.0196}, {"epoch": 134, "train_loss": 0.040237689159238164, "grad_norm": 0.052906472235918045, "test_error": 0.0204}, {"epoch": 135, "train_loss": 0.03993325077192276, "grad_norm": 0.051992688328027725, "test_error": 0.0208}, {"epoch": 136, "train_loss": 0.03985492806005641, "grad_norm": 0.05420168116688728, "test_error": 0.0205}, {"epoch": 137, "train_loss": 0.03967152332353483, "grad_norm": 0.06118931621313095, "test_error": 0.0203}, {"epoch": 138, "train_loss": 0.039416256141126114, "grad_norm": 0.11692391335964203, "test_error": 0.0202}, {"epoch": 139, "train_loss": 0.03931164498546665, "grad_norm": 0.051177751272916794, "test_error": 0.0203}, {"epoch": 140, "train_loss": 0.039058449777493176, "grad_norm": 0.07230570912361145, "test_error": 0.0205}, {"epoch": 141, "train_loss": 0.038793034137988194, "grad_norm": 0.07118216156959534, "test_error": 0.0203}, {"epoch": 142, "train_loss": 0.03869609443139052, "grad_norm": 0.07070879638195038, "test_error": 0.0203}, {"epoch": 143, "train_loss": 0.03845363856265127, "grad_norm": 0.03734313324093819, "test_error": 0.0204}, {"epoch": 144, "train_loss": 0.03832825527762664, "grad_norm": 0.05669634789228439, "test_error": 0.0199}, {"epoch": 145, "train_loss": 0.0381522849049458, "grad_norm": 0.028674885630607605, "test_error": 0.0198}, {"epoch": 146, "train_loss": 0.03790238619060256, "grad_norm": 0.07616890221834183, "test_error": 0.0201}, {"epoch": 147, "train_loss": 0.037770918548194456, "grad_norm": 0.053186044096946716, "test_error": 0.0199}, {"epoch": 148, "train_loss": 0.037643145449745744, "grad_norm": 0.085958331823349, "test_error": 0.0195}, {"epoch": 149, "train_loss": 0.0375249631053545, "grad_norm": 0.04768085479736328, "test_error": 0.0198}, {"epoch": 150, "train_loss": 0.037266832735893936, "grad_norm": 0.06680826842784882, "test_error": 0.0197}, {"epoch": 151, "train_loss": 0.03720688400934159, "grad_norm": 0.05520598590373993, "test_error": 0.0196}, {"epoch": 152, "train_loss": 0.03699078492929887, "grad_norm": 0.09986570477485657, "test_error": 0.0202}, {"epoch": 153, "train_loss": 0.03686676386767067, "grad_norm": 0.046347878873348236, "test_error": 0.0197}, {"epoch": 154, "train_loss": 0.03673358963106875, "grad_norm": 0.06831079721450806, "test_error": 0.0199}, {"epoch": 155, "train_loss": 0.036606063393939015, "grad_norm": 0.06841984391212463, "test_error": 0.0197}, {"epoch": 156, "train_loss": 0.036505819858954056, "grad_norm": 0.0779377818107605, "test_error": 0.0204}, {"epoch": 157, "train_loss": 0.03632726640685238, "grad_norm": 0.05772152543067932, "test_error": 0.0197}, {"epoch": 158, "train_loss": 0.036240934968285725, "grad_norm": 0.04736970737576485, "test_error": 0.0193}, {"epoch": 159, "train_loss": 0.03602380022907649, "grad_norm": 0.057977575808763504, "test_error": 0.0196}, {"epoch": 160, "train_loss": 0.03594328520474664, "grad_norm": 0.07611141353845596, "test_error": 0.0198}, {"epoch": 161, "train_loss": 0.03577647205795802, "grad_norm": 0.058614183217287064, "test_error": 0.0195}, {"epoch": 162, "train_loss": 0.03567030325007121, "grad_norm": 0.041113391518592834, "test_error": 0.0193}, {"epoch": 163, "train_loss": 0.03558016866982992, "grad_norm": 0.128123477101326, "test_error": 0.0197}, {"epoch": 164, "train_loss": 0.035476112517610695, "grad_norm": 0.04404904693365097, "test_error": 0.0193}, {"epoch": 165, "train_loss": 0.035282707880682815, "grad_norm": 0.06215665861964226, "test_error": 0.0196}, {"epoch": 166, "train_loss": 0.03517980636982732, "grad_norm": 0.0489116869866848, "test_error": 0.0202}, {"epoch": 167, "train_loss": 0.03503748526836959, "grad_norm": 0.06706560403108597, "test_error": 0.0195}, {"epoch": 168, "train_loss": 0.03491280943672852, "grad_norm": 0.06817993521690369, "test_error": 0.0188}, {"epoch": 169, "train_loss": 0.03488453948339641, "grad_norm": 0.051904335618019104, "test_error": 0.0196}, {"epoch": 170, "train_loss": 0.03465971425461854, "grad_norm": 0.05594591051340103, "test_error": 0.0191}, {"epoch": 171, "train_loss": 0.03468737359548686, "grad_norm": 0.07677808403968811, "test_error": 0.0187}, {"epoch": 172, "train_loss": 0.03442365533604849, "grad_norm": 0.07454143464565277, "test_error": 0.0186}, {"epoch": 173, "train_loss": 0.034456341680755335, "grad_norm": 0.04994821175932884, "test_error": 0.0187}, {"epoch": 174, "train_loss": 0.03424088691391323, "grad_norm": 0.04446851462125778, "test_error": 0.0197}, {"epoch": 175, "train_loss": 0.034172738388709455, "grad_norm": 0.08584336936473846, "test_error": 0.0193}, {"epoch": 176, "train_loss": 0.03414727625001494, "grad_norm": 0.07642285525798798, "test_error": 0.0189}, {"epoch": 177, "train_loss": 0.0340109845935076, "grad_norm": 0.04307029768824577, "test_error": 0.0194}, {"epoch": 178, "train_loss": 0.033902413811170845, "grad_norm": 0.05478407442569733, "test_error": 0.0189}, {"epoch": 179, "train_loss": 0.03376660081968293, "grad_norm": 0.0575827956199646, "test_error": 0.0187}, {"epoch": 180, "train_loss": 0.03367569055374285, "grad_norm": 0.049261707812547684, "test_error": 0.0195}, {"epoch": 181, "train_loss": 0.033581685263872105, "grad_norm": 0.09747613221406937, "test_error": 0.0193}, {"epoch": 182, "train_loss": 0.0335029010043072, "grad_norm": 0.0329253226518631, "test_error": 0.0185}, {"epoch": 183, "train_loss": 0.033457135924511626, "grad_norm": 0.04876425489783287, "test_error": 0.0188}, {"epoch": 184, "train_loss": 0.03333857033305685, "grad_norm": 0.02936752885580063, "test_error": 0.0189}, {"epoch": 185, "train_loss": 0.03328678080552588, "grad_norm": 0.0845036655664444, "test_error": 0.0185}, {"epoch": 186, "train_loss": 0.033167618638001536, "grad_norm": 0.07027261704206467, "test_error": 0.0189}, {"epoch": 187, "train_loss": 0.03306625374642802, "grad_norm": 0.08922693133354187, "test_error": 0.0199}, {"epoch": 188, "train_loss": 0.0330110006716471, "grad_norm": 0.030467800796031952, "test_error": 0.0189}, {"epoch": 189, "train_loss": 0.03290295102782936, "grad_norm": 0.028504956513643265, "test_error": 0.0193}, {"epoch": 190, "train_loss": 0.03273539833107983, "grad_norm": 0.03662032261490822, "test_error": 0.0186}, {"epoch": 191, "train_loss": 0.03270083040501049, "grad_norm": 0.05684109404683113, "test_error": 0.0188}, {"epoch": 192, "train_loss": 0.032670278241552296, "grad_norm": 0.06466986984014511, "test_error": 0.019}, {"epoch": 193, "train_loss": 0.032565394122585224, "grad_norm": 0.0388888418674469, "test_error": 0.0191}, {"epoch": 194, "train_loss": 0.03246505775279608, "grad_norm": 0.061983004212379456, "test_error": 0.0185}, {"epoch": 195, "train_loss": 0.032388384142158125, "grad_norm": 0.046555761247873306, "test_error": 0.0181}, {"epoch": 196, "train_loss": 0.032311188852851044, "grad_norm": 0.041691411286592484, "test_error": 0.0182}, {"epoch": 197, "train_loss": 0.03226097714957238, "grad_norm": 0.04886208102107048, "test_error": 0.0186}, {"epoch": 198, "train_loss": 0.032194553125741855, "grad_norm": 0.04748636111617088, "test_error": 0.0188}, {"epoch": 199, "train_loss": 0.03214352083500126, "grad_norm": 0.03833908960223198, "test_error": 0.0184}, {"epoch": 200, "train_loss": 0.03207979776690869, "grad_norm": 0.0662807822227478, "test_error": 0.0187}, {"epoch": 201, "train_loss": 0.03199429383335033, "grad_norm": 0.03249523788690567, "test_error": 0.0182}, {"epoch": 202, "train_loss": 0.03186714606221843, "grad_norm": 0.05439051240682602, "test_error": 0.0185}, {"epoch": 203, "train_loss": 0.03176952370235328, "grad_norm": 0.08523411303758621, "test_error": 0.0187}, {"epoch": 204, "train_loss": 0.031751662684900414, "grad_norm": 0.09796588122844696, "test_error": 0.0183}, {"epoch": 205, "train_loss": 0.03175124991603661, "grad_norm": 0.04690868780016899, "test_error": 0.018}, {"epoch": 206, "train_loss": 0.03164643023681613, "grad_norm": 0.05648867413401604, "test_error": 0.0183}, {"epoch": 207, "train_loss": 0.03157361719776721, "grad_norm": 0.0468728207051754, "test_error": 0.0187}, {"epoch": 208, "train_loss": 0.031470420899160675, "grad_norm": 0.05708783119916916, "test_error": 0.0184}, {"epoch": 209, "train_loss": 0.031500521599150184, "grad_norm": 0.03469441831111908, "test_error": 0.0188}, {"epoch": 210, "train_loss": 0.031365379631873413, "grad_norm": 0.05456716567277908, "test_error": 0.0185}, {"epoch": 211, "train_loss": 0.03132135308772073, "grad_norm": 0.07472430169582367, "test_error": 0.019}, {"epoch": 212, "train_loss": 0.031283204535842137, "grad_norm": 0.04362024366855621, "test_error": 0.0184}, {"epoch": 213, "train_loss": 0.031239624191672193, "grad_norm": 0.05663856863975525, "test_error": 0.0183}, {"epoch": 214, "train_loss": 0.031169349514816227, "grad_norm": 0.05628884583711624, "test_error": 0.0184}, {"epoch": 215, "train_loss": 0.03110300300565238, "grad_norm": 0.028080452233552933, "test_error": 0.0179}, {"epoch": 216, "train_loss": 0.031054877601466916, "grad_norm": 0.06260482221841812, "test_error": 0.0178}, {"epoch": 217, "train_loss": 0.030921077389328276, "grad_norm": 0.056330401450395584, "test_error": 0.0186}, {"epoch": 218, "train_loss": 0.030936081605177607, "grad_norm": 0.04167887195944786, "test_error": 0.0185}, {"epoch": 219, "train_loss": 0.030823330871431003, "grad_norm": 0.05358165130019188, "test_error": 0.0181}, {"epoch": 220, "train_loss": 0.030831163084561315, "grad_norm": 0.038083069026470184, "test_error": 0.0181}, {"epoch": 221, "train_loss": 0.03076741050836184, "grad_norm": 0.06922340393066406, "test_error": 0.0181}, {"epoch": 222, "train_loss": 0.030704555714546587, "grad_norm": 0.042726729065179825, "test_error": 0.0182}, {"epoch": 223, "train_loss": 0.030671637755202635, "grad_norm": 0.028755556792020798, "test_error": 0.0185}, {"epoch": 224, "train_loss": 0.030626805901440093, "grad_norm": 0.027636991813778877, "test_error": 0.0188}, {"epoch": 225, "train_loss": 0.030496756434004055, "grad_norm": 0.0587337501347065, "test_error": 0.0177}, {"epoch": 226, "train_loss": 0.03050551825543516, "grad_norm": 0.05870326608419418, "test_error": 0.0182}, {"epoch": 227, "train_loss": 0.030455111324743486, "grad_norm": 0.03691818565130234, "test_error": 0.0176}, {"epoch": 228, "train_loss": 0.030421645199569563, "grad_norm": 0.07107792794704437, "test_error": 0.0181}, {"epoch": 229, "train_loss": 0.030364258667614195, "grad_norm": 0.0450567863881588, "test_error": 0.0175}, {"epoch": 230, "train_loss": 0.03032964204921154, "grad_norm": 0.04195158928632736, "test_error": 0.0184}, {"epoch": 231, "train_loss": 0.030228135920192776, "grad_norm": 0.051886674016714096, "test_error": 0.0179}, {"epoch": 232, "train_loss": 0.030227040624993, "grad_norm": 0.039560846984386444, "test_error": 0.0179}, {"epoch": 233, "train_loss": 0.030167443565655656, "grad_norm": 0.04721987619996071, "test_error": 0.0182}, {"epoch": 234, "train_loss": 0.03011479009690811, "grad_norm": 0.055057935416698456, "test_error": 0.0184}, {"epoch": 235, "train_loss": 0.030047865330765488, "grad_norm": 0.04489199444651604, "test_error": 0.0176}, {"epoch": 236, "train_loss": 0.03004204976777449, "grad_norm": 0.040192924439907074, "test_error": 0.0182}, {"epoch": 237, "train_loss": 0.030000458530853695, "grad_norm": 0.05538126453757286, "test_error": 0.0182}, {"epoch": 238, "train_loss": 0.02991228195251703, "grad_norm": 0.05406443402171135, "test_error": 0.018}, {"epoch": 239, "train_loss": 0.029859077647842545, "grad_norm": 0.04385460168123245, "test_error": 0.0182}, {"epoch": 240, "train_loss": 0.029852760504800246, "grad_norm": 0.059997305274009705, "test_error": 0.0187}, {"epoch": 241, "train_loss": 0.029804943711414428, "grad_norm": 0.04389365389943123, "test_error": 0.0179}, {"epoch": 242, "train_loss": 0.029785427742962688, "grad_norm": 0.06205151230096817, "test_error": 0.0173}, {"epoch": 243, "train_loss": 0.029718206342227254, "grad_norm": 0.047105297446250916, "test_error": 0.0182}, {"epoch": 244, "train_loss": 0.029720848020951963, "grad_norm": 0.06544017791748047, "test_error": 0.0181}, {"epoch": 245, "train_loss": 0.029685604365576487, "grad_norm": 0.041005007922649384, "test_error": 0.0178}, {"epoch": 246, "train_loss": 0.02963424225395526, "grad_norm": 0.06096925958991051, "test_error": 0.0178}, {"epoch": 247, "train_loss": 0.02956337664066814, "grad_norm": 0.03957748785614967, "test_error": 0.018}, {"epoch": 248, "train_loss": 0.029499101139309158, "grad_norm": 0.029394064098596573, "test_error": 0.0181}, {"epoch": 249, "train_loss": 0.029477301508469583, "grad_norm": 0.039761267602443695, "test_error": 0.0182}, {"epoch": 250, "train_loss": 0.02945192485410856, "grad_norm": 0.04855883866548538, "test_error": 0.018}, {"epoch": 251, "train_loss": 0.02938659311885567, "grad_norm": 0.035290319472551346, "test_error": 0.0175}, {"epoch": 252, "train_loss": 0.029325273229502877, "grad_norm": 0.059330157935619354, "test_error": 0.0178}, {"epoch": 253, "train_loss": 0.029298413633230665, "grad_norm": 0.08357065916061401, "test_error": 0.0183}, {"epoch": 254, "train_loss": 0.029280615629875682, "grad_norm": 0.0456673763692379, "test_error": 0.0182}, {"epoch": 255, "train_loss": 0.02926124873259202, "grad_norm": 0.06061868742108345, "test_error": 0.0181}, {"epoch": 256, "train_loss": 0.02927607881463094, "grad_norm": 0.03799865022301674, "test_error": 0.0179}, {"epoch": 257, "train_loss": 0.029197243928705575, "grad_norm": 0.05298474431037903, "test_error": 0.018}, {"epoch": 258, "train_loss": 0.029149775203836423, "grad_norm": 0.05717601627111435, "test_error": 0.0179}, {"epoch": 259, "train_loss": 0.029147127181417695, "grad_norm": 0.025444721803069115, "test_error": 0.0175}, {"epoch": 260, "train_loss": 0.02908561498565056, "grad_norm": 0.05174487456679344, "test_error": 0.0176}, {"epoch": 261, "train_loss": 0.029033735103022384, "grad_norm": 0.1170758605003357, "test_error": 0.0182}, {"epoch": 262, "train_loss": 0.0290734736757319, "grad_norm": 0.025266384705901146, "test_error": 0.018}, {"epoch": 263, "train_loss": 0.028916792352470414, "grad_norm": 0.06583196669816971, "test_error": 0.0184}, {"epoch": 264, "train_loss": 0.028942084460446493, "grad_norm": 0.05873056501150131, "test_error": 0.0179}, {"epoch": 265, "train_loss": 0.028921324028192127, "grad_norm": 0.051222775131464005, "test_error": 0.0181}, {"epoch": 266, "train_loss": 0.02891504942198905, "grad_norm": 0.03851909562945366, "test_error": 0.0175}, {"epoch": 267, "train_loss": 0.028886263384726288, "grad_norm": 0.06239849328994751, "test_error": 0.0174}, {"epoch": 268, "train_loss": 0.02883668321889612, "grad_norm": 0.051885660737752914, "test_error": 0.0179}, {"epoch": 269, "train_loss": 0.028778358281197142, "grad_norm": 0.06520120054483414, "test_error": 0.0176}, {"epoch": 270, "train_loss": 0.02882109872055298, "grad_norm": 0.08466152846813202, "test_error": 0.0181}, {"epoch": 271, "train_loss": 0.028711143271776866, "grad_norm": 0.033785268664360046, "test_error": 0.0173}, {"epoch": 272, "train_loss": 0.028676949931837347, "grad_norm": 0.04268694669008255, "test_error": 0.0179}, {"epoch": 273, "train_loss": 0.02865398293279577, "grad_norm": 0.03883949667215347, "test_error": 0.0171}, {"epoch": 274, "train_loss": 0.028663463411464668, "grad_norm": 0.03975749388337135, "test_error": 0.0171}, {"epoch": 275, "train_loss": 0.028627867141824633, "grad_norm": 0.057202424854040146, "test_error": 0.0175}, {"epoch": 276, "train_loss": 0.028554016511053004, "grad_norm": 0.0699620395898819, "test_error": 0.0172}, {"epoch": 277, "train_loss": 0.028569956299164916, "grad_norm": 0.04633665829896927, "test_error": 0.0174}, {"epoch": 278, "train_loss": 0.028532910346169955, "grad_norm": 0.056282419711351395, "test_error": 0.0172}, {"epoch": 279, "train_loss": 0.02850616944914994, "grad_norm": 0.04458104074001312, "test_error": 0.0174}, {"epoch": 280, "train_loss": 0.028495872814120957, "grad_norm": 0.041062869131565094, "test_error": 0.0176}, {"epoch": 281, "train_loss": 0.0284563275371814, "grad_norm": 0.07120198756456375, "test_error": 0.0177}, {"epoch": 282, "train_loss": 0.028436214604773948, "grad_norm": 0.041940558701753616, "test_error": 0.0175}, {"epoch": 283, "train_loss": 0.02839357813244957, "grad_norm": 0.04554200544953346, "test_error": 0.018}, {"epoch": 284, "train_loss": 0.0283755647004679, "grad_norm": 0.02431449480354786, "test_error": 0.0172}, {"epoch": 285, "train_loss": 0.02834630508516178, "grad_norm": 0.04276510328054428, "test_error": 0.0173}, {"epoch": 286, "train_loss": 0.028294971247257005, "grad_norm": 0.05136207491159439, "test_error": 0.0174}, {"epoch": 287, "train_loss": 0.028313677742912356, "grad_norm": 0.04842493310570717, "test_error": 0.0173}, {"epoch": 288, "train_loss": 0.028283571435191942, "grad_norm": 0.054303597658872604, "test_error": 0.0174}, {"epoch": 289, "train_loss": 0.02827315357106272, "grad_norm": 0.04846309497952461, "test_error": 0.0179}, {"epoch": 290, "train_loss": 0.02813135892393378, "grad_norm": 0.04240357503294945, "test_error": 0.0174}, {"epoch": 291, "train_loss": 0.028211496730829823, "grad_norm": 0.04981410503387451, "test_error": 0.0178}, {"epoch": 292, "train_loss": 0.028199935960719208, "grad_norm": 0.07183640450239182, "test_error": 0.0175}, {"epoch": 293, "train_loss": 0.02812742762179308, "grad_norm": 0.058721575886011124, "test_error": 0.0183}, {"epoch": 294, "train_loss": 0.028131653485494703, "grad_norm": 0.03290886431932449, "test_error": 0.0172}, {"epoch": 295, "train_loss": 0.028134726088503762, "grad_norm": 0.06204817816615105, "test_error": 0.0175}, {"epoch": 296, "train_loss": 0.028099101686743476, "grad_norm": 0.06990811973810196, "test_error": 0.0173}, {"epoch": 297, "train_loss": 0.02803196231354862, "grad_norm": 0.026871293783187866, "test_error": 0.017}, {"epoch": 298, "train_loss": 0.028000194460556183, "grad_norm": 0.036318339407444, "test_error": 0.0173}, {"epoch": 299, "train_loss": 0.027962841784227446, "grad_norm": 0.043403323739767075, "test_error": 0.0174}, {"epoch": 300, "train_loss": 0.02796899937755855, "grad_norm": 0.04067858308553696, "test_error": 0.0171}]}