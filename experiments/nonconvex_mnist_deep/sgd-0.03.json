{"argv": ["train.py", "--seed", "12", "--optimizer", "SGD", "--run_name", "sgd_0.03.json", "--output_path", "experiments/nonconvex_mnist_deep/sgd-0.03.json", "--dataset", "MNIST", "--layer_sizes", "784", "600", "300", "10", "--batch_size", "10", "--learning_rate", "0.03", "--weight_decay", "0.001", "--num_epochs", "300", "--device", "cuda"], "args": {"seed": 12, "optimizer": "SGD", "run_name": "sgd_0.03.json", "output_path": "experiments/nonconvex_mnist_deep/sgd-0.03.json", "device": "cuda", "dataset": "MNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": false, "layer_sizes": [784, 600, 300, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.03, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 0.34933313525281845, "grad_norm": 0.3432244658470154, "test_error": 0.0466}, {"epoch": 2, "train_loss": 0.1321047033231977, "grad_norm": 0.258813738822937, "test_error": 0.0332}, {"epoch": 3, "train_loss": 0.09469141794395303, "grad_norm": 0.21175572276115417, "test_error": 0.0277}, {"epoch": 4, "train_loss": 0.0777445229772323, "grad_norm": 0.1365376114845276, "test_error": 0.0242}, {"epoch": 5, "train_loss": 0.06685238561601728, "grad_norm": 0.12373974174261093, "test_error": 0.0226}, {"epoch": 6, "train_loss": 0.06082784320200153, "grad_norm": 0.19236202538013458, "test_error": 0.0245}, {"epoch": 7, "train_loss": 0.05603111801612734, "grad_norm": 0.14616869390010834, "test_error": 0.0224}, {"epoch": 8, "train_loss": 0.05238489796930905, "grad_norm": 0.1438467651605606, "test_error": 0.0215}, {"epoch": 9, "train_loss": 0.05093708770238057, "grad_norm": 0.09659966826438904, "test_error": 0.019}, {"epoch": 10, "train_loss": 0.04814839639693431, "grad_norm": 0.3992414176464081, "test_error": 0.0247}, {"epoch": 11, "train_loss": 0.047845051425809894, "grad_norm": 0.1431088000535965, "test_error": 0.02}, {"epoch": 12, "train_loss": 0.04475920880845418, "grad_norm": 0.21881593763828278, "test_error": 0.0204}, {"epoch": 13, "train_loss": 0.044313905209399915, "grad_norm": 0.17397010326385498, "test_error": 0.0211}, {"epoch": 14, "train_loss": 0.043324908531232116, "grad_norm": 0.15421129763126373, "test_error": 0.0203}, {"epoch": 15, "train_loss": 0.0433240661231927, "grad_norm": 0.10605482012033463, "test_error": 0.0192}, {"epoch": 16, "train_loss": 0.04230638903609361, "grad_norm": 0.13847927749156952, "test_error": 0.021}, {"epoch": 17, "train_loss": 0.041819759083829317, "grad_norm": 0.20954245328903198, "test_error": 0.022}, {"epoch": 18, "train_loss": 0.0417974227390708, "grad_norm": 0.07483366876840591, "test_error": 0.0175}, {"epoch": 19, "train_loss": 0.04049543067685833, "grad_norm": 0.09598733484745026, "test_error": 0.0203}, {"epoch": 20, "train_loss": 0.04048632840068846, "grad_norm": 0.16941814124584198, "test_error": 0.0217}, {"epoch": 21, "train_loss": 0.04081971334734893, "grad_norm": 0.26467981934547424, "test_error": 0.0204}, {"epoch": 22, "train_loss": 0.03946734097614535, "grad_norm": 0.12273100018501282, "test_error": 0.0185}, {"epoch": 23, "train_loss": 0.03989742149135175, "grad_norm": 0.11008231341838837, "test_error": 0.0198}, {"epoch": 24, "train_loss": 0.03901465202409114, "grad_norm": 0.21827612817287445, "test_error": 0.0197}, {"epoch": 25, "train_loss": 0.03952692894241287, "grad_norm": 0.09738465398550034, "test_error": 0.0183}, {"epoch": 26, "train_loss": 0.03924512924239874, "grad_norm": 0.16707128286361694, "test_error": 0.0195}, {"epoch": 27, "train_loss": 0.03823301565910515, "grad_norm": 0.13341017067432404, "test_error": 0.02}, {"epoch": 28, "train_loss": 0.038056421721921654, "grad_norm": 0.10616662353277206, "test_error": 0.0169}, {"epoch": 29, "train_loss": 0.03805963999388526, "grad_norm": 0.11484788358211517, "test_error": 0.0197}, {"epoch": 30, "train_loss": 0.03799659650932154, "grad_norm": 0.1531670093536377, "test_error": 0.0179}, {"epoch": 31, "train_loss": 0.038515691623935706, "grad_norm": 0.11168010532855988, "test_error": 0.0207}, {"epoch": 32, "train_loss": 0.03807644194865376, "grad_norm": 0.14604255557060242, "test_error": 0.0193}, {"epoch": 33, "train_loss": 0.037764498371133715, "grad_norm": 0.14245763421058655, "test_error": 0.0177}, {"epoch": 34, "train_loss": 0.03812866428186438, "grad_norm": 0.12218612432479858, "test_error": 0.0197}, {"epoch": 35, "train_loss": 0.03773765061112742, "grad_norm": 0.11552947014570236, "test_error": 0.0177}, {"epoch": 36, "train_loss": 0.03735401279053622, "grad_norm": 0.19449515640735626, "test_error": 0.02}, {"epoch": 37, "train_loss": 0.03749007861294376, "grad_norm": 0.13230398297309875, "test_error": 0.0186}, {"epoch": 38, "train_loss": 0.03694989860059286, "grad_norm": 0.25433585047721863, "test_error": 0.0227}, {"epoch": 39, "train_loss": 0.03641037534806431, "grad_norm": 0.12298624962568283, "test_error": 0.0194}, {"epoch": 40, "train_loss": 0.037688244884406835, "grad_norm": 0.11785165965557098, "test_error": 0.0175}, {"epoch": 41, "train_loss": 0.03691340175144433, "grad_norm": 0.223352313041687, "test_error": 0.0235}, {"epoch": 42, "train_loss": 0.03606064269239141, "grad_norm": 0.13701480627059937, "test_error": 0.0185}, {"epoch": 43, "train_loss": 0.03744939305497488, "grad_norm": 0.08285870403051376, "test_error": 0.0159}, {"epoch": 44, "train_loss": 0.0367499067356257, "grad_norm": 0.18994519114494324, "test_error": 0.0188}, {"epoch": 45, "train_loss": 0.0366505468840963, "grad_norm": 0.24586598575115204, "test_error": 0.0226}, {"epoch": 46, "train_loss": 0.03680141560928314, "grad_norm": 0.2602323889732361, "test_error": 0.0213}, {"epoch": 47, "train_loss": 0.036279435131732804, "grad_norm": 0.10419129580259323, "test_error": 0.0181}, {"epoch": 48, "train_loss": 0.036250524723000124, "grad_norm": 0.16390644013881683, "test_error": 0.0189}, {"epoch": 49, "train_loss": 0.03736199139971723, "grad_norm": 0.1724282205104828, "test_error": 0.019}, {"epoch": 50, "train_loss": 0.03635781494041536, "grad_norm": 0.14423753321170807, "test_error": 0.0205}, {"epoch": 51, "train_loss": 0.03595472330341969, "grad_norm": 0.16077059507369995, "test_error": 0.0217}, {"epoch": 52, "train_loss": 0.03625362700858629, "grad_norm": 0.16879697144031525, "test_error": 0.0205}, {"epoch": 53, "train_loss": 0.036318334462489776, "grad_norm": 0.09321360290050507, "test_error": 0.0179}, {"epoch": 54, "train_loss": 0.03583932096947683, "grad_norm": 0.09701083600521088, "test_error": 0.0192}, {"epoch": 55, "train_loss": 0.03547319926478667, "grad_norm": 0.10945667326450348, "test_error": 0.0182}, {"epoch": 56, "train_loss": 0.03616168439445028, "grad_norm": 0.21495071053504944, "test_error": 0.0215}, {"epoch": 57, "train_loss": 0.03525743742605118, "grad_norm": 0.16343532502651215, "test_error": 0.0182}, {"epoch": 58, "train_loss": 0.03573705921052412, "grad_norm": 0.09024515748023987, "test_error": 0.0167}, {"epoch": 59, "train_loss": 0.03628641470258056, "grad_norm": 0.14671094715595245, "test_error": 0.02}, {"epoch": 60, "train_loss": 0.03657153698256298, "grad_norm": 0.12177978456020355, "test_error": 0.0179}, {"epoch": 61, "train_loss": 0.03597179778447268, "grad_norm": 0.09775494784116745, "test_error": 0.0176}, {"epoch": 62, "train_loss": 0.03541960934363791, "grad_norm": 0.1304321587085724, "test_error": 0.0182}, {"epoch": 63, "train_loss": 0.035338685056315926, "grad_norm": 0.11659862846136093, "test_error": 0.0177}, {"epoch": 64, "train_loss": 0.03565299389331995, "grad_norm": 0.11817628890275955, "test_error": 0.0176}, {"epoch": 65, "train_loss": 0.035538603031178354, "grad_norm": 0.1289358139038086, "test_error": 0.0184}, {"epoch": 66, "train_loss": 0.035518040489888034, "grad_norm": 0.0873957946896553, "test_error": 0.0173}, {"epoch": 67, "train_loss": 0.035442969255542266, "grad_norm": 0.1584649533033371, "test_error": 0.0197}, {"epoch": 68, "train_loss": 0.03592799102486363, "grad_norm": 0.10515964031219482, "test_error": 0.0176}, {"epoch": 69, "train_loss": 0.03590100468363865, "grad_norm": 0.15271735191345215, "test_error": 0.017}, {"epoch": 70, "train_loss": 0.03571949799101276, "grad_norm": 0.13346965610980988, "test_error": 0.0189}, {"epoch": 71, "train_loss": 0.03513564340028097, "grad_norm": 0.23041559755802155, "test_error": 0.0224}, {"epoch": 72, "train_loss": 0.03609193368416648, "grad_norm": 0.18734215199947357, "test_error": 0.0192}, {"epoch": 73, "train_loss": 0.03541323896853767, "grad_norm": 0.10278523713350296, "test_error": 0.0175}, {"epoch": 74, "train_loss": 0.03535966480790861, "grad_norm": 0.11815327405929565, "test_error": 0.0184}, {"epoch": 75, "train_loss": 0.03504417861429344, "grad_norm": 0.13386353850364685, "test_error": 0.0197}, {"epoch": 76, "train_loss": 0.0347308437894535, "grad_norm": 0.18710945546627045, "test_error": 0.0186}, {"epoch": 77, "train_loss": 0.03533356678051253, "grad_norm": 0.10469655692577362, "test_error": 0.0196}, {"epoch": 78, "train_loss": 0.03604341615099353, "grad_norm": 0.12029935419559479, "test_error": 0.0181}, {"epoch": 79, "train_loss": 0.03524383096896054, "grad_norm": 0.07240752875804901, "test_error": 0.0161}, {"epoch": 80, "train_loss": 0.03488334482890301, "grad_norm": 0.059603944420814514, "test_error": 0.0177}, {"epoch": 81, "train_loss": 0.03528815605863929, "grad_norm": 0.10672976076602936, "test_error": 0.0187}, {"epoch": 82, "train_loss": 0.03467603942041751, "grad_norm": 0.11498268693685532, "test_error": 0.0187}, {"epoch": 83, "train_loss": 0.03499929911827591, "grad_norm": 0.08385734260082245, "test_error": 0.018}, {"epoch": 84, "train_loss": 0.03431581890315768, "grad_norm": 0.16998615860939026, "test_error": 0.0191}, {"epoch": 85, "train_loss": 0.035426152705691494, "grad_norm": 0.18927007913589478, "test_error": 0.0195}, {"epoch": 86, "train_loss": 0.03515053746839112, "grad_norm": 0.18456286191940308, "test_error": 0.0184}, {"epoch": 87, "train_loss": 0.03446074611928877, "grad_norm": 0.16882799565792084, "test_error": 0.017}, {"epoch": 88, "train_loss": 0.034601079314311695, "grad_norm": 0.1435711830854416, "test_error": 0.0189}, {"epoch": 89, "train_loss": 0.03538712115876842, "grad_norm": 0.23147079348564148, "test_error": 0.0186}, {"epoch": 90, "train_loss": 0.034784497273707526, "grad_norm": 0.13878773152828217, "test_error": 0.0205}, {"epoch": 91, "train_loss": 0.03463165200838315, "grad_norm": 0.36913129687309265, "test_error": 0.0241}, {"epoch": 92, "train_loss": 0.03458584683696487, "grad_norm": 0.1723354011774063, "test_error": 0.0184}, {"epoch": 93, "train_loss": 0.03494453743363071, "grad_norm": 0.14718128740787506, "test_error": 0.0205}, {"epoch": 94, "train_loss": 0.03488620688118681, "grad_norm": 0.08091280609369278, "test_error": 0.0181}, {"epoch": 95, "train_loss": 0.034771270052854866, "grad_norm": 0.18499566614627838, "test_error": 0.0176}, {"epoch": 96, "train_loss": 0.03514572156018403, "grad_norm": 0.13937035202980042, "test_error": 0.0178}, {"epoch": 97, "train_loss": 0.03488136239302791, "grad_norm": 0.10904254764318466, "test_error": 0.0192}, {"epoch": 98, "train_loss": 0.03498688878502192, "grad_norm": 0.18690332770347595, "test_error": 0.0196}, {"epoch": 99, "train_loss": 0.03425036170635334, "grad_norm": 0.16071778535842896, "test_error": 0.0193}, {"epoch": 100, "train_loss": 0.03442612852129969, "grad_norm": 0.10232396423816681, "test_error": 0.0181}, {"epoch": 101, "train_loss": 0.03472602658745988, "grad_norm": 0.10531545430421829, "test_error": 0.0186}, {"epoch": 102, "train_loss": 0.03459565302819344, "grad_norm": 0.09973862767219543, "test_error": 0.0186}, {"epoch": 103, "train_loss": 0.03508344512680196, "grad_norm": 0.1424223780632019, "test_error": 0.0181}, {"epoch": 104, "train_loss": 0.03440083691944407, "grad_norm": 0.19519193470478058, "test_error": 0.02}, {"epoch": 105, "train_loss": 0.035281745625524004, "grad_norm": 0.1728908270597458, "test_error": 0.0202}, {"epoch": 106, "train_loss": 0.03498430890564729, "grad_norm": 0.08762648701667786, "test_error": 0.0184}, {"epoch": 107, "train_loss": 0.03442926648788368, "grad_norm": 0.08369455486536026, "test_error": 0.0181}, {"epoch": 108, "train_loss": 0.034780432795062856, "grad_norm": 0.08657187223434448, "test_error": 0.0166}, {"epoch": 109, "train_loss": 0.0343274823629957, "grad_norm": 0.10974575579166412, "test_error": 0.017}, {"epoch": 110, "train_loss": 0.03448993065156295, "grad_norm": 0.20314164459705353, "test_error": 0.0201}, {"epoch": 111, "train_loss": 0.03440531008080385, "grad_norm": 0.14219284057617188, "test_error": 0.0204}, {"epoch": 112, "train_loss": 0.034850524715603876, "grad_norm": 0.09871339052915573, "test_error": 0.0189}, {"epoch": 113, "train_loss": 0.03458839543505261, "grad_norm": 0.07073473185300827, "test_error": 0.0177}, {"epoch": 114, "train_loss": 0.034359594687901944, "grad_norm": 0.10833504796028137, "test_error": 0.0177}, {"epoch": 115, "train_loss": 0.0340586391642064, "grad_norm": 0.07161083817481995, "test_error": 0.0168}, {"epoch": 116, "train_loss": 0.03401285866976832, "grad_norm": 0.05939587950706482, "test_error": 0.0159}, {"epoch": 117, "train_loss": 0.034737196410060275, "grad_norm": 0.26783469319343567, "test_error": 0.0223}, {"epoch": 118, "train_loss": 0.03480424094998549, "grad_norm": 0.11099034547805786, "test_error": 0.0174}, {"epoch": 119, "train_loss": 0.034159536471255705, "grad_norm": 0.14573611319065094, "test_error": 0.0189}, {"epoch": 120, "train_loss": 0.03427051448178099, "grad_norm": 0.08832693099975586, "test_error": 0.0193}, {"epoch": 121, "train_loss": 0.03411435637883793, "grad_norm": 0.25040560960769653, "test_error": 0.0214}, {"epoch": 122, "train_loss": 0.03391088912777195, "grad_norm": 0.14492015540599823, "test_error": 0.0201}, {"epoch": 123, "train_loss": 0.0346357251400744, "grad_norm": 0.08215421438217163, "test_error": 0.0174}, {"epoch": 124, "train_loss": 0.034894723333491126, "grad_norm": 0.17882581055164337, "test_error": 0.0199}, {"epoch": 125, "train_loss": 0.034422396429242025, "grad_norm": 0.13598006963729858, "test_error": 0.0181}, {"epoch": 126, "train_loss": 0.03420736952511894, "grad_norm": 0.15380941331386566, "test_error": 0.0187}, {"epoch": 127, "train_loss": 0.03393702176671165, "grad_norm": 0.11308624595403671, "test_error": 0.0188}, {"epoch": 128, "train_loss": 0.03506493245283734, "grad_norm": 0.08806286752223969, "test_error": 0.0171}, {"epoch": 129, "train_loss": 0.03420420274882539, "grad_norm": 0.12458240240812302, "test_error": 0.0175}, {"epoch": 130, "train_loss": 0.03367208139643481, "grad_norm": 0.15907832980155945, "test_error": 0.0188}, {"epoch": 131, "train_loss": 0.03469569419085262, "grad_norm": 0.1046086996793747, "test_error": 0.0177}, {"epoch": 132, "train_loss": 0.03502838732785313, "grad_norm": 0.12581177055835724, "test_error": 0.0191}, {"epoch": 133, "train_loss": 0.03489960677755395, "grad_norm": 0.12370769679546356, "test_error": 0.0173}, {"epoch": 134, "train_loss": 0.03335318782226144, "grad_norm": 0.29318803548812866, "test_error": 0.0211}, {"epoch": 135, "train_loss": 0.03424649219439743, "grad_norm": 0.13085602223873138, "test_error": 0.0192}, {"epoch": 136, "train_loss": 0.03446527882203615, "grad_norm": 0.6857573390007019, "test_error": 0.0303}, {"epoch": 137, "train_loss": 0.03377583383177019, "grad_norm": 0.18753036856651306, "test_error": 0.0188}, {"epoch": 138, "train_loss": 0.03484590816364653, "grad_norm": 0.08493809401988983, "test_error": 0.0173}, {"epoch": 139, "train_loss": 0.03408825834051822, "grad_norm": 0.09875527769327164, "test_error": 0.0184}, {"epoch": 140, "train_loss": 0.0352844370748644, "grad_norm": 0.08020643889904022, "test_error": 0.0159}, {"epoch": 141, "train_loss": 0.03402712608221918, "grad_norm": 0.16152286529541016, "test_error": 0.0191}, {"epoch": 142, "train_loss": 0.03427573434374547, "grad_norm": 0.1319117397069931, "test_error": 0.0195}, {"epoch": 143, "train_loss": 0.03412966039124876, "grad_norm": 0.09607654064893723, "test_error": 0.018}, {"epoch": 144, "train_loss": 0.03419298317419452, "grad_norm": 0.15405310690402985, "test_error": 0.0208}, {"epoch": 145, "train_loss": 0.034033180488736735, "grad_norm": 0.13189935684204102, "test_error": 0.0181}, {"epoch": 146, "train_loss": 0.03448098575407978, "grad_norm": 0.26040130853652954, "test_error": 0.0192}, {"epoch": 147, "train_loss": 0.033604522172325235, "grad_norm": 0.13525110483169556, "test_error": 0.0187}, {"epoch": 148, "train_loss": 0.03403534922885592, "grad_norm": 0.22085046768188477, "test_error": 0.0207}, {"epoch": 149, "train_loss": 0.03460200283122928, "grad_norm": 0.17040228843688965, "test_error": 0.0188}, {"epoch": 150, "train_loss": 0.034865989741051935, "grad_norm": 0.09239263087511063, "test_error": 0.0168}, {"epoch": 151, "train_loss": 0.03343057380187626, "grad_norm": 0.11889725923538208, "test_error": 0.0174}, {"epoch": 152, "train_loss": 0.03488008729662882, "grad_norm": 0.14685982465744019, "test_error": 0.0195}, {"epoch": 153, "train_loss": 0.03416794658115153, "grad_norm": 0.18254205584526062, "test_error": 0.0206}, {"epoch": 154, "train_loss": 0.03394929588084536, "grad_norm": 0.17587648332118988, "test_error": 0.0186}, {"epoch": 155, "train_loss": 0.03426580095273433, "grad_norm": 0.06030832976102829, "test_error": 0.0177}, {"epoch": 156, "train_loss": 0.03389254020754985, "grad_norm": 0.17154286801815033, "test_error": 0.0184}, {"epoch": 157, "train_loss": 0.03444658556321762, "grad_norm": 0.10897267609834671, "test_error": 0.0171}, {"epoch": 158, "train_loss": 0.03429734036028094, "grad_norm": 0.14404556155204773, "test_error": 0.0186}, {"epoch": 159, "train_loss": 0.03374574815693874, "grad_norm": 0.09470751881599426, "test_error": 0.0155}, {"epoch": 160, "train_loss": 0.033871414051860484, "grad_norm": 0.1163516417145729, "test_error": 0.0177}, {"epoch": 161, "train_loss": 0.03429136023600828, "grad_norm": 0.12618348002433777, "test_error": 0.0178}, {"epoch": 162, "train_loss": 0.03384854915707789, "grad_norm": 0.13417616486549377, "test_error": 0.0191}, {"epoch": 163, "train_loss": 0.03415508884131365, "grad_norm": 0.21053634583950043, "test_error": 0.0187}, {"epoch": 164, "train_loss": 0.03413020748745475, "grad_norm": 0.08987997472286224, "test_error": 0.0167}, {"epoch": 165, "train_loss": 0.03384172322757028, "grad_norm": 0.1434069126844406, "test_error": 0.0184}, {"epoch": 166, "train_loss": 0.03377392681787993, "grad_norm": 0.10061667859554291, "test_error": 0.0169}, {"epoch": 167, "train_loss": 0.033835828488047504, "grad_norm": 0.07772205024957657, "test_error": 0.0171}, {"epoch": 168, "train_loss": 0.03467327485860248, "grad_norm": 0.10969701409339905, "test_error": 0.0163}, {"epoch": 169, "train_loss": 0.034435950894883716, "grad_norm": 0.11717244237661362, "test_error": 0.0167}, {"epoch": 170, "train_loss": 0.03386917183182959, "grad_norm": 0.08187129348516464, "test_error": 0.0174}, {"epoch": 171, "train_loss": 0.0342845493900968, "grad_norm": 0.1389172226190567, "test_error": 0.02}, {"epoch": 172, "train_loss": 0.034444657130094126, "grad_norm": 0.20467595756053925, "test_error": 0.0214}, {"epoch": 173, "train_loss": 0.034190984384287734, "grad_norm": 0.07734082639217377, "test_error": 0.0184}, {"epoch": 174, "train_loss": 0.03397860332111061, "grad_norm": 0.10329821705818176, "test_error": 0.0168}, {"epoch": 175, "train_loss": 0.0337610359168951, "grad_norm": 0.17107126116752625, "test_error": 0.0187}, {"epoch": 176, "train_loss": 0.034218497963437886, "grad_norm": 0.5293450355529785, "test_error": 0.0252}, {"epoch": 177, "train_loss": 0.03444434116273866, "grad_norm": 0.15051838755607605, "test_error": 0.018}, {"epoch": 178, "train_loss": 0.03360142790260336, "grad_norm": 0.10954049229621887, "test_error": 0.0198}, {"epoch": 179, "train_loss": 0.03350539088166503, "grad_norm": 0.0886492133140564, "test_error": 0.0176}, {"epoch": 180, "train_loss": 0.03418195105316894, "grad_norm": 0.12706761062145233, "test_error": 0.0181}, {"epoch": 181, "train_loss": 0.033014388759850896, "grad_norm": 0.09902312606573105, "test_error": 0.0181}, {"epoch": 182, "train_loss": 0.033312205445467646, "grad_norm": 0.11366340517997742, "test_error": 0.0187}, {"epoch": 183, "train_loss": 0.034646895115765804, "grad_norm": 0.1033027246594429, "test_error": 0.0175}, {"epoch": 184, "train_loss": 0.03406467545236228, "grad_norm": 0.2900244891643524, "test_error": 0.0221}, {"epoch": 185, "train_loss": 0.033552640142535284, "grad_norm": 0.16339002549648285, "test_error": 0.0201}, {"epoch": 186, "train_loss": 0.03385255085416429, "grad_norm": 0.1558077037334442, "test_error": 0.018}, {"epoch": 187, "train_loss": 0.033409838931753866, "grad_norm": 0.1355806291103363, "test_error": 0.0207}, {"epoch": 188, "train_loss": 0.034007297579167546, "grad_norm": 0.158136785030365, "test_error": 0.0186}, {"epoch": 189, "train_loss": 0.034001640301833204, "grad_norm": 0.08539795875549316, "test_error": 0.0182}, {"epoch": 190, "train_loss": 0.03455475283490766, "grad_norm": 0.13705943524837494, "test_error": 0.0181}, {"epoch": 191, "train_loss": 0.03383301700308706, "grad_norm": 0.13567177951335907, "test_error": 0.0202}, {"epoch": 192, "train_loss": 0.03431239701562542, "grad_norm": 0.08916531503200531, "test_error": 0.0179}, {"epoch": 193, "train_loss": 0.03365791552395967, "grad_norm": 0.0982995480298996, "test_error": 0.0173}, {"epoch": 194, "train_loss": 0.034110434593855946, "grad_norm": 0.18735139071941376, "test_error": 0.0185}, {"epoch": 195, "train_loss": 0.03351200769110195, "grad_norm": 0.17724595963954926, "test_error": 0.0195}, {"epoch": 196, "train_loss": 0.03470913697162177, "grad_norm": 0.1952335089445114, "test_error": 0.019}, {"epoch": 197, "train_loss": 0.03378372952723779, "grad_norm": 0.08091412484645844, "test_error": 0.0182}, {"epoch": 198, "train_loss": 0.0335147527456138, "grad_norm": 0.06414629518985748, "test_error": 0.0165}, {"epoch": 199, "train_loss": 0.033902398415673815, "grad_norm": 0.1134478971362114, "test_error": 0.0186}, {"epoch": 200, "train_loss": 0.033992944314925506, "grad_norm": 0.14998877048492432, "test_error": 0.0196}, {"epoch": 201, "train_loss": 0.03467516474018339, "grad_norm": 0.09461763501167297, "test_error": 0.0175}, {"epoch": 202, "train_loss": 0.03409340204487914, "grad_norm": 0.16641458868980408, "test_error": 0.0176}, {"epoch": 203, "train_loss": 0.033855176975446134, "grad_norm": 0.08438495546579361, "test_error": 0.0173}, {"epoch": 204, "train_loss": 0.03474447545386405, "grad_norm": 0.11604084819555283, "test_error": 0.0172}, {"epoch": 205, "train_loss": 0.03319130489252469, "grad_norm": 0.12468327581882477, "test_error": 0.0181}, {"epoch": 206, "train_loss": 0.03323552751314855, "grad_norm": 0.09733325242996216, "test_error": 0.017}, {"epoch": 207, "train_loss": 0.033741808935298954, "grad_norm": 0.0792299136519432, "test_error": 0.0164}, {"epoch": 208, "train_loss": 0.034453259068735254, "grad_norm": 0.13572365045547485, "test_error": 0.0174}, {"epoch": 209, "train_loss": 0.03382791931566802, "grad_norm": 0.05887391418218613, "test_error": 0.0167}, {"epoch": 210, "train_loss": 0.03426178219816454, "grad_norm": 0.19813227653503418, "test_error": 0.0178}, {"epoch": 211, "train_loss": 0.03426492233564932, "grad_norm": 0.20361360907554626, "test_error": 0.0201}, {"epoch": 212, "train_loss": 0.03349293683503735, "grad_norm": 0.11574070900678635, "test_error": 0.0179}, {"epoch": 213, "train_loss": 0.034155561468583374, "grad_norm": 0.11044333130121231, "test_error": 0.0173}, {"epoch": 214, "train_loss": 0.033389284186834026, "grad_norm": 0.07714132219552994, "test_error": 0.0176}, {"epoch": 215, "train_loss": 0.03400443223625189, "grad_norm": 0.1401325762271881, "test_error": 0.0195}, {"epoch": 216, "train_loss": 0.03433692909073822, "grad_norm": 0.11705339699983597, "test_error": 0.0188}, {"epoch": 217, "train_loss": 0.033302423745185175, "grad_norm": 0.15751567482948303, "test_error": 0.0183}, {"epoch": 218, "train_loss": 0.03399623366611922, "grad_norm": 0.09858155995607376, "test_error": 0.0174}, {"epoch": 219, "train_loss": 0.03341337366893519, "grad_norm": 0.09613863378763199, "test_error": 0.0166}, {"epoch": 220, "train_loss": 0.03367817366999225, "grad_norm": 0.15559223294258118, "test_error": 0.0193}, {"epoch": 221, "train_loss": 0.034210058444021946, "grad_norm": 0.1340237259864807, "test_error": 0.018}, {"epoch": 222, "train_loss": 0.03456972838347914, "grad_norm": 0.11140134930610657, "test_error": 0.0193}, {"epoch": 223, "train_loss": 0.033924265436343075, "grad_norm": 0.08786803483963013, "test_error": 0.0186}, {"epoch": 224, "train_loss": 0.033778554704006335, "grad_norm": 0.2682197391986847, "test_error": 0.0188}, {"epoch": 225, "train_loss": 0.033958286407782, "grad_norm": 0.15757347643375397, "test_error": 0.0174}, {"epoch": 226, "train_loss": 0.03384370660038258, "grad_norm": 0.09635434299707413, "test_error": 0.0187}, {"epoch": 227, "train_loss": 0.033782256194759004, "grad_norm": 0.1105378270149231, "test_error": 0.0194}, {"epoch": 228, "train_loss": 0.03419041042736838, "grad_norm": 0.15555788576602936, "test_error": 0.0193}, {"epoch": 229, "train_loss": 0.0342075204020075, "grad_norm": 0.1255030483007431, "test_error": 0.0175}, {"epoch": 230, "train_loss": 0.03447642536600567, "grad_norm": 0.0956367701292038, "test_error": 0.0164}, {"epoch": 231, "train_loss": 0.03387526328010911, "grad_norm": 0.1331479698419571, "test_error": 0.0192}, {"epoch": 232, "train_loss": 0.03369537284178174, "grad_norm": 0.12104769796133041, "test_error": 0.0186}, {"epoch": 233, "train_loss": 0.03336298107426167, "grad_norm": 0.12831391394138336, "test_error": 0.0187}, {"epoch": 234, "train_loss": 0.03369317464472988, "grad_norm": 0.10896225273609161, "test_error": 0.018}, {"epoch": 235, "train_loss": 0.0341903463041405, "grad_norm": 0.08167768269777298, "test_error": 0.0171}, {"epoch": 236, "train_loss": 0.03361575955884473, "grad_norm": 0.10846332460641861, "test_error": 0.0173}, {"epoch": 237, "train_loss": 0.03431503029864689, "grad_norm": 0.1466246247291565, "test_error": 0.0194}, {"epoch": 238, "train_loss": 0.03413554342207014, "grad_norm": 0.19666115939617157, "test_error": 0.0192}, {"epoch": 239, "train_loss": 0.03416555382263808, "grad_norm": 0.10456863790750504, "test_error": 0.0173}, {"epoch": 240, "train_loss": 0.034509155958046905, "grad_norm": 0.1459738165140152, "test_error": 0.0178}, {"epoch": 241, "train_loss": 0.03316220039892748, "grad_norm": 0.13030225038528442, "test_error": 0.0194}, {"epoch": 242, "train_loss": 0.03344154944277155, "grad_norm": 0.1930738240480423, "test_error": 0.0202}, {"epoch": 243, "train_loss": 0.034101317422452364, "grad_norm": 0.08510256558656693, "test_error": 0.0183}, {"epoch": 244, "train_loss": 0.033986601650622714, "grad_norm": 0.056073740124702454, "test_error": 0.0177}, {"epoch": 245, "train_loss": 0.03377698330111889, "grad_norm": 0.21662726998329163, "test_error": 0.02}, {"epoch": 246, "train_loss": 0.03469973909031493, "grad_norm": 0.10962479561567307, "test_error": 0.0175}, {"epoch": 247, "train_loss": 0.032956301675777164, "grad_norm": 0.1128709688782692, "test_error": 0.0176}, {"epoch": 248, "train_loss": 0.033821821758843726, "grad_norm": 0.1485116332769394, "test_error": 0.0201}, {"epoch": 249, "train_loss": 0.03367027189434642, "grad_norm": 0.12018872797489166, "test_error": 0.0164}, {"epoch": 250, "train_loss": 0.03427483409988054, "grad_norm": 0.2517688274383545, "test_error": 0.0207}, {"epoch": 251, "train_loss": 0.033241994629395775, "grad_norm": 0.09687881171703339, "test_error": 0.0178}, {"epoch": 252, "train_loss": 0.03380002653497892, "grad_norm": 0.14626677334308624, "test_error": 0.0185}, {"epoch": 253, "train_loss": 0.03363281287826248, "grad_norm": 0.12402178347110748, "test_error": 0.0179}, {"epoch": 254, "train_loss": 0.034297851093528155, "grad_norm": 0.07680477201938629, "test_error": 0.017}, {"epoch": 255, "train_loss": 0.03275566838763674, "grad_norm": 0.15171873569488525, "test_error": 0.0184}, {"epoch": 256, "train_loss": 0.0334007261242635, "grad_norm": 0.3110716640949249, "test_error": 0.022}, {"epoch": 257, "train_loss": 0.03373590392772167, "grad_norm": 0.1235165223479271, "test_error": 0.0177}, {"epoch": 258, "train_loss": 0.03389193709239286, "grad_norm": 0.2568768560886383, "test_error": 0.0229}, {"epoch": 259, "train_loss": 0.033519856521968906, "grad_norm": 0.056645553559064865, "test_error": 0.0163}, {"epoch": 260, "train_loss": 0.033442798575626514, "grad_norm": 0.0659550279378891, "test_error": 0.0173}, {"epoch": 261, "train_loss": 0.033842845056928736, "grad_norm": 0.1283438801765442, "test_error": 0.0177}, {"epoch": 262, "train_loss": 0.033326929076880334, "grad_norm": 0.18027517199516296, "test_error": 0.0196}, {"epoch": 263, "train_loss": 0.03410912254466772, "grad_norm": 0.10956676304340363, "test_error": 0.019}, {"epoch": 264, "train_loss": 0.033582976474416985, "grad_norm": 0.14374250173568726, "test_error": 0.0192}, {"epoch": 265, "train_loss": 0.03340533348446479, "grad_norm": 0.2608240842819214, "test_error": 0.0229}, {"epoch": 266, "train_loss": 0.033501338231076566, "grad_norm": 0.07174348086118698, "test_error": 0.0179}, {"epoch": 267, "train_loss": 0.03323281430445786, "grad_norm": 0.17787958681583405, "test_error": 0.0197}, {"epoch": 268, "train_loss": 0.034013326642557025, "grad_norm": 0.13997699320316315, "test_error": 0.0186}, {"epoch": 269, "train_loss": 0.0334791812839685, "grad_norm": 0.1344750076532364, "test_error": 0.0208}, {"epoch": 270, "train_loss": 0.03388804320654405, "grad_norm": 0.1542164385318756, "test_error": 0.018}, {"epoch": 271, "train_loss": 0.03444712071449855, "grad_norm": 0.10550102591514587, "test_error": 0.017}, {"epoch": 272, "train_loss": 0.03360343469169311, "grad_norm": 0.13731513917446136, "test_error": 0.018}, {"epoch": 273, "train_loss": 0.034389125083569526, "grad_norm": 0.13761435449123383, "test_error": 0.0189}, {"epoch": 274, "train_loss": 0.034023848801817316, "grad_norm": 0.10484752058982849, "test_error": 0.0156}, {"epoch": 275, "train_loss": 0.03309178073087726, "grad_norm": 0.29787465929985046, "test_error": 0.0212}, {"epoch": 276, "train_loss": 0.03322330035217116, "grad_norm": 0.1921243667602539, "test_error": 0.0186}, {"epoch": 277, "train_loss": 0.033467088104514306, "grad_norm": 0.079787977039814, "test_error": 0.0175}, {"epoch": 278, "train_loss": 0.03304488450342372, "grad_norm": 0.08038987964391708, "test_error": 0.0171}, {"epoch": 279, "train_loss": 0.03360531651380006, "grad_norm": 0.22156186401844025, "test_error": 0.0183}, {"epoch": 280, "train_loss": 0.0337115912927984, "grad_norm": 0.10617143660783768, "test_error": 0.017}, {"epoch": 281, "train_loss": 0.03352276848112524, "grad_norm": 0.09577956795692444, "test_error": 0.0171}, {"epoch": 282, "train_loss": 0.034080872947221605, "grad_norm": 0.12601201236248016, "test_error": 0.0184}, {"epoch": 283, "train_loss": 0.033681711262344226, "grad_norm": 0.2590637803077698, "test_error": 0.0209}, {"epoch": 284, "train_loss": 0.033653445309547045, "grad_norm": 0.14581646025180817, "test_error": 0.0184}, {"epoch": 285, "train_loss": 0.034396190112422724, "grad_norm": 0.11447736620903015, "test_error": 0.019}, {"epoch": 286, "train_loss": 0.03400412505273804, "grad_norm": 0.09491030871868134, "test_error": 0.0181}, {"epoch": 287, "train_loss": 0.03350282798625995, "grad_norm": 0.09426277130842209, "test_error": 0.0184}, {"epoch": 288, "train_loss": 0.03424968158517246, "grad_norm": 0.09948855638504028, "test_error": 0.0186}, {"epoch": 289, "train_loss": 0.03395005493484253, "grad_norm": 0.20283843576908112, "test_error": 0.0192}, {"epoch": 290, "train_loss": 0.03322735478379279, "grad_norm": 0.1724526733160019, "test_error": 0.0195}, {"epoch": 291, "train_loss": 0.03323424800324817, "grad_norm": 0.17879100143909454, "test_error": 0.018}, {"epoch": 292, "train_loss": 0.034101468737993856, "grad_norm": 0.17340052127838135, "test_error": 0.0191}, {"epoch": 293, "train_loss": 0.03400129964859419, "grad_norm": 0.12320952117443085, "test_error": 0.0175}, {"epoch": 294, "train_loss": 0.03351315551501709, "grad_norm": 0.19621340930461884, "test_error": 0.0201}, {"epoch": 295, "train_loss": 0.033722941268220896, "grad_norm": 0.20815418660640717, "test_error": 0.0218}, {"epoch": 296, "train_loss": 0.03339484592988447, "grad_norm": 0.06828725337982178, "test_error": 0.018}, {"epoch": 297, "train_loss": 0.033644321270837586, "grad_norm": 0.09991490840911865, "test_error": 0.0179}, {"epoch": 298, "train_loss": 0.03378248985142515, "grad_norm": 0.0848863422870636, "test_error": 0.0172}, {"epoch": 299, "train_loss": 0.033208788628694794, "grad_norm": 0.20556502044200897, "test_error": 0.0199}, {"epoch": 300, "train_loss": 0.03369248149271637, "grad_norm": 0.10609502345323563, "test_error": 0.0187}]}