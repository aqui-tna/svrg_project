{"argv": ["train.py", "--seed", "12", "--optimizer", "SGD", "--run_name", "sgd_0.01.json", "--output_path", "experiments/nonconvex_mnist_deep/sgd-0.01.json", "--dataset", "MNIST", "--layer_sizes", "784", "600", "300", "10", "--batch_size", "10", "--learning_rate", "0.01", "--weight_decay", "0.001", "--num_epochs", "300", "--device", "cuda"], "args": {"seed": 12, "optimizer": "SGD", "run_name": "sgd_0.01.json", "output_path": "experiments/nonconvex_mnist_deep/sgd-0.01.json", "device": "cuda", "dataset": "MNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": false, "layer_sizes": [784, 600, 300, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.01, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 0.571536503718545, "grad_norm": 0.4878016710281372, "test_error": 0.0763}, {"epoch": 2, "train_loss": 0.23396723081582846, "grad_norm": 0.38588929176330566, "test_error": 0.0557}, {"epoch": 3, "train_loss": 0.17026348411284076, "grad_norm": 0.28365689516067505, "test_error": 0.045}, {"epoch": 4, "train_loss": 0.13419210170345225, "grad_norm": 0.2706556022167206, "test_error": 0.0387}, {"epoch": 5, "train_loss": 0.11112777735632456, "grad_norm": 0.1801883429288864, "test_error": 0.0312}, {"epoch": 6, "train_loss": 0.09556892887297241, "grad_norm": 0.20419341325759888, "test_error": 0.0294}, {"epoch": 7, "train_loss": 0.08367450788556986, "grad_norm": 0.16663391888141632, "test_error": 0.0273}, {"epoch": 8, "train_loss": 0.07477453368386099, "grad_norm": 0.18560513854026794, "test_error": 0.0241}, {"epoch": 9, "train_loss": 0.06797898050301591, "grad_norm": 0.10629048198461533, "test_error": 0.0223}, {"epoch": 10, "train_loss": 0.06247672511029911, "grad_norm": 0.3039754033088684, "test_error": 0.0258}, {"epoch": 11, "train_loss": 0.05839080320237554, "grad_norm": 0.12553979456424713, "test_error": 0.0216}, {"epoch": 12, "train_loss": 0.05403470944144646, "grad_norm": 0.24026133120059967, "test_error": 0.0224}, {"epoch": 13, "train_loss": 0.051113122641506685, "grad_norm": 0.14218609035015106, "test_error": 0.0212}, {"epoch": 14, "train_loss": 0.048765281361032975, "grad_norm": 0.1311415284872055, "test_error": 0.0204}, {"epoch": 15, "train_loss": 0.04700825976505196, "grad_norm": 0.12248189747333527, "test_error": 0.0206}, {"epoch": 16, "train_loss": 0.04500679018096707, "grad_norm": 0.11318551748991013, "test_error": 0.021}, {"epoch": 17, "train_loss": 0.04302507019738065, "grad_norm": 0.17329414188861847, "test_error": 0.021}, {"epoch": 18, "train_loss": 0.04201018372526839, "grad_norm": 0.08087953925132751, "test_error": 0.0185}, {"epoch": 19, "train_loss": 0.04044738753060907, "grad_norm": 0.10467572510242462, "test_error": 0.02}, {"epoch": 20, "train_loss": 0.03949376361927959, "grad_norm": 0.14805196225643158, "test_error": 0.0202}, {"epoch": 21, "train_loss": 0.038482513162467515, "grad_norm": 0.28990721702575684, "test_error": 0.0209}, {"epoch": 22, "train_loss": 0.037729204852939194, "grad_norm": 0.1279725581407547, "test_error": 0.0197}, {"epoch": 23, "train_loss": 0.03680611215599008, "grad_norm": 0.0981646329164505, "test_error": 0.0202}, {"epoch": 24, "train_loss": 0.03631467803988683, "grad_norm": 0.17139023542404175, "test_error": 0.02}, {"epoch": 25, "train_loss": 0.035891491815884365, "grad_norm": 0.07067838311195374, "test_error": 0.0189}, {"epoch": 26, "train_loss": 0.03543806391572677, "grad_norm": 0.10585207492113113, "test_error": 0.0179}, {"epoch": 27, "train_loss": 0.03442666226833535, "grad_norm": 0.0831104964017868, "test_error": 0.019}, {"epoch": 28, "train_loss": 0.034145065723413914, "grad_norm": 0.07247405499219894, "test_error": 0.018}, {"epoch": 29, "train_loss": 0.03375500518733073, "grad_norm": 0.06920212507247925, "test_error": 0.0185}, {"epoch": 30, "train_loss": 0.03324556893568176, "grad_norm": 0.15105091035366058, "test_error": 0.0184}, {"epoch": 31, "train_loss": 0.0331502871067496, "grad_norm": 0.10868702083826065, "test_error": 0.0189}, {"epoch": 32, "train_loss": 0.03261770702108333, "grad_norm": 0.10000205785036087, "test_error": 0.0182}, {"epoch": 33, "train_loss": 0.03234544459929263, "grad_norm": 0.12462165206670761, "test_error": 0.0178}, {"epoch": 34, "train_loss": 0.03244485242346127, "grad_norm": 0.08327282220125198, "test_error": 0.0187}, {"epoch": 35, "train_loss": 0.03204019264277061, "grad_norm": 0.11051399260759354, "test_error": 0.0182}, {"epoch": 36, "train_loss": 0.031578166911730175, "grad_norm": 0.1788480579853058, "test_error": 0.0189}, {"epoch": 37, "train_loss": 0.03148678265573108, "grad_norm": 0.11375103145837784, "test_error": 0.0171}, {"epoch": 38, "train_loss": 0.03131364737891029, "grad_norm": 0.17468667030334473, "test_error": 0.0189}, {"epoch": 39, "train_loss": 0.03088902488358144, "grad_norm": 0.11230257898569107, "test_error": 0.0188}, {"epoch": 40, "train_loss": 0.031058168337588236, "grad_norm": 0.10985592752695084, "test_error": 0.018}, {"epoch": 41, "train_loss": 0.030634107642545132, "grad_norm": 0.1313745528459549, "test_error": 0.0189}, {"epoch": 42, "train_loss": 0.030302020049881927, "grad_norm": 0.06774838268756866, "test_error": 0.0181}, {"epoch": 43, "train_loss": 0.030792426906147738, "grad_norm": 0.06648341566324234, "test_error": 0.0163}, {"epoch": 44, "train_loss": 0.030403827695338503, "grad_norm": 0.10801885277032852, "test_error": 0.0173}, {"epoch": 45, "train_loss": 0.030314394621779987, "grad_norm": 0.22553059458732605, "test_error": 0.0194}, {"epoch": 46, "train_loss": 0.03019713596336078, "grad_norm": 0.18078279495239258, "test_error": 0.0181}, {"epoch": 47, "train_loss": 0.029846373022398134, "grad_norm": 0.10667021572589874, "test_error": 0.018}, {"epoch": 48, "train_loss": 0.02976463390045198, "grad_norm": 0.14399273693561554, "test_error": 0.0183}, {"epoch": 49, "train_loss": 0.030002500736615426, "grad_norm": 0.10586931556463242, "test_error": 0.0166}, {"epoch": 50, "train_loss": 0.02975638264584025, "grad_norm": 0.10876376926898956, "test_error": 0.0186}, {"epoch": 51, "train_loss": 0.02952700612982638, "grad_norm": 0.11523357033729553, "test_error": 0.0192}, {"epoch": 52, "train_loss": 0.029586998756970084, "grad_norm": 0.12280863523483276, "test_error": 0.0186}, {"epoch": 53, "train_loss": 0.029477600697340678, "grad_norm": 0.06382855772972107, "test_error": 0.0167}, {"epoch": 54, "train_loss": 0.029162122085515874, "grad_norm": 0.07323522120714188, "test_error": 0.018}, {"epoch": 55, "train_loss": 0.02893905693469666, "grad_norm": 0.08037023991346359, "test_error": 0.0174}, {"epoch": 56, "train_loss": 0.02926402527767641, "grad_norm": 0.20305702090263367, "test_error": 0.0192}, {"epoch": 57, "train_loss": 0.029110717014965, "grad_norm": 0.10821117460727692, "test_error": 0.0181}, {"epoch": 58, "train_loss": 0.02904226338865313, "grad_norm": 0.09086228162050247, "test_error": 0.0173}, {"epoch": 59, "train_loss": 0.029081867093778177, "grad_norm": 0.09659551084041595, "test_error": 0.0195}, {"epoch": 60, "train_loss": 0.029375416354470267, "grad_norm": 0.12945935130119324, "test_error": 0.0179}, {"epoch": 61, "train_loss": 0.02897834075244221, "grad_norm": 0.07666688412427902, "test_error": 0.0166}, {"epoch": 62, "train_loss": 0.028651932223307086, "grad_norm": 0.15051738917827606, "test_error": 0.0179}, {"epoch": 63, "train_loss": 0.028708278847858308, "grad_norm": 0.1073426902294159, "test_error": 0.0181}, {"epoch": 64, "train_loss": 0.028674166659865174, "grad_norm": 0.10678482055664062, "test_error": 0.018}, {"epoch": 65, "train_loss": 0.028626106971826326, "grad_norm": 0.11884233355522156, "test_error": 0.0175}, {"epoch": 66, "train_loss": 0.02864257397710268, "grad_norm": 0.07667331397533417, "test_error": 0.0181}, {"epoch": 67, "train_loss": 0.02850269842012494, "grad_norm": 0.14235103130340576, "test_error": 0.0186}, {"epoch": 68, "train_loss": 0.02864526776577986, "grad_norm": 0.11699317395687103, "test_error": 0.0176}, {"epoch": 69, "train_loss": 0.028459502397245765, "grad_norm": 0.14387960731983185, "test_error": 0.0178}, {"epoch": 70, "train_loss": 0.028509113127399663, "grad_norm": 0.11917806416749954, "test_error": 0.018}, {"epoch": 71, "train_loss": 0.028263188207575392, "grad_norm": 0.13503943383693695, "test_error": 0.0184}, {"epoch": 72, "train_loss": 0.02850330156175672, "grad_norm": 0.13438771665096283, "test_error": 0.019}, {"epoch": 73, "train_loss": 0.02828413787499206, "grad_norm": 0.08490265905857086, "test_error": 0.0182}, {"epoch": 74, "train_loss": 0.0282814049161049, "grad_norm": 0.11280711740255356, "test_error": 0.0173}, {"epoch": 75, "train_loss": 0.02837049811238588, "grad_norm": 0.09150538593530655, "test_error": 0.0177}, {"epoch": 76, "train_loss": 0.027943815504787684, "grad_norm": 0.16084787249565125, "test_error": 0.0166}, {"epoch": 77, "train_loss": 0.028142961062355122, "grad_norm": 0.08147826045751572, "test_error": 0.0186}, {"epoch": 78, "train_loss": 0.028372072878487718, "grad_norm": 0.08838731795549393, "test_error": 0.018}, {"epoch": 79, "train_loss": 0.028099097779942288, "grad_norm": 0.05050026997923851, "test_error": 0.017}, {"epoch": 80, "train_loss": 0.02808093549356272, "grad_norm": 0.07197505235671997, "test_error": 0.0185}, {"epoch": 81, "train_loss": 0.02804323658796784, "grad_norm": 0.12870022654533386, "test_error": 0.0185}, {"epoch": 82, "train_loss": 0.027757935824830687, "grad_norm": 0.08206324279308319, "test_error": 0.018}, {"epoch": 83, "train_loss": 0.027996658594769543, "grad_norm": 0.0526125505566597, "test_error": 0.0166}, {"epoch": 84, "train_loss": 0.027568312278885666, "grad_norm": 0.11975986510515213, "test_error": 0.0172}, {"epoch": 85, "train_loss": 0.028161706957498003, "grad_norm": 0.20202861726284027, "test_error": 0.0195}, {"epoch": 86, "train_loss": 0.027949177073901713, "grad_norm": 0.16836288571357727, "test_error": 0.0183}, {"epoch": 87, "train_loss": 0.027696019805802885, "grad_norm": 0.17395344376564026, "test_error": 0.0177}, {"epoch": 88, "train_loss": 0.02769185914057501, "grad_norm": 0.09822633117437363, "test_error": 0.0177}, {"epoch": 89, "train_loss": 0.027890168983120626, "grad_norm": 0.19135195016860962, "test_error": 0.0173}, {"epoch": 90, "train_loss": 0.02770009852190075, "grad_norm": 0.08791574090719223, "test_error": 0.0181}, {"epoch": 91, "train_loss": 0.027701020830267226, "grad_norm": 0.2034149318933487, "test_error": 0.0186}, {"epoch": 92, "train_loss": 0.0277074290219122, "grad_norm": 0.11623499542474747, "test_error": 0.0164}, {"epoch": 93, "train_loss": 0.0277328876969259, "grad_norm": 0.12707096338272095, "test_error": 0.0189}, {"epoch": 94, "train_loss": 0.02786899896824616, "grad_norm": 0.09862503409385681, "test_error": 0.0176}, {"epoch": 95, "train_loss": 0.027613587015900217, "grad_norm": 0.10446789860725403, "test_error": 0.0167}, {"epoch": 96, "train_loss": 0.02779139081149333, "grad_norm": 0.14014457166194916, "test_error": 0.0179}, {"epoch": 97, "train_loss": 0.027670378675849254, "grad_norm": 0.0852319523692131, "test_error": 0.0185}, {"epoch": 98, "train_loss": 0.02765967485839307, "grad_norm": 0.09330543875694275, "test_error": 0.0186}, {"epoch": 99, "train_loss": 0.027374912045939708, "grad_norm": 0.12447573989629745, "test_error": 0.0175}, {"epoch": 100, "train_loss": 0.027445693179169516, "grad_norm": 0.09417115151882172, "test_error": 0.0175}, {"epoch": 101, "train_loss": 0.027695460153156697, "grad_norm": 0.09105993807315826, "test_error": 0.0182}, {"epoch": 102, "train_loss": 0.02731460514748566, "grad_norm": 0.09331127256155014, "test_error": 0.0174}, {"epoch": 103, "train_loss": 0.02758998900858569, "grad_norm": 0.14326010644435883, "test_error": 0.0168}, {"epoch": 104, "train_loss": 0.027268750876280442, "grad_norm": 0.11798601597547531, "test_error": 0.018}, {"epoch": 105, "train_loss": 0.027619626732746837, "grad_norm": 0.15913565456867218, "test_error": 0.0187}, {"epoch": 106, "train_loss": 0.02749051954433283, "grad_norm": 0.06175358593463898, "test_error": 0.0179}, {"epoch": 107, "train_loss": 0.027362087726534808, "grad_norm": 0.07456792891025543, "test_error": 0.0186}, {"epoch": 108, "train_loss": 0.027493940787147342, "grad_norm": 0.07191430777311325, "test_error": 0.017}, {"epoch": 109, "train_loss": 0.02735092594916447, "grad_norm": 0.11813551932573318, "test_error": 0.0175}, {"epoch": 110, "train_loss": 0.02707825065368767, "grad_norm": 0.16521047055721283, "test_error": 0.0173}, {"epoch": 111, "train_loss": 0.027219212455912686, "grad_norm": 0.10683434456586838, "test_error": 0.018}, {"epoch": 112, "train_loss": 0.027486448222683976, "grad_norm": 0.07522427290678024, "test_error": 0.0166}, {"epoch": 113, "train_loss": 0.027325859046332578, "grad_norm": 0.08373012393712997, "test_error": 0.0177}, {"epoch": 114, "train_loss": 0.027115845766000953, "grad_norm": 0.09326747804880142, "test_error": 0.0165}, {"epoch": 115, "train_loss": 0.02705736102918066, "grad_norm": 0.06626687198877335, "test_error": 0.0167}, {"epoch": 116, "train_loss": 0.027087892986935914, "grad_norm": 0.06276744604110718, "test_error": 0.0167}, {"epoch": 117, "train_loss": 0.027268996063726566, "grad_norm": 0.11152192205190659, "test_error": 0.0182}, {"epoch": 118, "train_loss": 0.027290617876618246, "grad_norm": 0.09348427504301071, "test_error": 0.0166}, {"epoch": 119, "train_loss": 0.027120128693122147, "grad_norm": 0.09539191424846649, "test_error": 0.0177}, {"epoch": 120, "train_loss": 0.027174688852469746, "grad_norm": 0.0989072173833847, "test_error": 0.0175}, {"epoch": 121, "train_loss": 0.027119521857200502, "grad_norm": 0.11499551683664322, "test_error": 0.0172}, {"epoch": 122, "train_loss": 0.026808628827891274, "grad_norm": 0.11199913918972015, "test_error": 0.0181}, {"epoch": 123, "train_loss": 0.027048599157569696, "grad_norm": 0.06860482692718506, "test_error": 0.0169}, {"epoch": 124, "train_loss": 0.02705022964293797, "grad_norm": 0.12697000801563263, "test_error": 0.0189}, {"epoch": 125, "train_loss": 0.027250800936802988, "grad_norm": 0.0907975286245346, "test_error": 0.0172}, {"epoch": 126, "train_loss": 0.026972453045115495, "grad_norm": 0.05652093142271042, "test_error": 0.0166}, {"epoch": 127, "train_loss": 0.02701879537526596, "grad_norm": 0.08859343081712723, "test_error": 0.0169}, {"epoch": 128, "train_loss": 0.027272429977786183, "grad_norm": 0.07873379439115524, "test_error": 0.0172}, {"epoch": 129, "train_loss": 0.027212771748643717, "grad_norm": 0.07113876193761826, "test_error": 0.017}, {"epoch": 130, "train_loss": 0.026815962311639546, "grad_norm": 0.09657030552625656, "test_error": 0.0169}, {"epoch": 131, "train_loss": 0.02710543976696499, "grad_norm": 0.07511541992425919, "test_error": 0.0173}, {"epoch": 132, "train_loss": 0.0270815494190659, "grad_norm": 0.13577772676944733, "test_error": 0.0189}, {"epoch": 133, "train_loss": 0.02706681977779954, "grad_norm": 0.09649481624364853, "test_error": 0.017}, {"epoch": 134, "train_loss": 0.026642288838265814, "grad_norm": 0.16750945150852203, "test_error": 0.0175}, {"epoch": 135, "train_loss": 0.0269569451847298, "grad_norm": 0.08280202001333237, "test_error": 0.0174}, {"epoch": 136, "train_loss": 0.02706359322994831, "grad_norm": 0.4000782370567322, "test_error": 0.0221}, {"epoch": 137, "train_loss": 0.026779229896565084, "grad_norm": 0.11041354387998581, "test_error": 0.018}, {"epoch": 138, "train_loss": 0.027070719042577063, "grad_norm": 0.10174102336168289, "test_error": 0.0164}, {"epoch": 139, "train_loss": 0.026703582061090855, "grad_norm": 0.11843016743659973, "test_error": 0.0172}, {"epoch": 140, "train_loss": 0.027218993021184967, "grad_norm": 0.06413009762763977, "test_error": 0.0165}, {"epoch": 141, "train_loss": 0.026928558276369585, "grad_norm": 0.1093212217092514, "test_error": 0.0175}, {"epoch": 142, "train_loss": 0.02678511328913737, "grad_norm": 0.114576555788517, "test_error": 0.018}, {"epoch": 143, "train_loss": 0.026687901816437563, "grad_norm": 0.10078933835029602, "test_error": 0.0183}, {"epoch": 144, "train_loss": 0.02678200158032511, "grad_norm": 0.13988544046878815, "test_error": 0.0176}, {"epoch": 145, "train_loss": 0.026796534755194442, "grad_norm": 0.05123202130198479, "test_error": 0.0169}, {"epoch": 146, "train_loss": 0.026765505203555223, "grad_norm": 0.1521303951740265, "test_error": 0.0187}, {"epoch": 147, "train_loss": 0.026616454416454265, "grad_norm": 0.06750886887311935, "test_error": 0.0169}, {"epoch": 148, "train_loss": 0.02668044893372765, "grad_norm": 0.10298200696706772, "test_error": 0.0165}, {"epoch": 149, "train_loss": 0.026963579602888785, "grad_norm": 0.12641224265098572, "test_error": 0.0171}, {"epoch": 150, "train_loss": 0.02694165806359524, "grad_norm": 0.07966664433479309, "test_error": 0.0171}, {"epoch": 151, "train_loss": 0.026456953202122047, "grad_norm": 0.0633997693657875, "test_error": 0.0174}, {"epoch": 152, "train_loss": 0.027006653030470867, "grad_norm": 0.09610290825366974, "test_error": 0.0173}, {"epoch": 153, "train_loss": 0.026724893356777708, "grad_norm": 0.09695924073457718, "test_error": 0.0176}, {"epoch": 154, "train_loss": 0.026629206079247524, "grad_norm": 0.10496523231267929, "test_error": 0.0176}, {"epoch": 155, "train_loss": 0.02665860635746018, "grad_norm": 0.05850773677229881, "test_error": 0.017}, {"epoch": 156, "train_loss": 0.026677735297693288, "grad_norm": 0.18568766117095947, "test_error": 0.0177}, {"epoch": 157, "train_loss": 0.02673913189312831, "grad_norm": 0.09795765578746796, "test_error": 0.0174}, {"epoch": 158, "train_loss": 0.026635687738991692, "grad_norm": 0.12192519754171371, "test_error": 0.0177}, {"epoch": 159, "train_loss": 0.02662141711465665, "grad_norm": 0.10885118693113327, "test_error": 0.017}, {"epoch": 160, "train_loss": 0.026625761419173312, "grad_norm": 0.0722121074795723, "test_error": 0.0163}, {"epoch": 161, "train_loss": 0.02677876215626505, "grad_norm": 0.0947917029261589, "test_error": 0.0168}, {"epoch": 162, "train_loss": 0.02667552380799801, "grad_norm": 0.10118881613016129, "test_error": 0.0173}, {"epoch": 163, "train_loss": 0.026777507083332847, "grad_norm": 0.14926135540008545, "test_error": 0.0173}, {"epoch": 164, "train_loss": 0.026607459687904338, "grad_norm": 0.17505793273448944, "test_error": 0.0176}, {"epoch": 165, "train_loss": 0.026491373860893265, "grad_norm": 0.12942832708358765, "test_error": 0.0171}, {"epoch": 166, "train_loss": 0.02649205329346296, "grad_norm": 0.08174656331539154, "test_error": 0.0178}, {"epoch": 167, "train_loss": 0.026542240568621006, "grad_norm": 0.08325935900211334, "test_error": 0.0174}, {"epoch": 168, "train_loss": 0.02666763393873407, "grad_norm": 0.08792183548212051, "test_error": 0.0165}, {"epoch": 169, "train_loss": 0.026797141397141483, "grad_norm": 0.11515577137470245, "test_error": 0.0165}, {"epoch": 170, "train_loss": 0.02654913158385898, "grad_norm": 0.09025340527296066, "test_error": 0.0176}, {"epoch": 171, "train_loss": 0.026667065444315085, "grad_norm": 0.10448849946260452, "test_error": 0.0185}, {"epoch": 172, "train_loss": 0.02680494115657348, "grad_norm": 0.11902093887329102, "test_error": 0.0169}, {"epoch": 173, "train_loss": 0.02662429993096157, "grad_norm": 0.052746985107660294, "test_error": 0.0164}, {"epoch": 174, "train_loss": 0.026532193851982206, "grad_norm": 0.08786105364561081, "test_error": 0.0162}, {"epoch": 175, "train_loss": 0.026550749516289215, "grad_norm": 0.13094903528690338, "test_error": 0.0171}, {"epoch": 176, "train_loss": 0.02648974360009985, "grad_norm": 0.4861351549625397, "test_error": 0.0202}, {"epoch": 177, "train_loss": 0.02646717472098923, "grad_norm": 0.12514838576316833, "test_error": 0.0172}, {"epoch": 178, "train_loss": 0.026416002062673215, "grad_norm": 0.08217015117406845, "test_error": 0.0179}, {"epoch": 179, "train_loss": 0.0263459872854534, "grad_norm": 0.0884784609079361, "test_error": 0.0168}, {"epoch": 180, "train_loss": 0.02652304071266068, "grad_norm": 0.06871620565652847, "test_error": 0.0171}, {"epoch": 181, "train_loss": 0.026188949277299495, "grad_norm": 0.07460618764162064, "test_error": 0.0169}, {"epoch": 182, "train_loss": 0.026269821713275937, "grad_norm": 0.06875921040773392, "test_error": 0.0172}, {"epoch": 183, "train_loss": 0.026723542608728168, "grad_norm": 0.06101709604263306, "test_error": 0.0158}, {"epoch": 184, "train_loss": 0.02660351924979962, "grad_norm": 0.23154741525650024, "test_error": 0.0186}, {"epoch": 185, "train_loss": 0.026360805717199887, "grad_norm": 0.07435967028141022, "test_error": 0.0173}, {"epoch": 186, "train_loss": 0.02635824244419928, "grad_norm": 0.1432160884141922, "test_error": 0.0188}, {"epoch": 187, "train_loss": 0.026397920786417672, "grad_norm": 0.12518110871315002, "test_error": 0.0186}, {"epoch": 188, "train_loss": 0.02654128002979269, "grad_norm": 0.13259029388427734, "test_error": 0.0178}, {"epoch": 189, "train_loss": 0.026373835726238515, "grad_norm": 0.11046422272920609, "test_error": 0.0168}, {"epoch": 190, "train_loss": 0.026455357745842775, "grad_norm": 0.14455129206180573, "test_error": 0.0182}, {"epoch": 191, "train_loss": 0.026448724142169037, "grad_norm": 0.06621075421571732, "test_error": 0.0175}, {"epoch": 192, "train_loss": 0.026533759253431828, "grad_norm": 0.06725627183914185, "test_error": 0.0171}, {"epoch": 193, "train_loss": 0.026394542822580358, "grad_norm": 0.12777574360370636, "test_error": 0.0178}, {"epoch": 194, "train_loss": 0.02652262573999663, "grad_norm": 0.13704723119735718, "test_error": 0.0176}, {"epoch": 195, "train_loss": 0.02614644281514726, "grad_norm": 0.14458437263965607, "test_error": 0.018}, {"epoch": 196, "train_loss": 0.02662905720739218, "grad_norm": 0.15054082870483398, "test_error": 0.0184}, {"epoch": 197, "train_loss": 0.026306315854899974, "grad_norm": 0.0757346898317337, "test_error": 0.0173}, {"epoch": 198, "train_loss": 0.02644244494373076, "grad_norm": 0.07941203564405441, "test_error": 0.0173}, {"epoch": 199, "train_loss": 0.026209772461889467, "grad_norm": 0.0822310671210289, "test_error": 0.018}, {"epoch": 200, "train_loss": 0.026352764083562456, "grad_norm": 0.09653015434741974, "test_error": 0.0171}, {"epoch": 201, "train_loss": 0.02648391713873813, "grad_norm": 0.07577133923768997, "test_error": 0.0169}, {"epoch": 202, "train_loss": 0.026304609649732205, "grad_norm": 0.11588498950004578, "test_error": 0.017}, {"epoch": 203, "train_loss": 0.026321194397838553, "grad_norm": 0.07421945780515671, "test_error": 0.0172}, {"epoch": 204, "train_loss": 0.026653235227226103, "grad_norm": 0.11602108180522919, "test_error": 0.0168}, {"epoch": 205, "train_loss": 0.02624277074313189, "grad_norm": 0.0791364386677742, "test_error": 0.0165}, {"epoch": 206, "train_loss": 0.0262422980965542, "grad_norm": 0.08394517004489899, "test_error": 0.0171}, {"epoch": 207, "train_loss": 0.026108744724658513, "grad_norm": 0.09213408827781677, "test_error": 0.0169}, {"epoch": 208, "train_loss": 0.02642497959083994, "grad_norm": 0.0985463336110115, "test_error": 0.0175}, {"epoch": 209, "train_loss": 0.026370505960958933, "grad_norm": 0.04611952230334282, "test_error": 0.0168}, {"epoch": 210, "train_loss": 0.026414759460671726, "grad_norm": 0.153030663728714, "test_error": 0.0173}, {"epoch": 211, "train_loss": 0.026356737707794915, "grad_norm": 0.09276685863733292, "test_error": 0.0168}, {"epoch": 212, "train_loss": 0.02616163619524256, "grad_norm": 0.09673097729682922, "test_error": 0.0173}, {"epoch": 213, "train_loss": 0.026540097018844487, "grad_norm": 0.059329740703105927, "test_error": 0.016}, {"epoch": 214, "train_loss": 0.02602788735829866, "grad_norm": 0.0867558941245079, "test_error": 0.0169}, {"epoch": 215, "train_loss": 0.026366069231842024, "grad_norm": 0.08707955479621887, "test_error": 0.0179}, {"epoch": 216, "train_loss": 0.026279432406600488, "grad_norm": 0.08550379425287247, "test_error": 0.0178}, {"epoch": 217, "train_loss": 0.026182791863214032, "grad_norm": 0.1435888409614563, "test_error": 0.0172}, {"epoch": 218, "train_loss": 0.026261338570351653, "grad_norm": 0.0867607593536377, "test_error": 0.0168}, {"epoch": 219, "train_loss": 0.026073754714001553, "grad_norm": 0.07436665892601013, "test_error": 0.0167}, {"epoch": 220, "train_loss": 0.026304685995108837, "grad_norm": 0.14911219477653503, "test_error": 0.0186}, {"epoch": 221, "train_loss": 0.02632509385656158, "grad_norm": 0.10934387147426605, "test_error": 0.0162}, {"epoch": 222, "train_loss": 0.0264231235528423, "grad_norm": 0.07543759793043137, "test_error": 0.0174}, {"epoch": 223, "train_loss": 0.026284997789155266, "grad_norm": 0.07504742592573166, "test_error": 0.0176}, {"epoch": 224, "train_loss": 0.026261254893984492, "grad_norm": 0.15087473392486572, "test_error": 0.0174}, {"epoch": 225, "train_loss": 0.026244200202801344, "grad_norm": 0.07841038703918457, "test_error": 0.0155}, {"epoch": 226, "train_loss": 0.02625186080536514, "grad_norm": 0.1425025910139084, "test_error": 0.0175}, {"epoch": 227, "train_loss": 0.026172011323758244, "grad_norm": 0.07868867367506027, "test_error": 0.0181}, {"epoch": 228, "train_loss": 0.026184842711261203, "grad_norm": 0.09959331154823303, "test_error": 0.0172}, {"epoch": 229, "train_loss": 0.026173757278893997, "grad_norm": 0.10335744172334671, "test_error": 0.0164}, {"epoch": 230, "train_loss": 0.02639304187654731, "grad_norm": 0.06920496374368668, "test_error": 0.0167}, {"epoch": 231, "train_loss": 0.026205128287605475, "grad_norm": 0.10110314190387726, "test_error": 0.0178}, {"epoch": 232, "train_loss": 0.026154866142508885, "grad_norm": 0.0762910395860672, "test_error": 0.0166}, {"epoch": 233, "train_loss": 0.025925540864797463, "grad_norm": 0.08728725463151932, "test_error": 0.0179}, {"epoch": 234, "train_loss": 0.026006939142476766, "grad_norm": 0.08818847686052322, "test_error": 0.0171}, {"epoch": 235, "train_loss": 0.026369319007714997, "grad_norm": 0.07219018787145615, "test_error": 0.0169}, {"epoch": 236, "train_loss": 0.026111018582819574, "grad_norm": 0.07940016686916351, "test_error": 0.0169}, {"epoch": 237, "train_loss": 0.02625022971283761, "grad_norm": 0.10205606371164322, "test_error": 0.0173}, {"epoch": 238, "train_loss": 0.026390000366477276, "grad_norm": 0.126994788646698, "test_error": 0.0162}, {"epoch": 239, "train_loss": 0.026325696065706627, "grad_norm": 0.0615566186606884, "test_error": 0.0161}, {"epoch": 240, "train_loss": 0.0261928569740024, "grad_norm": 0.13612310588359833, "test_error": 0.0175}, {"epoch": 241, "train_loss": 0.02598802190682909, "grad_norm": 0.09713029116392136, "test_error": 0.017}, {"epoch": 242, "train_loss": 0.025990318451270773, "grad_norm": 0.12649968266487122, "test_error": 0.0172}, {"epoch": 243, "train_loss": 0.0260975691606994, "grad_norm": 0.07023688405752182, "test_error": 0.0168}, {"epoch": 244, "train_loss": 0.026160247662308393, "grad_norm": 0.051883891224861145, "test_error": 0.0171}, {"epoch": 245, "train_loss": 0.02610343448780865, "grad_norm": 0.10647507011890411, "test_error": 0.0167}, {"epoch": 246, "train_loss": 0.026373282027818884, "grad_norm": 0.04903264716267586, "test_error": 0.0162}, {"epoch": 247, "train_loss": 0.026023605015628466, "grad_norm": 0.08093169331550598, "test_error": 0.0176}, {"epoch": 248, "train_loss": 0.02602916054476615, "grad_norm": 0.10126399248838425, "test_error": 0.0176}, {"epoch": 249, "train_loss": 0.02609806838980876, "grad_norm": 0.07164900004863739, "test_error": 0.0168}, {"epoch": 250, "train_loss": 0.026202877986521343, "grad_norm": 0.20092329382896423, "test_error": 0.0182}, {"epoch": 251, "train_loss": 0.025998520997323794, "grad_norm": 0.11304726451635361, "test_error": 0.0169}, {"epoch": 252, "train_loss": 0.026170988578388156, "grad_norm": 0.08297958225011826, "test_error": 0.0165}, {"epoch": 253, "train_loss": 0.026129305161521187, "grad_norm": 0.06267135590314865, "test_error": 0.0154}, {"epoch": 254, "train_loss": 0.026342951767828103, "grad_norm": 0.06257953494787216, "test_error": 0.0176}, {"epoch": 255, "train_loss": 0.025904267188253775, "grad_norm": 0.10894504934549332, "test_error": 0.0171}, {"epoch": 256, "train_loss": 0.025871491948787784, "grad_norm": 0.1610763520002365, "test_error": 0.0177}, {"epoch": 257, "train_loss": 0.026215767472042597, "grad_norm": 0.09313514828681946, "test_error": 0.017}, {"epoch": 258, "train_loss": 0.025959895391958223, "grad_norm": 0.147283136844635, "test_error": 0.0188}, {"epoch": 259, "train_loss": 0.0260322500874269, "grad_norm": 0.04918621852993965, "test_error": 0.0159}, {"epoch": 260, "train_loss": 0.026026962103938178, "grad_norm": 0.05821283161640167, "test_error": 0.0173}, {"epoch": 261, "train_loss": 0.026043253870224967, "grad_norm": 0.057672783732414246, "test_error": 0.0167}, {"epoch": 262, "train_loss": 0.025933193551934287, "grad_norm": 0.1454429030418396, "test_error": 0.0181}, {"epoch": 263, "train_loss": 0.026218941674058444, "grad_norm": 0.13076072931289673, "test_error": 0.0182}, {"epoch": 264, "train_loss": 0.025994178284568382, "grad_norm": 0.1368732452392578, "test_error": 0.0179}, {"epoch": 265, "train_loss": 0.026024445435483358, "grad_norm": 0.11849009245634079, "test_error": 0.0176}, {"epoch": 266, "train_loss": 0.025870344980008668, "grad_norm": 0.08707378059625626, "test_error": 0.0172}, {"epoch": 267, "train_loss": 0.02611983318279575, "grad_norm": 0.10395212471485138, "test_error": 0.0169}, {"epoch": 268, "train_loss": 0.026024570995252967, "grad_norm": 0.1406088024377823, "test_error": 0.0177}, {"epoch": 269, "train_loss": 0.025701271231553014, "grad_norm": 0.1223512589931488, "test_error": 0.0184}, {"epoch": 270, "train_loss": 0.02602372891214812, "grad_norm": 0.12322928011417389, "test_error": 0.0172}, {"epoch": 271, "train_loss": 0.026107383231142495, "grad_norm": 0.08315422385931015, "test_error": 0.0172}, {"epoch": 272, "train_loss": 0.02605371488671517, "grad_norm": 0.07785583287477493, "test_error": 0.0175}, {"epoch": 273, "train_loss": 0.0261695558916108, "grad_norm": 0.09635907411575317, "test_error": 0.0178}, {"epoch": 274, "train_loss": 0.026238943242989383, "grad_norm": 0.11466431617736816, "test_error": 0.0162}, {"epoch": 275, "train_loss": 0.025775423297076487, "grad_norm": 0.17975082993507385, "test_error": 0.0177}, {"epoch": 276, "train_loss": 0.025832265933364396, "grad_norm": 0.07783989608287811, "test_error": 0.0163}, {"epoch": 277, "train_loss": 0.025970553574724668, "grad_norm": 0.0886891782283783, "test_error": 0.0163}, {"epoch": 278, "train_loss": 0.025723168611347016, "grad_norm": 0.059722404927015305, "test_error": 0.0162}, {"epoch": 279, "train_loss": 0.02589364487346029, "grad_norm": 0.12129850685596466, "test_error": 0.0169}, {"epoch": 280, "train_loss": 0.026003919248151458, "grad_norm": 0.08875560015439987, "test_error": 0.0168}, {"epoch": 281, "train_loss": 0.025953137515180667, "grad_norm": 0.07626321911811829, "test_error": 0.0167}, {"epoch": 282, "train_loss": 0.026056063219575057, "grad_norm": 0.10266266763210297, "test_error": 0.0168}, {"epoch": 283, "train_loss": 0.02597370726009346, "grad_norm": 0.15512685477733612, "test_error": 0.0182}, {"epoch": 284, "train_loss": 0.02600527072609111, "grad_norm": 0.10584961622953415, "test_error": 0.0164}, {"epoch": 285, "train_loss": 0.025974246658365396, "grad_norm": 0.09397699683904648, "test_error": 0.0174}, {"epoch": 286, "train_loss": 0.026069080633232565, "grad_norm": 0.0674743503332138, "test_error": 0.0172}, {"epoch": 287, "train_loss": 0.02585715621314739, "grad_norm": 0.06547414511442184, "test_error": 0.0172}, {"epoch": 288, "train_loss": 0.026130282518191963, "grad_norm": 0.0716266855597496, "test_error": 0.0174}, {"epoch": 289, "train_loss": 0.02588895935214047, "grad_norm": 0.12767019867897034, "test_error": 0.017}, {"epoch": 290, "train_loss": 0.025908361909770368, "grad_norm": 0.11358766257762909, "test_error": 0.0176}, {"epoch": 291, "train_loss": 0.025748058968471012, "grad_norm": 0.09323950856924057, "test_error": 0.017}, {"epoch": 292, "train_loss": 0.025851408051894394, "grad_norm": 0.081388920545578, "test_error": 0.0167}, {"epoch": 293, "train_loss": 0.0259360530814641, "grad_norm": 0.10510923713445663, "test_error": 0.0171}, {"epoch": 294, "train_loss": 0.025793910124322188, "grad_norm": 0.13237926363945007, "test_error": 0.0183}, {"epoch": 295, "train_loss": 0.025917232054651927, "grad_norm": 0.16860246658325195, "test_error": 0.0187}, {"epoch": 296, "train_loss": 0.025823449974287843, "grad_norm": 0.06788881123065948, "test_error": 0.0172}, {"epoch": 297, "train_loss": 0.025724525181309823, "grad_norm": 0.1097600907087326, "test_error": 0.0178}, {"epoch": 298, "train_loss": 0.025997982508861848, "grad_norm": 0.06716623157262802, "test_error": 0.0164}, {"epoch": 299, "train_loss": 0.02593071372851167, "grad_norm": 0.09748868644237518, "test_error": 0.0162}, {"epoch": 300, "train_loss": 0.025960447936728692, "grad_norm": 0.09083660691976547, "test_error": 0.0176}]}