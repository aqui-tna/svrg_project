{"argv": ["train.py", "--seed", "79", "--optimizer", "SGD", "--run_name", "sgd_0.01.json", "--output_path", "experiments/nonconvex_mnist_deep/sgd-0.01.json", "--dataset", "MNIST", "--layer_sizes", "784", "600", "300", "10", "--batch_size", "10", "--learning_rate", "0.01", "--weight_decay", "0.001", "--num_epochs", "300", "--device", "cuda"], "args": {"seed": 79, "optimizer": "SGD", "run_name": "sgd_0.01.json", "output_path": "experiments/nonconvex_mnist_deep/sgd-0.01.json", "device": "cuda", "dataset": "MNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": false, "layer_sizes": [784, 600, 300, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.01, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 0.5630253249546513, "grad_norm": 0.2646002173423767, "test_error": 0.0746}, {"epoch": 2, "train_loss": 0.23197705434177382, "grad_norm": 0.442813903093338, "test_error": 0.0566}, {"epoch": 3, "train_loss": 0.16859440631058534, "grad_norm": 0.2423223853111267, "test_error": 0.0423}, {"epoch": 4, "train_loss": 0.1323629082562014, "grad_norm": 0.2521599531173706, "test_error": 0.0357}, {"epoch": 5, "train_loss": 0.10946654430046328, "grad_norm": 0.18608342111110687, "test_error": 0.0306}, {"epoch": 6, "train_loss": 0.09387578141666017, "grad_norm": 0.22572560608386993, "test_error": 0.0297}, {"epoch": 7, "train_loss": 0.08271531767846318, "grad_norm": 0.23653078079223633, "test_error": 0.0269}, {"epoch": 8, "train_loss": 0.07402339900109897, "grad_norm": 0.2091929167509079, "test_error": 0.0264}, {"epoch": 9, "train_loss": 0.06714821688782831, "grad_norm": 0.1408413052558899, "test_error": 0.0237}, {"epoch": 10, "train_loss": 0.061838973546017466, "grad_norm": 0.24487675726413727, "test_error": 0.0222}, {"epoch": 11, "train_loss": 0.05783060336307001, "grad_norm": 0.07061772048473358, "test_error": 0.0197}, {"epoch": 12, "train_loss": 0.05409057153736649, "grad_norm": 0.19788801670074463, "test_error": 0.0218}, {"epoch": 13, "train_loss": 0.05088071975465088, "grad_norm": 0.1463969200849533, "test_error": 0.0219}, {"epoch": 14, "train_loss": 0.04821674041208462, "grad_norm": 0.14274348318576813, "test_error": 0.0205}, {"epoch": 15, "train_loss": 0.04629316939330359, "grad_norm": 0.274245023727417, "test_error": 0.0234}, {"epoch": 16, "train_loss": 0.044350186110653646, "grad_norm": 0.16486647725105286, "test_error": 0.0222}, {"epoch": 17, "train_loss": 0.04261151291486264, "grad_norm": 0.14996671676635742, "test_error": 0.0193}, {"epoch": 18, "train_loss": 0.04151306066563605, "grad_norm": 0.13588106632232666, "test_error": 0.0203}, {"epoch": 19, "train_loss": 0.03976333816138018, "grad_norm": 0.08413273841142654, "test_error": 0.019}, {"epoch": 20, "train_loss": 0.038655089194706914, "grad_norm": 0.17862235009670258, "test_error": 0.0203}, {"epoch": 21, "train_loss": 0.03789581739670636, "grad_norm": 0.13644707202911377, "test_error": 0.0189}, {"epoch": 22, "train_loss": 0.03714785132594989, "grad_norm": 0.08994891494512558, "test_error": 0.02}, {"epoch": 23, "train_loss": 0.0363517861062622, "grad_norm": 0.12338338047266006, "test_error": 0.019}, {"epoch": 24, "train_loss": 0.035751166876749875, "grad_norm": 0.20210109651088715, "test_error": 0.0211}, {"epoch": 25, "train_loss": 0.03524029955425552, "grad_norm": 0.11027459800243378, "test_error": 0.0203}, {"epoch": 26, "train_loss": 0.03448053853445163, "grad_norm": 0.11788947135210037, "test_error": 0.0189}, {"epoch": 27, "train_loss": 0.03415130192334861, "grad_norm": 0.08256255835294724, "test_error": 0.0171}, {"epoch": 28, "train_loss": 0.033749694875407535, "grad_norm": 0.11760319769382477, "test_error": 0.0186}, {"epoch": 29, "train_loss": 0.03327739741519811, "grad_norm": 0.13595815002918243, "test_error": 0.0187}, {"epoch": 30, "train_loss": 0.03272865791294801, "grad_norm": 0.1844351887702942, "test_error": 0.0192}, {"epoch": 31, "train_loss": 0.0326516533219595, "grad_norm": 0.15641704201698303, "test_error": 0.0183}, {"epoch": 32, "train_loss": 0.03242167432896773, "grad_norm": 0.10524832457304001, "test_error": 0.0179}, {"epoch": 33, "train_loss": 0.032176349583814344, "grad_norm": 0.09628527611494064, "test_error": 0.0185}, {"epoch": 34, "train_loss": 0.03172761733203273, "grad_norm": 0.29796674847602844, "test_error": 0.021}, {"epoch": 35, "train_loss": 0.031557815611702004, "grad_norm": 0.10563007742166519, "test_error": 0.0174}, {"epoch": 36, "train_loss": 0.03120739639012997, "grad_norm": 0.09227332472801208, "test_error": 0.0191}, {"epoch": 37, "train_loss": 0.03116044860695062, "grad_norm": 0.1081671267747879, "test_error": 0.0178}, {"epoch": 38, "train_loss": 0.031060618686227826, "grad_norm": 0.10027644783258438, "test_error": 0.0178}, {"epoch": 39, "train_loss": 0.030529815196748435, "grad_norm": 0.16998136043548584, "test_error": 0.0191}, {"epoch": 40, "train_loss": 0.030300862310143808, "grad_norm": 0.11034074425697327, "test_error": 0.0183}, {"epoch": 41, "train_loss": 0.030662897271564966, "grad_norm": 0.19498085975646973, "test_error": 0.0177}, {"epoch": 42, "train_loss": 0.03029925448007028, "grad_norm": 0.10653500258922577, "test_error": 0.0182}, {"epoch": 43, "train_loss": 0.030155303697606238, "grad_norm": 0.06939537823200226, "test_error": 0.0179}, {"epoch": 44, "train_loss": 0.030176025265318457, "grad_norm": 0.103784941136837, "test_error": 0.018}, {"epoch": 45, "train_loss": 0.029979628265306625, "grad_norm": 0.0837940126657486, "test_error": 0.0168}, {"epoch": 46, "train_loss": 0.029794846811938138, "grad_norm": 0.12219810485839844, "test_error": 0.0179}, {"epoch": 47, "train_loss": 0.02998405552253098, "grad_norm": 0.09575437754392624, "test_error": 0.018}, {"epoch": 48, "train_loss": 0.02962335920149538, "grad_norm": 0.16384254395961761, "test_error": 0.02}, {"epoch": 49, "train_loss": 0.0297034356216609, "grad_norm": 0.08265809714794159, "test_error": 0.0173}, {"epoch": 50, "train_loss": 0.029231345377886707, "grad_norm": 0.10043027997016907, "test_error": 0.018}, {"epoch": 51, "train_loss": 0.02933439606355872, "grad_norm": 0.09381194412708282, "test_error": 0.0169}, {"epoch": 52, "train_loss": 0.029176300603988542, "grad_norm": 0.19513759016990662, "test_error": 0.0183}, {"epoch": 53, "train_loss": 0.029064477235583277, "grad_norm": 0.12096352130174637, "test_error": 0.018}, {"epoch": 54, "train_loss": 0.028791300583058423, "grad_norm": 0.09303369373083115, "test_error": 0.0171}, {"epoch": 55, "train_loss": 0.029325284282521655, "grad_norm": 0.11667205393314362, "test_error": 0.0182}, {"epoch": 56, "train_loss": 0.028949362152973966, "grad_norm": 0.14654192328453064, "test_error": 0.0173}, {"epoch": 57, "train_loss": 0.028946838235793016, "grad_norm": 0.09007012844085693, "test_error": 0.0179}, {"epoch": 58, "train_loss": 0.028740655213046314, "grad_norm": 0.0966530591249466, "test_error": 0.0179}, {"epoch": 59, "train_loss": 0.028628332741121993, "grad_norm": 0.1330544501543045, "test_error": 0.0177}, {"epoch": 60, "train_loss": 0.028665033362582713, "grad_norm": 0.09518559277057648, "test_error": 0.0173}, {"epoch": 61, "train_loss": 0.028670621238779857, "grad_norm": 0.0888662114739418, "test_error": 0.0173}, {"epoch": 62, "train_loss": 0.028477771042647267, "grad_norm": 0.08495868742465973, "test_error": 0.0166}, {"epoch": 63, "train_loss": 0.028685476852280165, "grad_norm": 0.06580895930528641, "test_error": 0.0172}, {"epoch": 64, "train_loss": 0.028290272443249706, "grad_norm": 0.10991749912500381, "test_error": 0.0163}, {"epoch": 65, "train_loss": 0.02844364782901539, "grad_norm": 0.11721282452344894, "test_error": 0.0179}, {"epoch": 66, "train_loss": 0.028594553417392792, "grad_norm": 0.12714838981628418, "test_error": 0.0173}, {"epoch": 67, "train_loss": 0.028487873134203257, "grad_norm": 0.04944269731640816, "test_error": 0.0158}, {"epoch": 68, "train_loss": 0.02818479425777817, "grad_norm": 0.08429411798715591, "test_error": 0.0176}, {"epoch": 69, "train_loss": 0.028238521977255005, "grad_norm": 0.09357284009456635, "test_error": 0.0175}, {"epoch": 70, "train_loss": 0.02811653577228329, "grad_norm": 0.09409530460834503, "test_error": 0.0172}, {"epoch": 71, "train_loss": 0.02808800359632005, "grad_norm": 0.1101340502500534, "test_error": 0.0177}, {"epoch": 72, "train_loss": 0.028217076267760908, "grad_norm": 0.11308138072490692, "test_error": 0.0168}, {"epoch": 73, "train_loss": 0.02801921605199944, "grad_norm": 0.05789710208773613, "test_error": 0.0179}, {"epoch": 74, "train_loss": 0.027722232083860338, "grad_norm": 0.14730145037174225, "test_error": 0.017}, {"epoch": 75, "train_loss": 0.027955110344053537, "grad_norm": 0.173976868391037, "test_error": 0.0175}, {"epoch": 76, "train_loss": 0.02795391052129465, "grad_norm": 0.1795552521944046, "test_error": 0.0181}, {"epoch": 77, "train_loss": 0.028224004711936382, "grad_norm": 0.08508028835058212, "test_error": 0.0166}, {"epoch": 78, "train_loss": 0.02800417128209665, "grad_norm": 0.09188050776720047, "test_error": 0.0167}, {"epoch": 79, "train_loss": 0.02800489584960451, "grad_norm": 0.1432187259197235, "test_error": 0.0176}, {"epoch": 80, "train_loss": 0.028009547319782238, "grad_norm": 0.10540030151605606, "test_error": 0.0171}, {"epoch": 81, "train_loss": 0.028008650047711855, "grad_norm": 0.11386553943157196, "test_error": 0.0166}, {"epoch": 82, "train_loss": 0.027835119629715337, "grad_norm": 0.14093473553657532, "test_error": 0.0191}, {"epoch": 83, "train_loss": 0.027802208749242708, "grad_norm": 0.13445986807346344, "test_error": 0.0171}, {"epoch": 84, "train_loss": 0.027832678092536905, "grad_norm": 0.20944124460220337, "test_error": 0.019}, {"epoch": 85, "train_loss": 0.027826160552142633, "grad_norm": 0.1574009358882904, "test_error": 0.0191}, {"epoch": 86, "train_loss": 0.027880850527149354, "grad_norm": 0.11441541463136673, "test_error": 0.0176}, {"epoch": 87, "train_loss": 0.027662645147996955, "grad_norm": 0.1393166184425354, "test_error": 0.0169}, {"epoch": 88, "train_loss": 0.027928770479258673, "grad_norm": 0.23093681037425995, "test_error": 0.0188}, {"epoch": 89, "train_loss": 0.027855015179457647, "grad_norm": 0.09920258820056915, "test_error": 0.0175}, {"epoch": 90, "train_loss": 0.027567183463344313, "grad_norm": 0.10669506341218948, "test_error": 0.0181}, {"epoch": 91, "train_loss": 0.027832220841424716, "grad_norm": 0.1138642206788063, "test_error": 0.017}, {"epoch": 92, "train_loss": 0.027391506646257766, "grad_norm": 0.19514070451259613, "test_error": 0.0177}, {"epoch": 93, "train_loss": 0.02741810587642249, "grad_norm": 0.238777294754982, "test_error": 0.0207}, {"epoch": 94, "train_loss": 0.02763518454793666, "grad_norm": 0.126155823469162, "test_error": 0.018}, {"epoch": 95, "train_loss": 0.02738382030230908, "grad_norm": 0.18744049966335297, "test_error": 0.0195}, {"epoch": 96, "train_loss": 0.027321898193054948, "grad_norm": 0.16674719750881195, "test_error": 0.018}, {"epoch": 97, "train_loss": 0.027583403213677228, "grad_norm": 0.08640129119157791, "test_error": 0.0165}, {"epoch": 98, "train_loss": 0.027404966823965274, "grad_norm": 0.1352861225605011, "test_error": 0.0179}, {"epoch": 99, "train_loss": 0.02736246106769249, "grad_norm": 0.11917106807231903, "test_error": 0.0175}, {"epoch": 100, "train_loss": 0.027336774809762574, "grad_norm": 0.10702143609523773, "test_error": 0.0172}, {"epoch": 101, "train_loss": 0.02735053816585666, "grad_norm": 0.2015838474035263, "test_error": 0.019}, {"epoch": 102, "train_loss": 0.027456062172190286, "grad_norm": 0.07659853994846344, "test_error": 0.0175}, {"epoch": 103, "train_loss": 0.027436270762686035, "grad_norm": 0.15890681743621826, "test_error": 0.0186}, {"epoch": 104, "train_loss": 0.027543443387927254, "grad_norm": 0.07285138964653015, "test_error": 0.0164}, {"epoch": 105, "train_loss": 0.027158566644468616, "grad_norm": 0.25098946690559387, "test_error": 0.0181}, {"epoch": 106, "train_loss": 0.027243539398121356, "grad_norm": 0.1071089506149292, "test_error": 0.0172}, {"epoch": 107, "train_loss": 0.027284738353574842, "grad_norm": 0.07005120068788528, "test_error": 0.0177}, {"epoch": 108, "train_loss": 0.027371778821446546, "grad_norm": 0.09066997468471527, "test_error": 0.0179}, {"epoch": 109, "train_loss": 0.027162951110930103, "grad_norm": 0.09291960299015045, "test_error": 0.0181}, {"epoch": 110, "train_loss": 0.027241712754257606, "grad_norm": 0.0771324560046196, "test_error": 0.0165}, {"epoch": 111, "train_loss": 0.027225164906466186, "grad_norm": 0.18015992641448975, "test_error": 0.0169}, {"epoch": 112, "train_loss": 0.027294161164963346, "grad_norm": 0.13766761124134064, "test_error": 0.0162}, {"epoch": 113, "train_loss": 0.02714044433753588, "grad_norm": 0.19318930804729462, "test_error": 0.0184}, {"epoch": 114, "train_loss": 0.0273721964070913, "grad_norm": 0.15425769984722137, "test_error": 0.0159}, {"epoch": 115, "train_loss": 0.027427021264307162, "grad_norm": 0.15776881575584412, "test_error": 0.0189}, {"epoch": 116, "train_loss": 0.027393983652475678, "grad_norm": 0.06146954745054245, "test_error": 0.0166}, {"epoch": 117, "train_loss": 0.02718513308070639, "grad_norm": 0.07749612629413605, "test_error": 0.0181}, {"epoch": 118, "train_loss": 0.027228853770002993, "grad_norm": 0.13825157284736633, "test_error": 0.0183}, {"epoch": 119, "train_loss": 0.027227664490647535, "grad_norm": 0.07032114267349243, "test_error": 0.0169}, {"epoch": 120, "train_loss": 0.027234127621210063, "grad_norm": 0.16096094250679016, "test_error": 0.0184}, {"epoch": 121, "train_loss": 0.027018145541708994, "grad_norm": 0.09728866070508957, "test_error": 0.0175}, {"epoch": 122, "train_loss": 0.027105314116148898, "grad_norm": 0.20505908131599426, "test_error": 0.017}, {"epoch": 123, "train_loss": 0.02711877539442988, "grad_norm": 0.09812682121992111, "test_error": 0.0169}, {"epoch": 124, "train_loss": 0.026789762105365905, "grad_norm": 0.2512282431125641, "test_error": 0.0181}, {"epoch": 125, "train_loss": 0.02699876219003636, "grad_norm": 0.13196127116680145, "test_error": 0.0177}, {"epoch": 126, "train_loss": 0.02699260474217105, "grad_norm": 0.048727527260780334, "test_error": 0.0169}, {"epoch": 127, "train_loss": 0.027058333448148914, "grad_norm": 0.15643848478794098, "test_error": 0.018}, {"epoch": 128, "train_loss": 0.0268087293421025, "grad_norm": 0.17090429365634918, "test_error": 0.0173}, {"epoch": 129, "train_loss": 0.027147811029407116, "grad_norm": 0.1425795555114746, "test_error": 0.0185}, {"epoch": 130, "train_loss": 0.026756565175868066, "grad_norm": 0.14781548082828522, "test_error": 0.017}, {"epoch": 131, "train_loss": 0.027204315161941245, "grad_norm": 0.0706467553973198, "test_error": 0.0174}, {"epoch": 132, "train_loss": 0.026930929640463244, "grad_norm": 0.0897529348731041, "test_error": 0.0178}, {"epoch": 133, "train_loss": 0.026983725126561088, "grad_norm": 0.057230960577726364, "test_error": 0.0164}, {"epoch": 134, "train_loss": 0.027168459112930577, "grad_norm": 0.09700428694486618, "test_error": 0.0173}, {"epoch": 135, "train_loss": 0.02669147921109834, "grad_norm": 0.12001436203718185, "test_error": 0.0164}, {"epoch": 136, "train_loss": 0.027111988830098806, "grad_norm": 0.2807639241218567, "test_error": 0.0196}, {"epoch": 137, "train_loss": 0.026985818434729785, "grad_norm": 0.12738937139511108, "test_error": 0.0188}, {"epoch": 138, "train_loss": 0.0268776032494546, "grad_norm": 0.2671491205692291, "test_error": 0.0208}, {"epoch": 139, "train_loss": 0.026973311605814766, "grad_norm": 0.13740280270576477, "test_error": 0.0176}, {"epoch": 140, "train_loss": 0.026993425449623222, "grad_norm": 0.09281917661428452, "test_error": 0.0169}, {"epoch": 141, "train_loss": 0.02669016563881693, "grad_norm": 0.15241673588752747, "test_error": 0.018}, {"epoch": 142, "train_loss": 0.026690855719246124, "grad_norm": 0.17109213769435883, "test_error": 0.0186}, {"epoch": 143, "train_loss": 0.026749803942938646, "grad_norm": 0.07192244380712509, "test_error": 0.0168}, {"epoch": 144, "train_loss": 0.02682840783103408, "grad_norm": 0.14674018323421478, "test_error": 0.017}, {"epoch": 145, "train_loss": 0.02685062613589495, "grad_norm": 0.12237909436225891, "test_error": 0.0178}, {"epoch": 146, "train_loss": 0.026559336364732494, "grad_norm": 0.07499933987855911, "test_error": 0.0162}, {"epoch": 147, "train_loss": 0.026780488980628434, "grad_norm": 0.11980821937322617, "test_error": 0.0186}, {"epoch": 148, "train_loss": 0.026825074106808944, "grad_norm": 0.09503351897001266, "test_error": 0.0176}, {"epoch": 149, "train_loss": 0.026959189820438042, "grad_norm": 0.13240011036396027, "test_error": 0.0194}, {"epoch": 150, "train_loss": 0.02648581223420236, "grad_norm": 0.08929433673620224, "test_error": 0.0163}, {"epoch": 151, "train_loss": 0.027026246610155794, "grad_norm": 0.157669335603714, "test_error": 0.0189}, {"epoch": 152, "train_loss": 0.026492954797150258, "grad_norm": 0.13918790221214294, "test_error": 0.0185}, {"epoch": 153, "train_loss": 0.026600618944047406, "grad_norm": 0.10548453778028488, "test_error": 0.0172}, {"epoch": 154, "train_loss": 0.026820268343697534, "grad_norm": 0.12878473103046417, "test_error": 0.0169}, {"epoch": 155, "train_loss": 0.026634482001992487, "grad_norm": 0.1404516100883484, "test_error": 0.0183}, {"epoch": 156, "train_loss": 0.026673148492215356, "grad_norm": 0.10123568773269653, "test_error": 0.0157}, {"epoch": 157, "train_loss": 0.026808892707683604, "grad_norm": 0.1872808188199997, "test_error": 0.0181}, {"epoch": 158, "train_loss": 0.026793358196659633, "grad_norm": 0.09048792719841003, "test_error": 0.0175}, {"epoch": 159, "train_loss": 0.02661772435163342, "grad_norm": 0.10571051388978958, "test_error": 0.0161}, {"epoch": 160, "train_loss": 0.026834858564989798, "grad_norm": 0.11692960560321808, "test_error": 0.0169}, {"epoch": 161, "train_loss": 0.02637085251441264, "grad_norm": 0.08002273738384247, "test_error": 0.016}, {"epoch": 162, "train_loss": 0.026682225331380323, "grad_norm": 0.0852218046784401, "test_error": 0.0176}, {"epoch": 163, "train_loss": 0.026650578805885745, "grad_norm": 0.1880880743265152, "test_error": 0.0167}, {"epoch": 164, "train_loss": 0.02678033044001495, "grad_norm": 0.09588181972503662, "test_error": 0.0181}, {"epoch": 165, "train_loss": 0.026741139687389174, "grad_norm": 0.0860910639166832, "test_error": 0.0169}, {"epoch": 166, "train_loss": 0.026428291260580106, "grad_norm": 0.08276698738336563, "test_error": 0.0179}, {"epoch": 167, "train_loss": 0.02650374248270964, "grad_norm": 0.11552104353904724, "test_error": 0.0167}, {"epoch": 168, "train_loss": 0.026674375689108274, "grad_norm": 0.13893572986125946, "test_error": 0.0184}, {"epoch": 169, "train_loss": 0.026714758303462684, "grad_norm": 0.0982375219464302, "test_error": 0.0173}, {"epoch": 170, "train_loss": 0.02642588239836429, "grad_norm": 0.06905660033226013, "test_error": 0.0163}, {"epoch": 171, "train_loss": 0.026855810099383235, "grad_norm": 0.10182694345712662, "test_error": 0.0158}, {"epoch": 172, "train_loss": 0.02629177801680877, "grad_norm": 0.14875423908233643, "test_error": 0.0168}, {"epoch": 173, "train_loss": 0.026547650294814956, "grad_norm": 0.18925750255584717, "test_error": 0.0179}, {"epoch": 174, "train_loss": 0.026705868288006362, "grad_norm": 0.1383599042892456, "test_error": 0.0179}, {"epoch": 175, "train_loss": 0.026569781320620676, "grad_norm": 0.13468416035175323, "test_error": 0.0176}, {"epoch": 176, "train_loss": 0.02664165474597636, "grad_norm": 0.09964954853057861, "test_error": 0.016}, {"epoch": 177, "train_loss": 0.02654310178056767, "grad_norm": 0.08631106466054916, "test_error": 0.0157}, {"epoch": 178, "train_loss": 0.026698929978447267, "grad_norm": 0.14908629655838013, "test_error": 0.0178}, {"epoch": 179, "train_loss": 0.02652261624750099, "grad_norm": 0.0847240462899208, "test_error": 0.017}, {"epoch": 180, "train_loss": 0.026299561255946173, "grad_norm": 0.10569310933351517, "test_error": 0.0173}, {"epoch": 181, "train_loss": 0.026634323252306785, "grad_norm": 0.07348695397377014, "test_error": 0.017}, {"epoch": 182, "train_loss": 0.026701951680559433, "grad_norm": 0.06539173424243927, "test_error": 0.0163}, {"epoch": 183, "train_loss": 0.0266733179804869, "grad_norm": 0.11694223433732986, "test_error": 0.0163}, {"epoch": 184, "train_loss": 0.026547723476813796, "grad_norm": 0.09544111043214798, "test_error": 0.0178}, {"epoch": 185, "train_loss": 0.026632791683024456, "grad_norm": 0.1250254511833191, "test_error": 0.0179}, {"epoch": 186, "train_loss": 0.02653972817992326, "grad_norm": 0.16305461525917053, "test_error": 0.0178}, {"epoch": 187, "train_loss": 0.026524654071040762, "grad_norm": 0.07097367942333221, "test_error": 0.0172}, {"epoch": 188, "train_loss": 0.02622895663837941, "grad_norm": 0.085988350212574, "test_error": 0.017}, {"epoch": 189, "train_loss": 0.026251681357394165, "grad_norm": 0.08687977492809296, "test_error": 0.0171}, {"epoch": 190, "train_loss": 0.026322225612738597, "grad_norm": 0.10284747183322906, "test_error": 0.0174}, {"epoch": 191, "train_loss": 0.026250547938873447, "grad_norm": 0.10895401984453201, "test_error": 0.018}, {"epoch": 192, "train_loss": 0.026438178952012094, "grad_norm": 0.10468512028455734, "test_error": 0.0172}, {"epoch": 193, "train_loss": 0.026240049042321818, "grad_norm": 0.07617518305778503, "test_error": 0.018}, {"epoch": 194, "train_loss": 0.02638226465778765, "grad_norm": 0.11260998249053955, "test_error": 0.0173}, {"epoch": 195, "train_loss": 0.026270467538110097, "grad_norm": 0.10928130894899368, "test_error": 0.0171}, {"epoch": 196, "train_loss": 0.026343866590585095, "grad_norm": 0.08840177208185196, "test_error": 0.0172}, {"epoch": 197, "train_loss": 0.026630172699554047, "grad_norm": 0.07523789256811142, "test_error": 0.0164}, {"epoch": 198, "train_loss": 0.02656560460817612, "grad_norm": 0.09466241300106049, "test_error": 0.018}, {"epoch": 199, "train_loss": 0.026393341607768284, "grad_norm": 0.12003400176763535, "test_error": 0.0174}, {"epoch": 200, "train_loss": 0.026520392041973536, "grad_norm": 0.17562556266784668, "test_error": 0.0188}, {"epoch": 201, "train_loss": 0.02620104984585002, "grad_norm": 0.10543353110551834, "test_error": 0.0163}, {"epoch": 202, "train_loss": 0.026242548965320262, "grad_norm": 0.05611613020300865, "test_error": 0.0168}, {"epoch": 203, "train_loss": 0.026276635238464224, "grad_norm": 0.12293818593025208, "test_error": 0.0173}, {"epoch": 204, "train_loss": 0.0262672985940153, "grad_norm": 0.13883091509342194, "test_error": 0.017}, {"epoch": 205, "train_loss": 0.02639002157194773, "grad_norm": 0.10064423084259033, "test_error": 0.0168}, {"epoch": 206, "train_loss": 0.026246258664420263, "grad_norm": 0.12674769759178162, "test_error": 0.0185}, {"epoch": 207, "train_loss": 0.026455879807976694, "grad_norm": 0.059840817004442215, "test_error": 0.0165}, {"epoch": 208, "train_loss": 0.026266988539864543, "grad_norm": 0.06051445007324219, "test_error": 0.0178}, {"epoch": 209, "train_loss": 0.026511526796855228, "grad_norm": 0.08048547059297562, "test_error": 0.0168}, {"epoch": 210, "train_loss": 0.02638491140883222, "grad_norm": 0.17061278223991394, "test_error": 0.0179}, {"epoch": 211, "train_loss": 0.02616344561772712, "grad_norm": 0.16670921444892883, "test_error": 0.0191}, {"epoch": 212, "train_loss": 0.02646946782429586, "grad_norm": 0.09417222440242767, "test_error": 0.0161}, {"epoch": 213, "train_loss": 0.026446244552455027, "grad_norm": 0.06577672809362411, "test_error": 0.0175}, {"epoch": 214, "train_loss": 0.02631430246528665, "grad_norm": 0.11810099333524704, "test_error": 0.0173}, {"epoch": 215, "train_loss": 0.026383466483132605, "grad_norm": 0.09717884659767151, "test_error": 0.0164}, {"epoch": 216, "train_loss": 0.026227155042196196, "grad_norm": 0.14198975265026093, "test_error": 0.0163}, {"epoch": 217, "train_loss": 0.026230282638546973, "grad_norm": 0.06170882657170296, "test_error": 0.0161}, {"epoch": 218, "train_loss": 0.0265112639423484, "grad_norm": 0.12897296249866486, "test_error": 0.0192}, {"epoch": 219, "train_loss": 0.026186714779929995, "grad_norm": 0.06297511607408524, "test_error": 0.0163}, {"epoch": 220, "train_loss": 0.026349312681995796, "grad_norm": 0.08929982036352158, "test_error": 0.0169}, {"epoch": 221, "train_loss": 0.026398137376158655, "grad_norm": 0.15440614521503448, "test_error": 0.0163}, {"epoch": 222, "train_loss": 0.02625467057975766, "grad_norm": 0.05219293013215065, "test_error": 0.0168}, {"epoch": 223, "train_loss": 0.02592108769251839, "grad_norm": 0.10095109045505524, "test_error": 0.0161}, {"epoch": 224, "train_loss": 0.0262723987664358, "grad_norm": 0.1333356350660324, "test_error": 0.0182}, {"epoch": 225, "train_loss": 0.02609722659027223, "grad_norm": 0.10050727427005768, "test_error": 0.018}, {"epoch": 226, "train_loss": 0.026225925288910122, "grad_norm": 0.08911870419979095, "test_error": 0.0169}, {"epoch": 227, "train_loss": 0.026359006581861952, "grad_norm": 0.0835060328245163, "test_error": 0.0168}, {"epoch": 228, "train_loss": 0.026198578420371633, "grad_norm": 0.187127023935318, "test_error": 0.0182}, {"epoch": 229, "train_loss": 0.026239045287060433, "grad_norm": 0.11090411245822906, "test_error": 0.0151}, {"epoch": 230, "train_loss": 0.026293002756952774, "grad_norm": 0.08380261063575745, "test_error": 0.0176}, {"epoch": 231, "train_loss": 0.026146251669158422, "grad_norm": 0.08831524848937988, "test_error": 0.0165}, {"epoch": 232, "train_loss": 0.02634179801181017, "grad_norm": 0.087474025785923, "test_error": 0.0161}, {"epoch": 233, "train_loss": 0.026188030971514915, "grad_norm": 0.1385999172925949, "test_error": 0.0183}, {"epoch": 234, "train_loss": 0.026149332891223214, "grad_norm": 0.06402012705802917, "test_error": 0.0162}, {"epoch": 235, "train_loss": 0.026034040958076123, "grad_norm": 0.1843697875738144, "test_error": 0.0175}, {"epoch": 236, "train_loss": 0.026240469738695538, "grad_norm": 0.04769932106137276, "test_error": 0.0168}, {"epoch": 237, "train_loss": 0.026301381404882706, "grad_norm": 0.24186235666275024, "test_error": 0.02}, {"epoch": 238, "train_loss": 0.026259117027642786, "grad_norm": 0.12924130260944366, "test_error": 0.0173}, {"epoch": 239, "train_loss": 0.0260988547715145, "grad_norm": 0.1376039832830429, "test_error": 0.0177}, {"epoch": 240, "train_loss": 0.026184786883958925, "grad_norm": 0.1398342102766037, "test_error": 0.0177}, {"epoch": 241, "train_loss": 0.0260682465233549, "grad_norm": 0.08278732001781464, "test_error": 0.0166}, {"epoch": 242, "train_loss": 0.02626051704485144, "grad_norm": 0.09673205763101578, "test_error": 0.0169}, {"epoch": 243, "train_loss": 0.02615300660187495, "grad_norm": 0.08921454101800919, "test_error": 0.0171}, {"epoch": 244, "train_loss": 0.02613539914818345, "grad_norm": 0.06568130105733871, "test_error": 0.0169}, {"epoch": 245, "train_loss": 0.02640712818622948, "grad_norm": 0.06435323506593704, "test_error": 0.0171}, {"epoch": 246, "train_loss": 0.026295682839690318, "grad_norm": 0.09775412827730179, "test_error": 0.0163}, {"epoch": 247, "train_loss": 0.026009190026939903, "grad_norm": 0.15314297378063202, "test_error": 0.0174}, {"epoch": 248, "train_loss": 0.02589008824148429, "grad_norm": 0.06924983114004135, "test_error": 0.017}, {"epoch": 249, "train_loss": 0.02593683430965272, "grad_norm": 0.08557908982038498, "test_error": 0.0169}, {"epoch": 250, "train_loss": 0.026089319278190182, "grad_norm": 0.0968928411602974, "test_error": 0.0173}, {"epoch": 251, "train_loss": 0.026071781280743986, "grad_norm": 0.09096458554267883, "test_error": 0.0164}, {"epoch": 252, "train_loss": 0.025936239934395415, "grad_norm": 0.1432674676179886, "test_error": 0.0173}, {"epoch": 253, "train_loss": 0.025771656081761952, "grad_norm": 0.1329757571220398, "test_error": 0.0177}, {"epoch": 254, "train_loss": 0.026060621266224188, "grad_norm": 0.05430359020829201, "test_error": 0.0174}, {"epoch": 255, "train_loss": 0.026043284991382584, "grad_norm": 0.10710306465625763, "test_error": 0.0169}, {"epoch": 256, "train_loss": 0.02624552591877485, "grad_norm": 0.07113827019929886, "test_error": 0.0163}, {"epoch": 257, "train_loss": 0.0259864221590445, "grad_norm": 0.10833919048309326, "test_error": 0.0175}, {"epoch": 258, "train_loss": 0.025884836171365652, "grad_norm": 0.14613227546215057, "test_error": 0.0182}, {"epoch": 259, "train_loss": 0.026148106940609674, "grad_norm": 0.1244848296046257, "test_error": 0.0163}, {"epoch": 260, "train_loss": 0.026017934647005556, "grad_norm": 0.09051629900932312, "test_error": 0.0168}, {"epoch": 261, "train_loss": 0.026109803595842095, "grad_norm": 0.351199746131897, "test_error": 0.021}, {"epoch": 262, "train_loss": 0.026295684899433885, "grad_norm": 0.054218973964452744, "test_error": 0.0164}, {"epoch": 263, "train_loss": 0.02586338830718887, "grad_norm": 0.09475666284561157, "test_error": 0.0165}, {"epoch": 264, "train_loss": 0.026060992775708048, "grad_norm": 0.14093683660030365, "test_error": 0.0179}, {"epoch": 265, "train_loss": 0.025861943170932742, "grad_norm": 0.0666649118065834, "test_error": 0.017}, {"epoch": 266, "train_loss": 0.02628140633411143, "grad_norm": 0.07311505079269409, "test_error": 0.0176}, {"epoch": 267, "train_loss": 0.02603975583415498, "grad_norm": 0.1212461069226265, "test_error": 0.0171}, {"epoch": 268, "train_loss": 0.026060080205027286, "grad_norm": 0.05914830416440964, "test_error": 0.0165}, {"epoch": 269, "train_loss": 0.02576796085357152, "grad_norm": 0.1057920977473259, "test_error": 0.0174}, {"epoch": 270, "train_loss": 0.026171207419703326, "grad_norm": 0.1734294891357422, "test_error": 0.0175}, {"epoch": 271, "train_loss": 0.02598771283915024, "grad_norm": 0.059190716594457626, "test_error": 0.0159}, {"epoch": 272, "train_loss": 0.02593611247476656, "grad_norm": 0.12607727944850922, "test_error": 0.0169}, {"epoch": 273, "train_loss": 0.02596109492779942, "grad_norm": 0.08633169531822205, "test_error": 0.0141}, {"epoch": 274, "train_loss": 0.026087415587690583, "grad_norm": 0.06366806477308273, "test_error": 0.0166}, {"epoch": 275, "train_loss": 0.02607464018245567, "grad_norm": 0.11929460614919662, "test_error": 0.0167}, {"epoch": 276, "train_loss": 0.0261669731740379, "grad_norm": 0.18067128956317902, "test_error": 0.0181}, {"epoch": 277, "train_loss": 0.026023613880451497, "grad_norm": 0.14252378046512604, "test_error": 0.0165}, {"epoch": 278, "train_loss": 0.0259283759317356, "grad_norm": 0.08494751155376434, "test_error": 0.016}, {"epoch": 279, "train_loss": 0.02579233259993392, "grad_norm": 0.05006767809391022, "test_error": 0.0156}, {"epoch": 280, "train_loss": 0.026003510930267416, "grad_norm": 0.09762316197156906, "test_error": 0.0172}, {"epoch": 281, "train_loss": 0.02577802468688363, "grad_norm": 0.10207568109035492, "test_error": 0.0165}, {"epoch": 282, "train_loss": 0.02593358975337469, "grad_norm": 0.12514740228652954, "test_error": 0.0178}, {"epoch": 283, "train_loss": 0.026047724215920123, "grad_norm": 0.21160389482975006, "test_error": 0.0184}, {"epoch": 284, "train_loss": 0.026039858530775138, "grad_norm": 0.07615412026643753, "test_error": 0.0156}, {"epoch": 285, "train_loss": 0.02610947755742624, "grad_norm": 0.10511653870344162, "test_error": 0.0174}, {"epoch": 286, "train_loss": 0.02591897183318603, "grad_norm": 0.08639764040708542, "test_error": 0.0168}, {"epoch": 287, "train_loss": 0.026040392830055985, "grad_norm": 0.07642363756895065, "test_error": 0.017}, {"epoch": 288, "train_loss": 0.025907805043578265, "grad_norm": 0.12946228682994843, "test_error": 0.0161}, {"epoch": 289, "train_loss": 0.02599358189005337, "grad_norm": 0.07829171419143677, "test_error": 0.017}, {"epoch": 290, "train_loss": 0.025892349329017936, "grad_norm": 0.0633048489689827, "test_error": 0.0166}, {"epoch": 291, "train_loss": 0.026046996553343586, "grad_norm": 0.09374493360519409, "test_error": 0.0179}, {"epoch": 292, "train_loss": 0.026090646184049545, "grad_norm": 0.12825529277324677, "test_error": 0.0164}, {"epoch": 293, "train_loss": 0.025823790677464178, "grad_norm": 0.09628720581531525, "test_error": 0.0168}, {"epoch": 294, "train_loss": 0.02589179398884638, "grad_norm": 0.09053953737020493, "test_error": 0.017}, {"epoch": 295, "train_loss": 0.026121625679152202, "grad_norm": 0.0898544192314148, "test_error": 0.0166}, {"epoch": 296, "train_loss": 0.026041970792774614, "grad_norm": 0.10310521721839905, "test_error": 0.0169}, {"epoch": 297, "train_loss": 0.02566298127919193, "grad_norm": 0.10371388494968414, "test_error": 0.0167}, {"epoch": 298, "train_loss": 0.025670400988165056, "grad_norm": 0.1504400074481964, "test_error": 0.0172}, {"epoch": 299, "train_loss": 0.025672374966144464, "grad_norm": 0.0688282698392868, "test_error": 0.0159}, {"epoch": 300, "train_loss": 0.025945614059106448, "grad_norm": 0.14072880148887634, "test_error": 0.0163}]}