{"argv": ["train.py", "--seed", "12", "--optimizer", "SGD", "--run_name", "sgd_0.1.json", "--output_path", "experiments/nonconvex_mnist_deep/sgd-0.1.json", "--dataset", "MNIST", "--layer_sizes", "784", "600", "300", "10", "--batch_size", "10", "--learning_rate", "0.1", "--weight_decay", "0.001", "--num_epochs", "300", "--device", "cuda"], "args": {"seed": 12, "optimizer": "SGD", "run_name": "sgd_0.1.json", "output_path": "experiments/nonconvex_mnist_deep/sgd-0.1.json", "device": "cuda", "dataset": "MNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": false, "layer_sizes": [784, 600, 300, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.1, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 0.24529438397746708, "grad_norm": 0.3775705099105835, "test_error": 0.047}, {"epoch": 2, "train_loss": 0.11350772227315853, "grad_norm": 0.2056940495967865, "test_error": 0.0292}, {"epoch": 3, "train_loss": 0.0988954246531066, "grad_norm": 0.19866879284381866, "test_error": 0.0297}, {"epoch": 4, "train_loss": 0.09041080081225664, "grad_norm": 0.1389821469783783, "test_error": 0.0261}, {"epoch": 5, "train_loss": 0.08777413477282486, "grad_norm": 0.17156384885311127, "test_error": 0.0282}, {"epoch": 6, "train_loss": 0.08543617111934873, "grad_norm": 0.10847146809101105, "test_error": 0.026}, {"epoch": 7, "train_loss": 0.0826413353208142, "grad_norm": 0.1753803789615631, "test_error": 0.0292}, {"epoch": 8, "train_loss": 0.08198442475479532, "grad_norm": 0.12155033648014069, "test_error": 0.0256}, {"epoch": 9, "train_loss": 0.08183333680183569, "grad_norm": 0.2585963010787964, "test_error": 0.0263}, {"epoch": 10, "train_loss": 0.08141864386115534, "grad_norm": 0.2183799147605896, "test_error": 0.0255}, {"epoch": 11, "train_loss": 0.08254485088968552, "grad_norm": 0.16217124462127686, "test_error": 0.0241}, {"epoch": 12, "train_loss": 0.08028539732250889, "grad_norm": 0.12850916385650635, "test_error": 0.0231}, {"epoch": 13, "train_loss": 0.08043655912435255, "grad_norm": 0.22539901733398438, "test_error": 0.0277}, {"epoch": 14, "train_loss": 0.07894505255279849, "grad_norm": 0.43493911623954773, "test_error": 0.0313}, {"epoch": 15, "train_loss": 0.08157823831558926, "grad_norm": 0.12226392328739166, "test_error": 0.0248}, {"epoch": 16, "train_loss": 0.0793996827651475, "grad_norm": 0.13912861049175262, "test_error": 0.0249}, {"epoch": 17, "train_loss": 0.07905337938536104, "grad_norm": 0.28864389657974243, "test_error": 0.0354}, {"epoch": 18, "train_loss": 0.07981511917179644, "grad_norm": 0.10222873836755753, "test_error": 0.0235}, {"epoch": 19, "train_loss": 0.07798721856556465, "grad_norm": 0.19539301097393036, "test_error": 0.0301}, {"epoch": 20, "train_loss": 0.08001532596605344, "grad_norm": 0.21612109243869781, "test_error": 0.0292}, {"epoch": 21, "train_loss": 0.08002980512814246, "grad_norm": 0.21715502440929413, "test_error": 0.0279}, {"epoch": 22, "train_loss": 0.07821944472867472, "grad_norm": 0.09480983763933182, "test_error": 0.0221}, {"epoch": 23, "train_loss": 0.078549909122783, "grad_norm": 0.10853101313114166, "test_error": 0.0231}, {"epoch": 24, "train_loss": 0.0796785914542561, "grad_norm": 0.20743761956691742, "test_error": 0.0264}, {"epoch": 25, "train_loss": 0.07977945446633385, "grad_norm": 0.11485235393047333, "test_error": 0.0229}, {"epoch": 26, "train_loss": 0.07943441691460612, "grad_norm": 0.17562423646450043, "test_error": 0.0272}, {"epoch": 27, "train_loss": 0.07871637871564356, "grad_norm": 0.23612801730632782, "test_error": 0.0305}, {"epoch": 28, "train_loss": 0.07998956789063717, "grad_norm": 0.1814630627632141, "test_error": 0.0251}, {"epoch": 29, "train_loss": 0.07784619841854146, "grad_norm": 0.1555609405040741, "test_error": 0.0239}, {"epoch": 30, "train_loss": 0.0789437945952183, "grad_norm": 0.15311811864376068, "test_error": 0.025}, {"epoch": 31, "train_loss": 0.07840961732297971, "grad_norm": 0.20482876896858215, "test_error": 0.0287}, {"epoch": 32, "train_loss": 0.0778804602754996, "grad_norm": 0.1979859173297882, "test_error": 0.0245}, {"epoch": 33, "train_loss": 0.0794880173230146, "grad_norm": 0.21501128375530243, "test_error": 0.0275}, {"epoch": 34, "train_loss": 0.07755319211710594, "grad_norm": 0.1419435739517212, "test_error": 0.0253}, {"epoch": 35, "train_loss": 0.07801059168032468, "grad_norm": 0.15237654745578766, "test_error": 0.0233}, {"epoch": 36, "train_loss": 0.07757224894247337, "grad_norm": 0.2367336004972458, "test_error": 0.0305}, {"epoch": 37, "train_loss": 0.08006555636178139, "grad_norm": 0.26898711919784546, "test_error": 0.0319}, {"epoch": 38, "train_loss": 0.07943908413623285, "grad_norm": 0.19912680983543396, "test_error": 0.0274}, {"epoch": 39, "train_loss": 0.07671358556327565, "grad_norm": 0.16553577780723572, "test_error": 0.0255}, {"epoch": 40, "train_loss": 0.07932930071358472, "grad_norm": 0.2331663817167282, "test_error": 0.0287}, {"epoch": 41, "train_loss": 0.07891595123758209, "grad_norm": 0.17465366423130035, "test_error": 0.0283}, {"epoch": 42, "train_loss": 0.07670951983512593, "grad_norm": 0.2426588237285614, "test_error": 0.0288}, {"epoch": 43, "train_loss": 0.07894370695658047, "grad_norm": 0.16526012122631073, "test_error": 0.0231}, {"epoch": 44, "train_loss": 0.07859295317606545, "grad_norm": 0.21904319524765015, "test_error": 0.0281}, {"epoch": 45, "train_loss": 0.07786579122883268, "grad_norm": 0.2857820689678192, "test_error": 0.0336}, {"epoch": 46, "train_loss": 0.07823705069421218, "grad_norm": 0.32051882147789, "test_error": 0.0324}, {"epoch": 47, "train_loss": 0.07728165906314098, "grad_norm": 0.21288569271564484, "test_error": 0.0292}, {"epoch": 48, "train_loss": 0.07811176212556893, "grad_norm": 0.371707558631897, "test_error": 0.0314}, {"epoch": 49, "train_loss": 0.07843314840554376, "grad_norm": 0.16103065013885498, "test_error": 0.027}, {"epoch": 50, "train_loss": 0.07761953824676554, "grad_norm": 0.41485920548439026, "test_error": 0.0385}, {"epoch": 51, "train_loss": 0.07816162580834256, "grad_norm": 0.3874681293964386, "test_error": 0.0415}, {"epoch": 52, "train_loss": 0.0791312153499748, "grad_norm": 0.3418075442314148, "test_error": 0.0379}, {"epoch": 53, "train_loss": 0.07779472287165118, "grad_norm": 0.10524231940507889, "test_error": 0.0246}, {"epoch": 54, "train_loss": 0.07885599408173584, "grad_norm": 0.11678904294967651, "test_error": 0.0249}, {"epoch": 55, "train_loss": 0.07853041663574307, "grad_norm": 0.23723691701889038, "test_error": 0.0271}, {"epoch": 56, "train_loss": 0.07829062111365298, "grad_norm": 0.24138104915618896, "test_error": 0.0313}, {"epoch": 57, "train_loss": 0.0782925253070983, "grad_norm": 0.17860223352909088, "test_error": 0.0275}, {"epoch": 58, "train_loss": 0.07803969428634082, "grad_norm": 0.1126309484243393, "test_error": 0.0231}, {"epoch": 59, "train_loss": 0.07912663193866562, "grad_norm": 0.1223851665854454, "test_error": 0.0228}, {"epoch": 60, "train_loss": 0.07892115951800467, "grad_norm": 0.1264485865831375, "test_error": 0.0239}, {"epoch": 61, "train_loss": 0.07870146566447996, "grad_norm": 0.20134852826595306, "test_error": 0.0257}, {"epoch": 62, "train_loss": 0.07747921242430068, "grad_norm": 0.1643386036157608, "test_error": 0.0253}, {"epoch": 63, "train_loss": 0.07792979121651539, "grad_norm": 0.11872841417789459, "test_error": 0.0224}, {"epoch": 64, "train_loss": 0.07753518908637246, "grad_norm": 0.1417521983385086, "test_error": 0.0269}, {"epoch": 65, "train_loss": 0.07890020579259727, "grad_norm": 0.16339555382728577, "test_error": 0.0254}, {"epoch": 66, "train_loss": 0.07842172809603654, "grad_norm": 0.1195894107222557, "test_error": 0.0223}, {"epoch": 67, "train_loss": 0.07748983989293386, "grad_norm": 0.15834598243236542, "test_error": 0.0254}, {"epoch": 68, "train_loss": 0.07962463750641958, "grad_norm": 0.13178348541259766, "test_error": 0.0219}, {"epoch": 69, "train_loss": 0.07932198424285647, "grad_norm": 0.18190635740756989, "test_error": 0.028}, {"epoch": 70, "train_loss": 0.07896709894079929, "grad_norm": 0.16381555795669556, "test_error": 0.0253}, {"epoch": 71, "train_loss": 0.07741115796959638, "grad_norm": 0.361488938331604, "test_error": 0.0331}, {"epoch": 72, "train_loss": 0.07817091136228797, "grad_norm": 0.2443191111087799, "test_error": 0.0294}, {"epoch": 73, "train_loss": 0.07923720336960105, "grad_norm": 0.2264421135187149, "test_error": 0.0261}, {"epoch": 74, "train_loss": 0.07760568903524594, "grad_norm": 0.1446632593870163, "test_error": 0.0243}, {"epoch": 75, "train_loss": 0.07697392565112386, "grad_norm": 0.3960127830505371, "test_error": 0.0381}, {"epoch": 76, "train_loss": 0.07762773151900788, "grad_norm": 0.49959632754325867, "test_error": 0.0471}, {"epoch": 77, "train_loss": 0.07840853424474578, "grad_norm": 0.37606310844421387, "test_error": 0.0353}, {"epoch": 78, "train_loss": 0.0791821505654225, "grad_norm": 0.25910547375679016, "test_error": 0.0317}, {"epoch": 79, "train_loss": 0.07854247881369278, "grad_norm": 0.14601188898086548, "test_error": 0.0232}, {"epoch": 80, "train_loss": 0.07701906324275236, "grad_norm": 0.4749833047389984, "test_error": 0.0394}, {"epoch": 81, "train_loss": 0.07887289831807479, "grad_norm": 0.20426832139492035, "test_error": 0.0264}, {"epoch": 82, "train_loss": 0.0771647065950286, "grad_norm": 0.1445218175649643, "test_error": 0.0253}, {"epoch": 83, "train_loss": 0.07803603108316019, "grad_norm": 0.14745862782001495, "test_error": 0.0267}, {"epoch": 84, "train_loss": 0.07595864468084862, "grad_norm": 0.25871047377586365, "test_error": 0.0289}, {"epoch": 85, "train_loss": 0.07786903471341551, "grad_norm": 0.17286376655101776, "test_error": 0.0248}, {"epoch": 86, "train_loss": 0.07940794410398909, "grad_norm": 0.296440988779068, "test_error": 0.0334}, {"epoch": 87, "train_loss": 0.07771241401933851, "grad_norm": 0.10573722422122955, "test_error": 0.0236}, {"epoch": 88, "train_loss": 0.077441632306276, "grad_norm": 0.19439485669136047, "test_error": 0.0278}, {"epoch": 89, "train_loss": 0.07797534179724122, "grad_norm": 0.28629544377326965, "test_error": 0.0296}, {"epoch": 90, "train_loss": 0.08010981164474167, "grad_norm": 0.11979419738054276, "test_error": 0.0242}, {"epoch": 91, "train_loss": 0.07738484504495864, "grad_norm": 0.4442959725856781, "test_error": 0.0407}, {"epoch": 92, "train_loss": 0.07835368245472636, "grad_norm": 0.2096128761768341, "test_error": 0.0279}, {"epoch": 93, "train_loss": 0.07766657983110296, "grad_norm": 0.47370535135269165, "test_error": 0.0475}, {"epoch": 94, "train_loss": 0.07773142377259258, "grad_norm": 0.0906188115477562, "test_error": 0.023}, {"epoch": 95, "train_loss": 0.07916786933414308, "grad_norm": 0.26208746433258057, "test_error": 0.0278}, {"epoch": 96, "train_loss": 0.0786931906551666, "grad_norm": 0.2487637847661972, "test_error": 0.0287}, {"epoch": 97, "train_loss": 0.07759353175884462, "grad_norm": 0.23875275254249573, "test_error": 0.03}, {"epoch": 98, "train_loss": 0.07828930073510855, "grad_norm": 0.19123604893684387, "test_error": 0.0289}, {"epoch": 99, "train_loss": 0.07762154108635393, "grad_norm": 0.2902714014053345, "test_error": 0.0337}, {"epoch": 100, "train_loss": 0.07712623531378389, "grad_norm": 0.2274457961320877, "test_error": 0.0317}, {"epoch": 101, "train_loss": 0.07813078295791152, "grad_norm": 0.2169245183467865, "test_error": 0.026}, {"epoch": 102, "train_loss": 0.0774701448649915, "grad_norm": 0.09895245730876923, "test_error": 0.0225}, {"epoch": 103, "train_loss": 0.07936546750194975, "grad_norm": 0.14413471519947052, "test_error": 0.0258}, {"epoch": 104, "train_loss": 0.07958999169987024, "grad_norm": 0.21543020009994507, "test_error": 0.0296}, {"epoch": 105, "train_loss": 0.07957549328058182, "grad_norm": 0.1555350124835968, "test_error": 0.0237}, {"epoch": 106, "train_loss": 0.07995691021797635, "grad_norm": 0.20559583604335785, "test_error": 0.0275}, {"epoch": 107, "train_loss": 0.07746457667806923, "grad_norm": 0.13124169409275055, "test_error": 0.0249}, {"epoch": 108, "train_loss": 0.07782161860151487, "grad_norm": 0.12638983130455017, "test_error": 0.0254}, {"epoch": 109, "train_loss": 0.07753187957009747, "grad_norm": 0.1623958796262741, "test_error": 0.0266}, {"epoch": 110, "train_loss": 0.07873180721917743, "grad_norm": 0.21286419034004211, "test_error": 0.0295}, {"epoch": 111, "train_loss": 0.07720325098722242, "grad_norm": 0.12840884923934937, "test_error": 0.0233}, {"epoch": 112, "train_loss": 0.0785744598169064, "grad_norm": 0.16303399205207825, "test_error": 0.0255}, {"epoch": 113, "train_loss": 0.07988095923142585, "grad_norm": 0.25684818625450134, "test_error": 0.033}, {"epoch": 114, "train_loss": 0.07758380888679434, "grad_norm": 0.13561685383319855, "test_error": 0.0265}, {"epoch": 115, "train_loss": 0.07903092944442323, "grad_norm": 0.09106135368347168, "test_error": 0.0216}, {"epoch": 116, "train_loss": 0.07826708429224527, "grad_norm": 0.08125977218151093, "test_error": 0.0194}, {"epoch": 117, "train_loss": 0.07994193601187241, "grad_norm": 0.27184638381004333, "test_error": 0.0331}, {"epoch": 118, "train_loss": 0.07784292891613828, "grad_norm": 0.18277598917484283, "test_error": 0.0263}, {"epoch": 119, "train_loss": 0.07893730468017747, "grad_norm": 0.13493242859840393, "test_error": 0.0232}, {"epoch": 120, "train_loss": 0.07755991751388258, "grad_norm": 0.1736549735069275, "test_error": 0.0261}, {"epoch": 121, "train_loss": 0.07772639056029584, "grad_norm": 0.357839971780777, "test_error": 0.036}, {"epoch": 122, "train_loss": 0.07877444928673503, "grad_norm": 0.15319515764713287, "test_error": 0.0257}, {"epoch": 123, "train_loss": 0.07880035419304476, "grad_norm": 0.2588876783847809, "test_error": 0.0282}, {"epoch": 124, "train_loss": 0.07935323384345974, "grad_norm": 0.2100459188222885, "test_error": 0.0269}, {"epoch": 125, "train_loss": 0.07986300497744621, "grad_norm": 0.3673538863658905, "test_error": 0.0359}, {"epoch": 126, "train_loss": 0.07868313615224422, "grad_norm": 0.24829638004302979, "test_error": 0.0272}, {"epoch": 127, "train_loss": 0.07822071722265295, "grad_norm": 0.1917359083890915, "test_error": 0.0281}, {"epoch": 128, "train_loss": 0.07858185861642414, "grad_norm": 0.12408959865570068, "test_error": 0.0246}, {"epoch": 129, "train_loss": 0.0780433364174678, "grad_norm": 0.1779317557811737, "test_error": 0.0256}, {"epoch": 130, "train_loss": 0.07769743420062877, "grad_norm": 0.27749332785606384, "test_error": 0.0286}, {"epoch": 131, "train_loss": 0.07899377500723737, "grad_norm": 0.13603758811950684, "test_error": 0.0249}, {"epoch": 132, "train_loss": 0.07964746706829949, "grad_norm": 0.17541401088237762, "test_error": 0.027}, {"epoch": 133, "train_loss": 0.0812472772560553, "grad_norm": 0.2600978910923004, "test_error": 0.0316}, {"epoch": 134, "train_loss": 0.07711815243317688, "grad_norm": 0.6951485276222229, "test_error": 0.0545}, {"epoch": 135, "train_loss": 0.07711435217417602, "grad_norm": 0.15408213436603546, "test_error": 0.0235}, {"epoch": 136, "train_loss": 0.08007137736484826, "grad_norm": 0.5218334794044495, "test_error": 0.0413}, {"epoch": 137, "train_loss": 0.07954332829527024, "grad_norm": 0.19953495264053345, "test_error": 0.0283}, {"epoch": 138, "train_loss": 0.08006789078580429, "grad_norm": 0.11712948977947235, "test_error": 0.0207}, {"epoch": 139, "train_loss": 0.07825625761983732, "grad_norm": 0.14211271703243256, "test_error": 0.0249}, {"epoch": 140, "train_loss": 0.0788395890971151, "grad_norm": 0.12908902764320374, "test_error": 0.0224}, {"epoch": 141, "train_loss": 0.07900840212237865, "grad_norm": 0.200452983379364, "test_error": 0.028}, {"epoch": 142, "train_loss": 0.07848801519598055, "grad_norm": 0.2296830415725708, "test_error": 0.0307}, {"epoch": 143, "train_loss": 0.07801700964770135, "grad_norm": 0.20381560921669006, "test_error": 0.0289}, {"epoch": 144, "train_loss": 0.07943158915112629, "grad_norm": 0.2872333526611328, "test_error": 0.0338}, {"epoch": 145, "train_loss": 0.07647691701223812, "grad_norm": 0.17389559745788574, "test_error": 0.0249}, {"epoch": 146, "train_loss": 0.07924130454064773, "grad_norm": 0.7333954572677612, "test_error": 0.0517}, {"epoch": 147, "train_loss": 0.07721594059590037, "grad_norm": 0.20025499165058136, "test_error": 0.028}, {"epoch": 148, "train_loss": 0.07820674024300509, "grad_norm": 0.33076146245002747, "test_error": 0.0323}, {"epoch": 149, "train_loss": 0.07995876721431584, "grad_norm": 0.14571689069271088, "test_error": 0.0225}, {"epoch": 150, "train_loss": 0.07840127652624262, "grad_norm": 0.10567885637283325, "test_error": 0.0212}, {"epoch": 151, "train_loss": 0.07911257227571575, "grad_norm": 0.1527981013059616, "test_error": 0.0241}, {"epoch": 152, "train_loss": 0.07922416690024571, "grad_norm": 0.19058312475681305, "test_error": 0.0262}, {"epoch": 153, "train_loss": 0.07886595256998165, "grad_norm": 0.17990179359912872, "test_error": 0.0242}, {"epoch": 154, "train_loss": 0.07898224205681376, "grad_norm": 0.2982330322265625, "test_error": 0.0312}, {"epoch": 155, "train_loss": 0.07813189990361206, "grad_norm": 0.07264868170022964, "test_error": 0.0232}, {"epoch": 156, "train_loss": 0.0785543656815862, "grad_norm": 0.303977370262146, "test_error": 0.0315}, {"epoch": 157, "train_loss": 0.07910353818483903, "grad_norm": 0.1565914750099182, "test_error": 0.0274}, {"epoch": 158, "train_loss": 0.07909016191000895, "grad_norm": 0.1294862926006317, "test_error": 0.0204}, {"epoch": 159, "train_loss": 0.07795010903554794, "grad_norm": 0.34743139147758484, "test_error": 0.0319}, {"epoch": 160, "train_loss": 0.07826388010097192, "grad_norm": 0.09364686161279678, "test_error": 0.0214}, {"epoch": 161, "train_loss": 0.07847722645096171, "grad_norm": 0.17221057415008545, "test_error": 0.0238}, {"epoch": 162, "train_loss": 0.0792978769326437, "grad_norm": 0.2004598081111908, "test_error": 0.0265}, {"epoch": 163, "train_loss": 0.07762774719434189, "grad_norm": 0.28151935338974, "test_error": 0.0285}, {"epoch": 164, "train_loss": 0.07994822117874961, "grad_norm": 0.16830195486545563, "test_error": 0.0247}, {"epoch": 165, "train_loss": 0.07933885830338235, "grad_norm": 0.09814918786287308, "test_error": 0.0234}, {"epoch": 166, "train_loss": 0.07704661466217415, "grad_norm": 0.1558077335357666, "test_error": 0.0232}, {"epoch": 167, "train_loss": 0.07690997967058016, "grad_norm": 0.14729736745357513, "test_error": 0.0241}, {"epoch": 168, "train_loss": 0.0804344849021242, "grad_norm": 0.1379324048757553, "test_error": 0.0224}, {"epoch": 169, "train_loss": 0.07814921588855699, "grad_norm": 0.16631369292736053, "test_error": 0.0259}, {"epoch": 170, "train_loss": 0.0792124070462111, "grad_norm": 0.1500496119260788, "test_error": 0.0246}, {"epoch": 171, "train_loss": 0.07844156315897514, "grad_norm": 0.2891640067100525, "test_error": 0.032}, {"epoch": 172, "train_loss": 0.07922763616748853, "grad_norm": 0.1473916471004486, "test_error": 0.0234}, {"epoch": 173, "train_loss": 0.07881888191288211, "grad_norm": 0.13231807947158813, "test_error": 0.0258}, {"epoch": 174, "train_loss": 0.07902728750658328, "grad_norm": 0.16386738419532776, "test_error": 0.0247}, {"epoch": 175, "train_loss": 0.07866708195153478, "grad_norm": 0.24878306686878204, "test_error": 0.0311}, {"epoch": 176, "train_loss": 0.07869760256127241, "grad_norm": 0.3760068416595459, "test_error": 0.0359}, {"epoch": 177, "train_loss": 0.07908311396912905, "grad_norm": 0.14621680974960327, "test_error": 0.0238}, {"epoch": 178, "train_loss": 0.07853626717368994, "grad_norm": 0.11654191464185715, "test_error": 0.0252}, {"epoch": 179, "train_loss": 0.07832658094884634, "grad_norm": 0.15470032393932343, "test_error": 0.0282}, {"epoch": 180, "train_loss": 0.07918650739705967, "grad_norm": 0.21898028254508972, "test_error": 0.0281}, {"epoch": 181, "train_loss": 0.07732419066250441, "grad_norm": 0.17720232903957367, "test_error": 0.0306}, {"epoch": 182, "train_loss": 0.07978694976013018, "grad_norm": 0.182081401348114, "test_error": 0.0281}, {"epoch": 183, "train_loss": 0.07684202199104039, "grad_norm": 0.3339216709136963, "test_error": 0.0318}, {"epoch": 184, "train_loss": 0.07932896714909293, "grad_norm": 0.21302102506160736, "test_error": 0.026}, {"epoch": 185, "train_loss": 0.07783881334142521, "grad_norm": 0.29560336470603943, "test_error": 0.0325}, {"epoch": 186, "train_loss": 0.07952189895233217, "grad_norm": 0.11860107630491257, "test_error": 0.024}, {"epoch": 187, "train_loss": 0.07686541537640247, "grad_norm": 0.18503384292125702, "test_error": 0.032}, {"epoch": 188, "train_loss": 0.0793735597920798, "grad_norm": 0.14098985493183136, "test_error": 0.0231}, {"epoch": 189, "train_loss": 0.07909619475510409, "grad_norm": 0.16027911007404327, "test_error": 0.0287}, {"epoch": 190, "train_loss": 0.07928624282872382, "grad_norm": 0.13727200031280518, "test_error": 0.0257}, {"epoch": 191, "train_loss": 0.07870469564623879, "grad_norm": 0.19178791344165802, "test_error": 0.0305}, {"epoch": 192, "train_loss": 0.07917655932198978, "grad_norm": 0.1583762913942337, "test_error": 0.0281}, {"epoch": 193, "train_loss": 0.0783556872604701, "grad_norm": 0.10421332716941833, "test_error": 0.0245}, {"epoch": 194, "train_loss": 0.07808893651448306, "grad_norm": 0.3678201138973236, "test_error": 0.0359}, {"epoch": 195, "train_loss": 0.07810840251675108, "grad_norm": 0.18039502203464508, "test_error": 0.027}, {"epoch": 196, "train_loss": 0.07887636131405694, "grad_norm": 0.12661148607730865, "test_error": 0.0235}, {"epoch": 197, "train_loss": 0.07969282323423735, "grad_norm": 0.14985749125480652, "test_error": 0.0272}, {"epoch": 198, "train_loss": 0.07905902526187128, "grad_norm": 0.10278983414173126, "test_error": 0.0263}, {"epoch": 199, "train_loss": 0.07805701462825528, "grad_norm": 0.175601065158844, "test_error": 0.0301}, {"epoch": 200, "train_loss": 0.079820421656356, "grad_norm": 0.2533878684043884, "test_error": 0.0315}, {"epoch": 201, "train_loss": 0.07968961694005217, "grad_norm": 0.12069966644048691, "test_error": 0.0242}, {"epoch": 202, "train_loss": 0.07903019186770932, "grad_norm": 0.21958619356155396, "test_error": 0.0287}, {"epoch": 203, "train_loss": 0.07845023174203986, "grad_norm": 0.23972180485725403, "test_error": 0.0287}, {"epoch": 204, "train_loss": 0.08071229140352806, "grad_norm": 0.31202271580696106, "test_error": 0.0325}, {"epoch": 205, "train_loss": 0.07692595349149875, "grad_norm": 0.16887472569942474, "test_error": 0.0259}, {"epoch": 206, "train_loss": 0.07715360388666158, "grad_norm": 0.12260470539331436, "test_error": 0.0257}, {"epoch": 207, "train_loss": 0.0785214761053406, "grad_norm": 0.16894641518592834, "test_error": 0.027}, {"epoch": 208, "train_loss": 0.07947862229703363, "grad_norm": 0.1766836941242218, "test_error": 0.0246}, {"epoch": 209, "train_loss": 0.0780211431391702, "grad_norm": 0.18752562999725342, "test_error": 0.0265}, {"epoch": 210, "train_loss": 0.07931290377874878, "grad_norm": 0.34493809938430786, "test_error": 0.0305}, {"epoch": 211, "train_loss": 0.0808998652842735, "grad_norm": 0.17790751159191132, "test_error": 0.0262}, {"epoch": 212, "train_loss": 0.0772713492679759, "grad_norm": 0.27937811613082886, "test_error": 0.0345}, {"epoch": 213, "train_loss": 0.07995031716066782, "grad_norm": 0.16038115322589874, "test_error": 0.0237}, {"epoch": 214, "train_loss": 0.07846507314250145, "grad_norm": 0.11634061485528946, "test_error": 0.0234}, {"epoch": 215, "train_loss": 0.0782593383512188, "grad_norm": 0.24053284525871277, "test_error": 0.0303}, {"epoch": 216, "train_loss": 0.07981329569508913, "grad_norm": 0.1435939073562622, "test_error": 0.0245}, {"epoch": 217, "train_loss": 0.0789420671286692, "grad_norm": 0.22852058708667755, "test_error": 0.0272}, {"epoch": 218, "train_loss": 0.07976992919410987, "grad_norm": 0.19941957294940948, "test_error": 0.0247}, {"epoch": 219, "train_loss": 0.07763992538333211, "grad_norm": 0.18888050317764282, "test_error": 0.027}, {"epoch": 220, "train_loss": 0.07854020876944802, "grad_norm": 0.27569955587387085, "test_error": 0.0328}, {"epoch": 221, "train_loss": 0.07971820060054596, "grad_norm": 0.20409898459911346, "test_error": 0.0286}, {"epoch": 222, "train_loss": 0.07847305276898017, "grad_norm": 0.10549386590719223, "test_error": 0.0223}, {"epoch": 223, "train_loss": 0.07910748826691269, "grad_norm": 0.21368157863616943, "test_error": 0.0287}, {"epoch": 224, "train_loss": 0.07967280849252711, "grad_norm": 0.3674614429473877, "test_error": 0.0323}, {"epoch": 225, "train_loss": 0.0791570993555118, "grad_norm": 0.35405415296554565, "test_error": 0.039}, {"epoch": 226, "train_loss": 0.0779366631710606, "grad_norm": 0.3622725307941437, "test_error": 0.0405}, {"epoch": 227, "train_loss": 0.07897076648420867, "grad_norm": 0.15799719095230103, "test_error": 0.0272}, {"epoch": 228, "train_loss": 0.07864888103129246, "grad_norm": 0.3500818610191345, "test_error": 0.0335}, {"epoch": 229, "train_loss": 0.07829293353164393, "grad_norm": 0.38954782485961914, "test_error": 0.0318}, {"epoch": 230, "train_loss": 0.08120181633824662, "grad_norm": 0.15065835416316986, "test_error": 0.0229}, {"epoch": 231, "train_loss": 0.0787658434187518, "grad_norm": 0.15711729228496552, "test_error": 0.0254}, {"epoch": 232, "train_loss": 0.08007837521577311, "grad_norm": 0.30016711354255676, "test_error": 0.032}, {"epoch": 233, "train_loss": 0.07744916128144784, "grad_norm": 0.1937170922756195, "test_error": 0.0272}, {"epoch": 234, "train_loss": 0.07901277348051372, "grad_norm": 0.3031071424484253, "test_error": 0.0313}, {"epoch": 235, "train_loss": 0.07760119008935969, "grad_norm": 0.1613490879535675, "test_error": 0.0229}, {"epoch": 236, "train_loss": 0.07930703427912279, "grad_norm": 0.25753435492515564, "test_error": 0.0303}, {"epoch": 237, "train_loss": 0.0784187233935736, "grad_norm": 0.48693588376045227, "test_error": 0.0379}, {"epoch": 238, "train_loss": 0.07986189965802623, "grad_norm": 0.23922313749790192, "test_error": 0.0256}, {"epoch": 239, "train_loss": 0.07989689456710766, "grad_norm": 0.21237239241600037, "test_error": 0.0272}, {"epoch": 240, "train_loss": 0.08009860645648344, "grad_norm": 0.18330252170562744, "test_error": 0.0282}, {"epoch": 241, "train_loss": 0.07911328661339455, "grad_norm": 0.20405200123786926, "test_error": 0.0271}, {"epoch": 242, "train_loss": 0.07868404387307237, "grad_norm": 0.2133961021900177, "test_error": 0.0289}, {"epoch": 243, "train_loss": 0.07965145849937592, "grad_norm": 0.15435568988323212, "test_error": 0.0255}, {"epoch": 244, "train_loss": 0.07851305510271049, "grad_norm": 0.07463917136192322, "test_error": 0.0233}, {"epoch": 245, "train_loss": 0.08014238272989072, "grad_norm": 0.1585294008255005, "test_error": 0.0262}, {"epoch": 246, "train_loss": 0.07858808993812758, "grad_norm": 0.27543824911117554, "test_error": 0.0302}, {"epoch": 247, "train_loss": 0.07885148684733334, "grad_norm": 0.16676846146583557, "test_error": 0.028}, {"epoch": 248, "train_loss": 0.07945048991695512, "grad_norm": 0.27557340264320374, "test_error": 0.0339}, {"epoch": 249, "train_loss": 0.07885254289877049, "grad_norm": 0.1703348457813263, "test_error": 0.0241}, {"epoch": 250, "train_loss": 0.08024062968712194, "grad_norm": 0.3854806125164032, "test_error": 0.0356}, {"epoch": 251, "train_loss": 0.07673354368773531, "grad_norm": 0.2534371614456177, "test_error": 0.0309}, {"epoch": 252, "train_loss": 0.07866226199062658, "grad_norm": 0.18226566910743713, "test_error": 0.0266}, {"epoch": 253, "train_loss": 0.0779918064805291, "grad_norm": 0.22456040978431702, "test_error": 0.0277}, {"epoch": 254, "train_loss": 0.07970132827241469, "grad_norm": 0.14087887108325958, "test_error": 0.0232}, {"epoch": 255, "train_loss": 0.07931436625012915, "grad_norm": 0.11614856868982315, "test_error": 0.0233}, {"epoch": 256, "train_loss": 0.07827813574108101, "grad_norm": 0.3066772520542145, "test_error": 0.0334}, {"epoch": 257, "train_loss": 0.08081529543697737, "grad_norm": 0.16155190765857697, "test_error": 0.0256}, {"epoch": 258, "train_loss": 0.07911190256582146, "grad_norm": 0.3450745642185211, "test_error": 0.0386}, {"epoch": 259, "train_loss": 0.07846326647115832, "grad_norm": 0.08355724811553955, "test_error": 0.0231}, {"epoch": 260, "train_loss": 0.07894980053016722, "grad_norm": 0.10641394555568695, "test_error": 0.0231}, {"epoch": 261, "train_loss": 0.0780122606427467, "grad_norm": 0.22933915257453918, "test_error": 0.0291}, {"epoch": 262, "train_loss": 0.07931449144989165, "grad_norm": 0.15348182618618011, "test_error": 0.026}, {"epoch": 263, "train_loss": 0.0778680359415254, "grad_norm": 0.24374181032180786, "test_error": 0.0326}, {"epoch": 264, "train_loss": 0.0799955042492802, "grad_norm": 0.11096585541963577, "test_error": 0.0227}, {"epoch": 265, "train_loss": 0.0786009121004463, "grad_norm": 0.2165730744600296, "test_error": 0.0274}, {"epoch": 266, "train_loss": 0.07954493207117776, "grad_norm": 0.20591354370117188, "test_error": 0.0261}, {"epoch": 267, "train_loss": 0.07830553313058772, "grad_norm": 0.23237544298171997, "test_error": 0.0283}, {"epoch": 268, "train_loss": 0.07926797406034408, "grad_norm": 0.20899748802185059, "test_error": 0.0263}, {"epoch": 269, "train_loss": 0.07920531481163198, "grad_norm": 0.381666898727417, "test_error": 0.04}, {"epoch": 270, "train_loss": 0.07938205975414409, "grad_norm": 0.6565528512001038, "test_error": 0.0482}, {"epoch": 271, "train_loss": 0.08045905821134754, "grad_norm": 0.2192063182592392, "test_error": 0.0265}, {"epoch": 272, "train_loss": 0.07860622421600662, "grad_norm": 0.18578797578811646, "test_error": 0.0256}, {"epoch": 273, "train_loss": 0.08098293474787958, "grad_norm": 0.3169479966163635, "test_error": 0.0328}, {"epoch": 274, "train_loss": 0.08002324799193593, "grad_norm": 0.14569254219532013, "test_error": 0.0235}, {"epoch": 275, "train_loss": 0.07827363421396148, "grad_norm": 0.20446479320526123, "test_error": 0.0291}, {"epoch": 276, "train_loss": 0.07953674677673067, "grad_norm": 0.17829011380672455, "test_error": 0.0241}, {"epoch": 277, "train_loss": 0.07907287492916415, "grad_norm": 0.10419272631406784, "test_error": 0.0233}, {"epoch": 278, "train_loss": 0.07911370768116952, "grad_norm": 0.1701691895723343, "test_error": 0.0268}, {"epoch": 279, "train_loss": 0.07943317241122229, "grad_norm": 0.18885940313339233, "test_error": 0.0263}, {"epoch": 280, "train_loss": 0.07876822919897192, "grad_norm": 0.1439095437526703, "test_error": 0.0242}, {"epoch": 281, "train_loss": 0.0797631509946732, "grad_norm": 0.2626574635505676, "test_error": 0.0278}, {"epoch": 282, "train_loss": 0.07945735218891302, "grad_norm": 0.19489061832427979, "test_error": 0.0268}, {"epoch": 283, "train_loss": 0.07919122442093794, "grad_norm": 0.21640589833259583, "test_error": 0.0303}, {"epoch": 284, "train_loss": 0.08029792137935389, "grad_norm": 0.20215991139411926, "test_error": 0.0283}, {"epoch": 285, "train_loss": 0.08010008225937296, "grad_norm": 0.19485905766487122, "test_error": 0.0258}, {"epoch": 286, "train_loss": 0.07898984198847757, "grad_norm": 0.18652386963367462, "test_error": 0.0281}, {"epoch": 287, "train_loss": 0.0786775512030484, "grad_norm": 0.17684265971183777, "test_error": 0.0278}, {"epoch": 288, "train_loss": 0.07938173782239027, "grad_norm": 0.18934743106365204, "test_error": 0.0257}, {"epoch": 289, "train_loss": 0.07951384619775005, "grad_norm": 0.29840004444122314, "test_error": 0.0309}, {"epoch": 290, "train_loss": 0.07884839897081838, "grad_norm": 0.15500569343566895, "test_error": 0.0236}, {"epoch": 291, "train_loss": 0.07912509264372178, "grad_norm": 0.2574852406978607, "test_error": 0.0303}, {"epoch": 292, "train_loss": 0.07929225346544991, "grad_norm": 0.5677180290222168, "test_error": 0.0437}, {"epoch": 293, "train_loss": 0.07995929197477623, "grad_norm": 0.2431751787662506, "test_error": 0.0277}, {"epoch": 294, "train_loss": 0.08026452158130754, "grad_norm": 0.1743684709072113, "test_error": 0.0268}, {"epoch": 295, "train_loss": 0.0787816104284963, "grad_norm": 0.27018922567367554, "test_error": 0.03}, {"epoch": 296, "train_loss": 0.08002121711866979, "grad_norm": 0.13366027176380157, "test_error": 0.0229}, {"epoch": 297, "train_loss": 0.0810850895576441, "grad_norm": 0.1615479588508606, "test_error": 0.0248}, {"epoch": 298, "train_loss": 0.07877429361301862, "grad_norm": 0.12933918833732605, "test_error": 0.0259}, {"epoch": 299, "train_loss": 0.07901404842294384, "grad_norm": 0.36662939190864563, "test_error": 0.04}, {"epoch": 300, "train_loss": 0.07889876915270967, "grad_norm": 0.26907193660736084, "test_error": 0.0322}]}