{"argv": ["train.py", "--seed", "12", "--optimizer", "SGD", "--run_name", "sgd_0.25.json", "--output_path", "experiments/nonconvex_fmnist/sgd-0.25.json", "--dataset", "FMNIST", "--layer_sizes", "784", "100", "10", "--batch_size", "10", "--learning_rate", "0.25", "--weight_decay", "0.001", "--num_epochs", "300", "--download", "--device", "cuda"], "args": {"seed": 12, "optimizer": "SGD", "run_name": "sgd_0.25.json", "output_path": "experiments/nonconvex_fmnist/sgd-0.25.json", "device": "cuda", "dataset": "FMNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": true, "layer_sizes": [784, 100, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.25, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 0.7285429598395713, "grad_norm": 0.9691017270088196, "test_error": 0.24848333333333333}, {"epoch": 2, "train_loss": 0.619932689786811, "grad_norm": 0.5646783113479614, "test_error": 0.19873333333333335}, {"epoch": 3, "train_loss": 0.6064903847649693, "grad_norm": 0.4445273280143738, "test_error": 0.19873333333333335}, {"epoch": 4, "train_loss": 0.5940067055857119, "grad_norm": 2.510293483734131, "test_error": 0.28996666666666665}, {"epoch": 5, "train_loss": 0.6182002355050451, "grad_norm": 0.3578319251537323, "test_error": 0.16991666666666666}, {"epoch": 6, "train_loss": 0.6145593615177398, "grad_norm": 2.313148260116577, "test_error": 0.29715}, {"epoch": 7, "train_loss": 0.6135217246346486, "grad_norm": 0.31569018959999084, "test_error": 0.17428333333333335}, {"epoch": 8, "train_loss": 0.6142530297059178, "grad_norm": 0.4543478786945343, "test_error": 0.20991666666666667}, {"epoch": 9, "train_loss": 0.6220055572649774, "grad_norm": 0.905318021774292, "test_error": 0.24513333333333334}, {"epoch": 10, "train_loss": 0.6539035613596594, "grad_norm": 0.40993571281433105, "test_error": 0.19655}, {"epoch": 11, "train_loss": 0.6248935036562228, "grad_norm": 0.5879034996032715, "test_error": 0.24906666666666666}, {"epoch": 12, "train_loss": 0.6298580973919016, "grad_norm": 0.7637805938720703, "test_error": 0.30493333333333333}, {"epoch": 13, "train_loss": 0.6485078245896536, "grad_norm": 0.7151606678962708, "test_error": 0.2019}, {"epoch": 14, "train_loss": 0.6362024711637447, "grad_norm": 0.2883917987346649, "test_error": 0.16901666666666668}, {"epoch": 15, "train_loss": 0.620519231320514, "grad_norm": 0.5186712145805359, "test_error": 0.2730666666666667}, {"epoch": 16, "train_loss": 0.6502298226363491, "grad_norm": 0.15727634727954865, "test_error": 0.16741666666666666}, {"epoch": 17, "train_loss": 0.6569003824410029, "grad_norm": 0.4668693542480469, "test_error": 0.2668333333333333}, {"epoch": 18, "train_loss": 0.6280803653945526, "grad_norm": 0.5798276662826538, "test_error": 0.20386666666666667}, {"epoch": 19, "train_loss": 0.6643679832373746, "grad_norm": 0.9787465929985046, "test_error": 0.22908333333333333}, {"epoch": 20, "train_loss": 0.6516971044315336, "grad_norm": 0.47371813654899597, "test_error": 0.19231666666666666}, {"epoch": 21, "train_loss": 0.6603798869644331, "grad_norm": 0.3816744387149811, "test_error": 0.2931}, {"epoch": 22, "train_loss": 0.7274597170173657, "grad_norm": 0.2506308853626251, "test_error": 0.2301}, {"epoch": 23, "train_loss": 0.7081263753195914, "grad_norm": 0.45636963844299316, "test_error": 0.37875}, {"epoch": 24, "train_loss": 0.7855771643901244, "grad_norm": 0.7861481308937073, "test_error": 0.2583166666666667}, {"epoch": 25, "train_loss": 0.761760333944733, "grad_norm": 1.0229203701019287, "test_error": 0.3359666666666667}, {"epoch": 26, "train_loss": 0.7927422926489575, "grad_norm": 0.6242086291313171, "test_error": 0.22443333333333335}, {"epoch": 27, "train_loss": 0.9376414025622265, "grad_norm": 0.5409049391746521, "test_error": 0.24431666666666665}, {"epoch": 28, "train_loss": 0.780227785586069, "grad_norm": 0.5775884985923767, "test_error": 0.23878333333333332}, {"epoch": 29, "train_loss": 0.7506218114304356, "grad_norm": 0.6789126396179199, "test_error": 0.31195}, {"epoch": 30, "train_loss": 0.7458046701375085, "grad_norm": 0.34227973222732544, "test_error": 0.22788333333333333}, {"epoch": 31, "train_loss": 0.7247047140944438, "grad_norm": 0.6005354523658752, "test_error": 0.23918333333333333}, {"epoch": 32, "train_loss": 0.7180852739044155, "grad_norm": 0.5381209254264832, "test_error": 0.26971666666666666}, {"epoch": 33, "train_loss": 0.748603142037134, "grad_norm": 0.4732757806777954, "test_error": 0.29568333333333335}, {"epoch": 34, "train_loss": 0.7946455509069686, "grad_norm": 0.5553219318389893, "test_error": 0.2937}, {"epoch": 35, "train_loss": 0.8414032216657263, "grad_norm": 0.6592040061950684, "test_error": 0.32631666666666664}, {"epoch": 36, "train_loss": 0.873349630078068, "grad_norm": 0.5746831893920898, "test_error": 0.36746666666666666}, {"epoch": 37, "train_loss": 0.9238524862664441, "grad_norm": 0.37192675471305847, "test_error": 0.2938}, {"epoch": 38, "train_loss": 0.8092191679044627, "grad_norm": 0.5192745923995972, "test_error": 0.3042}, {"epoch": 39, "train_loss": 0.8035593513008983, "grad_norm": 0.6063472628593445, "test_error": 0.27568333333333334}, {"epoch": 40, "train_loss": 0.7519530869304824, "grad_norm": 1.0432231426239014, "test_error": 0.2485}, {"epoch": 41, "train_loss": 0.7351835049845589, "grad_norm": 1.1839557886123657, "test_error": 0.2922166666666667}, {"epoch": 42, "train_loss": 0.7464143550090181, "grad_norm": 0.4567873179912567, "test_error": 0.32338333333333336}, {"epoch": 43, "train_loss": 0.7983320540487766, "grad_norm": 0.6161428689956665, "test_error": 0.23135}, {"epoch": 44, "train_loss": 0.7839766338480404, "grad_norm": 1.2449045181274414, "test_error": 0.4828}, {"epoch": 45, "train_loss": 0.8709705817180996, "grad_norm": 0.5002021789550781, "test_error": 0.32913333333333333}, {"epoch": 46, "train_loss": 0.8124171839092548, "grad_norm": 0.25230738520622253, "test_error": 0.284}, {"epoch": 47, "train_loss": 0.8105645368861345, "grad_norm": 0.7059813737869263, "test_error": 0.2502666666666667}, {"epoch": 48, "train_loss": 0.7577049352102913, "grad_norm": 1.2641911506652832, "test_error": 0.2979}, {"epoch": 49, "train_loss": 0.8672686338719602, "grad_norm": 0.3264992833137512, "test_error": 0.23175}, {"epoch": 50, "train_loss": 0.8305484099132009, "grad_norm": 0.32009413838386536, "test_error": 0.22908333333333333}, {"epoch": 51, "train_loss": 0.7783286781253603, "grad_norm": 0.6330881714820862, "test_error": 0.30393333333333333}, {"epoch": 52, "train_loss": 0.844197636883473, "grad_norm": 0.5796706676483154, "test_error": 0.25745}, {"epoch": 53, "train_loss": 0.9074869689941406, "grad_norm": 0.47249242663383484, "test_error": 0.2650666666666667}, {"epoch": 54, "train_loss": 0.8593071348387749, "grad_norm": 0.44900402426719666, "test_error": 0.4742}, {"epoch": 55, "train_loss": 0.9227941276682541, "grad_norm": 0.5637454390525818, "test_error": 0.34663333333333335}, {"epoch": 56, "train_loss": 0.8642072827826098, "grad_norm": 1.4883917570114136, "test_error": 0.479}, {"epoch": 57, "train_loss": 0.8502842122631458, "grad_norm": 0.4898868799209595, "test_error": 0.30216666666666664}, {"epoch": 58, "train_loss": 0.9268290886400888, "grad_norm": 0.9145855903625488, "test_error": 0.44333333333333336}, {"epoch": 59, "train_loss": 0.8989009808059781, "grad_norm": 0.3257442116737366, "test_error": 0.3051}, {"epoch": 60, "train_loss": 0.8795503829636921, "grad_norm": 1.021016240119934, "test_error": 0.3364333333333333}, {"epoch": 61, "train_loss": 0.9994592038743819, "grad_norm": 0.6353438496589661, "test_error": 0.32438333333333336}, {"epoch": 62, "train_loss": 0.9574074672351902, "grad_norm": 0.8578175902366638, "test_error": 0.2906}, {"epoch": 63, "train_loss": 0.933445486864696, "grad_norm": 0.4253472089767456, "test_error": 0.30785}, {"epoch": 64, "train_loss": 0.8163056466924027, "grad_norm": 0.9424262642860413, "test_error": 0.4588833333333333}, {"epoch": 65, "train_loss": 0.8846406242686013, "grad_norm": 0.5756874680519104, "test_error": 0.28905}, {"epoch": 66, "train_loss": 1.0095660119991128, "grad_norm": 0.5088470578193665, "test_error": 0.31628333333333336}, {"epoch": 67, "train_loss": 0.9562555538838108, "grad_norm": 0.753239631652832, "test_error": 0.30275}, {"epoch": 68, "train_loss": 0.9373167222039774, "grad_norm": 0.7097349166870117, "test_error": 0.3006666666666667}, {"epoch": 69, "train_loss": 0.933045908657834, "grad_norm": 0.40832042694091797, "test_error": 0.2917}, {"epoch": 70, "train_loss": 0.94280787564752, "grad_norm": 0.6212539076805115, "test_error": 0.28751666666666664}, {"epoch": 71, "train_loss": 0.9427457581715037, "grad_norm": 1.2307814359664917, "test_error": 0.48068333333333335}, {"epoch": 72, "train_loss": 1.0751512681921012, "grad_norm": 0.7583041787147522, "test_error": 0.3247333333333333}, {"epoch": 73, "train_loss": 0.9519477085191757, "grad_norm": 0.542701244354248, "test_error": 0.3057166666666667}, {"epoch": 74, "train_loss": 1.002901857206598, "grad_norm": 1.2884584665298462, "test_error": 0.41938333333333333}, {"epoch": 75, "train_loss": 0.9629266876174758, "grad_norm": 0.5357445478439331, "test_error": 0.34736666666666666}, {"epoch": 76, "train_loss": 0.9288530650970837, "grad_norm": 0.18721118569374084, "test_error": 0.3661333333333333}, {"epoch": 77, "train_loss": 0.9599387259874493, "grad_norm": 0.43796291947364807, "test_error": 0.3010333333333333}, {"epoch": 78, "train_loss": 0.9399975275096173, "grad_norm": 0.37449249625205994, "test_error": 0.283}, {"epoch": 79, "train_loss": 1.1270141014742354, "grad_norm": 2.05938982963562, "test_error": 0.5071166666666667}, {"epoch": 80, "train_loss": 1.2866477292825778, "grad_norm": 3.8390629291534424, "test_error": 0.5179}, {"epoch": 81, "train_loss": 1.461258056814472, "grad_norm": 1.4498404264450073, "test_error": 0.5698333333333333}, {"epoch": 82, "train_loss": 1.0623020761764297, "grad_norm": 0.44379162788391113, "test_error": 0.3000833333333333}, {"epoch": 83, "train_loss": 0.936019994609834, "grad_norm": 0.6187337040901184, "test_error": 0.3259666666666667}, {"epoch": 84, "train_loss": 1.0687955308494468, "grad_norm": 1.094840407371521, "test_error": 0.42785}, {"epoch": 85, "train_loss": 1.4650472948352495, "grad_norm": 0.7353289723396301, "test_error": 0.5565166666666667}, {"epoch": 86, "train_loss": 1.4896908500492574, "grad_norm": 0.6341605186462402, "test_error": 0.5903}, {"epoch": 87, "train_loss": 1.4671589949627717, "grad_norm": 0.8472245335578918, "test_error": 0.60685}, {"epoch": 88, "train_loss": 1.3851565643548966, "grad_norm": 1.4566019773483276, "test_error": 0.743}, {"epoch": 89, "train_loss": 1.1713183838576078, "grad_norm": 0.5476996302604675, "test_error": 0.33213333333333334}, {"epoch": 90, "train_loss": 1.100539485740165, "grad_norm": 0.5821709632873535, "test_error": 0.65145}, {"epoch": 91, "train_loss": 1.3026136996100346, "grad_norm": 0.4204631745815277, "test_error": 0.4424166666666667}, {"epoch": 92, "train_loss": 1.254244026005268, "grad_norm": 0.5035383701324463, "test_error": 0.4117166666666667}, {"epoch": 93, "train_loss": 1.1836249414605555, "grad_norm": 0.5461061000823975, "test_error": 0.5774833333333333}, {"epoch": 94, "train_loss": 1.4606702468693256, "grad_norm": 0.1945721060037613, "test_error": 0.5584166666666667}, {"epoch": 95, "train_loss": 1.3325050453953444, "grad_norm": 0.25662651658058167, "test_error": 0.5435}, {"epoch": 96, "train_loss": 1.2503204421599705, "grad_norm": 0.2505137622356415, "test_error": 0.4374166666666667}, {"epoch": 97, "train_loss": 1.1293661898639984, "grad_norm": 0.8314635753631592, "test_error": 0.49998333333333334}, {"epoch": 98, "train_loss": 1.03933252919962, "grad_norm": 0.4592609107494354, "test_error": 0.3703166666666667}, {"epoch": 99, "train_loss": 0.9522436933517456, "grad_norm": 0.5778577923774719, "test_error": 0.2873}, {"epoch": 100, "train_loss": 0.9427225181078538, "grad_norm": 0.9307157397270203, "test_error": 0.44225}, {"epoch": 101, "train_loss": 0.9275982756546388, "grad_norm": 0.6384676694869995, "test_error": 0.2940833333333333}, {"epoch": 102, "train_loss": 0.980005709300749, "grad_norm": 1.189019799232483, "test_error": 0.4126666666666667}, {"epoch": 103, "train_loss": 1.1438981366730294, "grad_norm": 0.507227897644043, "test_error": 0.3905}, {"epoch": 104, "train_loss": 1.1723866298894088, "grad_norm": 0.9781089425086975, "test_error": 0.3873666666666667}, {"epoch": 105, "train_loss": 1.1281431830115616, "grad_norm": 0.8223049640655518, "test_error": 0.3894}, {"epoch": 106, "train_loss": 1.4633509383810064, "grad_norm": 0.8994521498680115, "test_error": 0.5840166666666666}, {"epoch": 107, "train_loss": 1.1961129641582569, "grad_norm": 0.35979709029197693, "test_error": 0.4703}, {"epoch": 108, "train_loss": 1.1013712918441743, "grad_norm": 0.2033422589302063, "test_error": 0.39138333333333336}, {"epoch": 109, "train_loss": 1.1541443058227498, "grad_norm": 0.8479871153831482, "test_error": 0.4525666666666667}, {"epoch": 110, "train_loss": 1.1422144313007594, "grad_norm": 1.3356473445892334, "test_error": 0.5175833333333333}, {"epoch": 111, "train_loss": 1.0966879316394529, "grad_norm": 0.5466700792312622, "test_error": 0.4117}, {"epoch": 112, "train_loss": 0.924153623120316, "grad_norm": 0.4816722869873047, "test_error": 0.32968333333333333}, {"epoch": 113, "train_loss": 0.8509364574927216, "grad_norm": 0.6175455451011658, "test_error": 0.30118333333333336}, {"epoch": 114, "train_loss": 0.8758438251744955, "grad_norm": 0.8796992897987366, "test_error": 0.32115}, {"epoch": 115, "train_loss": 0.8169882207897802, "grad_norm": 0.44521746039390564, "test_error": 0.23041666666666666}, {"epoch": 116, "train_loss": 0.7892914942214265, "grad_norm": 0.7228894233703613, "test_error": 0.33825}, {"epoch": 117, "train_loss": 0.7701070324353253, "grad_norm": 0.44696152210235596, "test_error": 0.23118333333333332}, {"epoch": 118, "train_loss": 0.9547940890515844, "grad_norm": 0.7261179089546204, "test_error": 0.28226666666666667}, {"epoch": 119, "train_loss": 0.8323959595529984, "grad_norm": 0.2704898416996002, "test_error": 0.2386}, {"epoch": 120, "train_loss": 0.8315161477342868, "grad_norm": 0.47415196895599365, "test_error": 0.25361666666666666}, {"epoch": 121, "train_loss": 0.8164329649976765, "grad_norm": 0.8945271968841553, "test_error": 0.26381666666666664}, {"epoch": 122, "train_loss": 0.8191035896365841, "grad_norm": 0.9231169819831848, "test_error": 0.28436666666666666}, {"epoch": 123, "train_loss": 0.8094267806399924, "grad_norm": 0.4846861958503723, "test_error": 0.3039}, {"epoch": 124, "train_loss": 0.9144538900256157, "grad_norm": 0.9378630518913269, "test_error": 0.40398333333333336}, {"epoch": 125, "train_loss": 0.9594406915130094, "grad_norm": 0.8479087948799133, "test_error": 0.31638333333333335}, {"epoch": 126, "train_loss": 0.8949414508929476, "grad_norm": 0.4675362706184387, "test_error": 0.26795}, {"epoch": 127, "train_loss": 0.8321236402681097, "grad_norm": 0.8342803120613098, "test_error": 0.2816666666666667}, {"epoch": 128, "train_loss": 0.8128253660562138, "grad_norm": 1.3337101936340332, "test_error": 0.30851666666666666}, {"epoch": 129, "train_loss": 0.8111431208718568, "grad_norm": 0.3765517473220825, "test_error": 0.2804333333333333}, {"epoch": 130, "train_loss": 0.7906350445781524, "grad_norm": 0.963638424873352, "test_error": 0.36656666666666665}, {"epoch": 131, "train_loss": 1.0784198582743605, "grad_norm": 1.7258827686309814, "test_error": 0.42115}, {"epoch": 132, "train_loss": 0.969981528825437, "grad_norm": 0.4894428253173828, "test_error": 0.31343333333333334}, {"epoch": 133, "train_loss": 0.9539092146717012, "grad_norm": 0.7669630646705627, "test_error": 0.37478333333333336}, {"epoch": 134, "train_loss": 1.0708248722922677, "grad_norm": 2.9111907482147217, "test_error": 0.4141}, {"epoch": 135, "train_loss": 0.9629254666175693, "grad_norm": 0.9776318073272705, "test_error": 0.37288333333333334}, {"epoch": 136, "train_loss": 1.0303270122086008, "grad_norm": 1.5567820072174072, "test_error": 0.49743333333333334}, {"epoch": 137, "train_loss": 0.9386190848288437, "grad_norm": 1.5595295429229736, "test_error": 0.45286666666666664}, {"epoch": 138, "train_loss": 0.9002805028132473, "grad_norm": 0.6264076232910156, "test_error": 0.31493333333333334}, {"epoch": 139, "train_loss": 0.901099005865554, "grad_norm": 0.5725807547569275, "test_error": 0.30775}, {"epoch": 140, "train_loss": 1.0522495733080433, "grad_norm": 0.2753531336784363, "test_error": 0.29738333333333333}, {"epoch": 141, "train_loss": 0.9007663143267856, "grad_norm": 1.1201766729354858, "test_error": 0.3746833333333333}, {"epoch": 142, "train_loss": 0.9952570371835803, "grad_norm": 0.977394163608551, "test_error": 0.3715333333333333}, {"epoch": 143, "train_loss": 1.1105417981150871, "grad_norm": 1.7121707201004028, "test_error": 0.4217166666666667}, {"epoch": 144, "train_loss": 1.2689167742406329, "grad_norm": 2.555314779281616, "test_error": 0.6243666666666666}, {"epoch": 145, "train_loss": 1.1595973243204256, "grad_norm": 2.0811188220977783, "test_error": 0.5230333333333334}, {"epoch": 146, "train_loss": 1.0068660367888709, "grad_norm": 0.5102912187576294, "test_error": 0.31548333333333334}, {"epoch": 147, "train_loss": 1.1818511779215186, "grad_norm": 0.5209988355636597, "test_error": 0.4624333333333333}, {"epoch": 148, "train_loss": 1.1329312056085716, "grad_norm": 0.8763775825500488, "test_error": 0.46495}, {"epoch": 149, "train_loss": 1.3857137858644129, "grad_norm": 1.4462095499038696, "test_error": 0.64565}, {"epoch": 150, "train_loss": 1.6618843188881873, "grad_norm": 1.5830559730529785, "test_error": 0.5885166666666667}, {"epoch": 151, "train_loss": 1.7590373018731673, "grad_norm": 0.7800318598747253, "test_error": 0.6740666666666667}, {"epoch": 152, "train_loss": 1.6128742524335782, "grad_norm": 0.46270257234573364, "test_error": 0.60945}, {"epoch": 153, "train_loss": 1.7495808017800252, "grad_norm": 0.28746262192726135, "test_error": 0.7578666666666667}, {"epoch": 154, "train_loss": 2.272037931263447, "grad_norm": 0.027983715757727623, "test_error": 0.9001333333333333}, {"epoch": 155, "train_loss": 2.06028323212266, "grad_norm": 0.07154172658920288, "test_error": 0.7981833333333334}, {"epoch": 156, "train_loss": 1.8290248760680357, "grad_norm": 0.6665307879447937, "test_error": 0.7762166666666667}, {"epoch": 157, "train_loss": 1.528484545464317, "grad_norm": 0.5061718225479126, "test_error": 0.5648166666666666}, {"epoch": 158, "train_loss": 1.60563023836414, "grad_norm": 0.23588578402996063, "test_error": 0.7680666666666667}, {"epoch": 159, "train_loss": 1.717919227813681, "grad_norm": 0.5285033583641052, "test_error": 0.7084}, {"epoch": 160, "train_loss": 1.4574925976196924, "grad_norm": 2.1868913173675537, "test_error": 0.5938666666666667}, {"epoch": 161, "train_loss": 1.667455078125, "grad_norm": 0.08254580199718475, "test_error": 0.8095}, {"epoch": 162, "train_loss": 1.6981350019176802, "grad_norm": 1.1601431369781494, "test_error": 0.7614166666666666}, {"epoch": 163, "train_loss": 1.7342464283108712, "grad_norm": 0.4804255962371826, "test_error": 0.72465}, {"epoch": 164, "train_loss": 1.7414703610837459, "grad_norm": 1.3411507606506348, "test_error": 0.7585}, {"epoch": 165, "train_loss": 2.2697913390596707, "grad_norm": 0.5183030962944031, "test_error": 0.74055}, {"epoch": 166, "train_loss": 1.7509893597215413, "grad_norm": 1.1452301740646362, "test_error": 0.8046833333333333}, {"epoch": 167, "train_loss": 1.582711472781996, "grad_norm": 0.8639122843742371, "test_error": 0.5386333333333333}, {"epoch": 168, "train_loss": 1.3546700271442533, "grad_norm": 0.7870169878005981, "test_error": 0.4888166666666667}, {"epoch": 169, "train_loss": 1.3159207459886868, "grad_norm": 0.3667954206466675, "test_error": 0.47375}, {"epoch": 170, "train_loss": 1.3330570247396827, "grad_norm": 0.8405392169952393, "test_error": 0.4781666666666667}, {"epoch": 171, "train_loss": 1.3245246467515825, "grad_norm": 2.0037786960601807, "test_error": 0.5690666666666667}, {"epoch": 172, "train_loss": 1.577186342899998, "grad_norm": 0.1323097199201584, "test_error": 0.68075}, {"epoch": 173, "train_loss": 1.75003061825037, "grad_norm": 0.3504091501235962, "test_error": 0.729}, {"epoch": 174, "train_loss": 1.5228749668300152, "grad_norm": 0.6927655935287476, "test_error": 0.6653}, {"epoch": 175, "train_loss": 1.507442552079757, "grad_norm": 1.7006940841674805, "test_error": 0.6034333333333334}, {"epoch": 176, "train_loss": 1.447676805143555, "grad_norm": 0.47033265233039856, "test_error": 0.5391}, {"epoch": 177, "train_loss": 1.4752078732550145, "grad_norm": 1.518592119216919, "test_error": 0.6797}, {"epoch": 178, "train_loss": 1.7430024441927672, "grad_norm": 0.5307971239089966, "test_error": 0.583}, {"epoch": 179, "train_loss": 1.6724608771006266, "grad_norm": 0.2914266288280487, "test_error": 0.7267333333333333}, {"epoch": 180, "train_loss": 2.18417778373758, "grad_norm": 0.0303183700889349, "test_error": 0.9}, {"epoch": 181, "train_loss": 2.1349993147850035, "grad_norm": 0.3054139018058777, "test_error": 0.75935}, {"epoch": 182, "train_loss": 2.0868707554539045, "grad_norm": 0.4927718937397003, "test_error": 0.72205}, {"epoch": 183, "train_loss": 2.026094524949789, "grad_norm": 2.606658697128296, "test_error": 0.8094}, {"epoch": 184, "train_loss": 1.966243222395579, "grad_norm": 1.5652202367782593, "test_error": 0.7745166666666666}, {"epoch": 185, "train_loss": 1.9648275418182215, "grad_norm": 0.44040483236312866, "test_error": 0.7409833333333333}, {"epoch": 186, "train_loss": 2.059505782206853, "grad_norm": 1.0565218925476074, "test_error": 0.7558}, {"epoch": 187, "train_loss": 2.067602356761694, "grad_norm": 0.44141265749931335, "test_error": 0.7542666666666666}, {"epoch": 188, "train_loss": 2.0045544158418975, "grad_norm": 0.5998097062110901, "test_error": 0.7792166666666667}, {"epoch": 189, "train_loss": 2.003488892376423, "grad_norm": 0.3163662552833557, "test_error": 0.7231833333333333}, {"epoch": 190, "train_loss": 2.0017152503430844, "grad_norm": 0.31715065240859985, "test_error": 0.7427166666666667}, {"epoch": 191, "train_loss": 2.089945078223944, "grad_norm": 0.02096807397902012, "test_error": 0.8999833333333334}, {"epoch": 192, "train_loss": 2.1204377001821997, "grad_norm": 0.11090938746929169, "test_error": 0.7905833333333333}, {"epoch": 193, "train_loss": 2.0385840764840446, "grad_norm": 0.2563198208808899, "test_error": 0.72345}, {"epoch": 194, "train_loss": 2.0352278501987455, "grad_norm": 0.09688036888837814, "test_error": 0.8031833333333334}, {"epoch": 195, "train_loss": 1.9620981709361076, "grad_norm": 0.2564229667186737, "test_error": 0.7295666666666667}, {"epoch": 196, "train_loss": 1.9807382246653238, "grad_norm": 0.07689709216356277, "test_error": 0.8034}, {"epoch": 197, "train_loss": 1.9941398270130157, "grad_norm": 0.4991007149219513, "test_error": 0.8186166666666667}, {"epoch": 198, "train_loss": 2.004081438789765, "grad_norm": 0.10135339945554733, "test_error": 0.8000333333333334}, {"epoch": 199, "train_loss": 1.9740638860265414, "grad_norm": 0.3781934380531311, "test_error": 0.7220333333333333}, {"epoch": 200, "train_loss": 1.9666790897548199, "grad_norm": 0.42056119441986084, "test_error": 0.8109}, {"epoch": 201, "train_loss": 1.968851171851158, "grad_norm": 2.1710145473480225, "test_error": 0.8169}, {"epoch": 202, "train_loss": 2.02209972713391, "grad_norm": 0.39059823751449585, "test_error": 0.7232}, {"epoch": 203, "train_loss": 1.9720021029909451, "grad_norm": 0.2522784471511841, "test_error": 0.8018166666666666}, {"epoch": 204, "train_loss": 1.9972547413011392, "grad_norm": 0.40290847420692444, "test_error": 0.7364333333333334}, {"epoch": 205, "train_loss": 1.9724591090281804, "grad_norm": 1.9253005981445312, "test_error": 0.8132333333333334}, {"epoch": 206, "train_loss": 2.271278335571289, "grad_norm": 0.036082327365875244, "test_error": 0.8999666666666667}, {"epoch": 207, "train_loss": 2.1947534068922203, "grad_norm": 0.03490689769387245, "test_error": 0.9}, {"epoch": 208, "train_loss": 2.2888100082079568, "grad_norm": 0.029920699074864388, "test_error": 0.9}, {"epoch": 209, "train_loss": 2.3080954008897145, "grad_norm": 0.03511524945497513, "test_error": 0.9}, {"epoch": 210, "train_loss": 2.3083020190000534, "grad_norm": 0.037695083767175674, "test_error": 0.9}, {"epoch": 211, "train_loss": 1.9288437713682651, "grad_norm": 0.3991354703903198, "test_error": 0.7178666666666667}, {"epoch": 212, "train_loss": 1.7223013684252897, "grad_norm": 0.1999533325433731, "test_error": 0.7189333333333333}, {"epoch": 213, "train_loss": 1.7408859968582788, "grad_norm": 1.6268694400787354, "test_error": 0.8390666666666666}, {"epoch": 214, "train_loss": 2.1016495524048806, "grad_norm": 0.0227983295917511, "test_error": 0.8999833333333334}, {"epoch": 215, "train_loss": 1.8875982894202072, "grad_norm": 0.5332911610603333, "test_error": 0.7136}, {"epoch": 216, "train_loss": 2.1118323577046394, "grad_norm": 0.024626854807138443, "test_error": 0.9}, {"epoch": 217, "train_loss": 2.3083660878737766, "grad_norm": 0.04270098730921745, "test_error": 0.9}, {"epoch": 218, "train_loss": 2.3083861739238105, "grad_norm": 0.03493131697177887, "test_error": 0.9}, {"epoch": 219, "train_loss": 2.30810929052035, "grad_norm": 0.0280144065618515, "test_error": 0.9}, {"epoch": 220, "train_loss": 2.3081295896371206, "grad_norm": 0.032865241169929504, "test_error": 0.9}, {"epoch": 221, "train_loss": 2.307820420861244, "grad_norm": 0.04387110471725464, "test_error": 0.9}, {"epoch": 222, "train_loss": 2.308383871436119, "grad_norm": 0.03522582724690437, "test_error": 0.9}, {"epoch": 223, "train_loss": 2.3081006191968916, "grad_norm": 0.04232225939631462, "test_error": 0.9}, {"epoch": 224, "train_loss": 2.308132917404175, "grad_norm": 0.024718748405575752, "test_error": 0.9}, {"epoch": 225, "train_loss": 2.3082040578921634, "grad_norm": 0.02781027927994728, "test_error": 0.9}, {"epoch": 226, "train_loss": 2.308322652697563, "grad_norm": 0.02349845878779888, "test_error": 0.9}, {"epoch": 227, "train_loss": 2.30832392680645, "grad_norm": 0.0225417111068964, "test_error": 0.9}, {"epoch": 228, "train_loss": 2.308052355090777, "grad_norm": 0.018664076924324036, "test_error": 0.9}, {"epoch": 229, "train_loss": 2.307896246433258, "grad_norm": 0.04536028951406479, "test_error": 0.9}, {"epoch": 230, "train_loss": 2.308165623664856, "grad_norm": 0.03734841197729111, "test_error": 0.9}, {"epoch": 231, "train_loss": 2.30843624262015, "grad_norm": 0.0245271697640419, "test_error": 0.9}, {"epoch": 232, "train_loss": 2.30806331996123, "grad_norm": 0.028152037411928177, "test_error": 0.9}, {"epoch": 233, "train_loss": 2.3084505472183228, "grad_norm": 0.024177424609661102, "test_error": 0.9}, {"epoch": 234, "train_loss": 2.308218494415283, "grad_norm": 0.04434336721897125, "test_error": 0.9}, {"epoch": 235, "train_loss": 2.3084608021179833, "grad_norm": 0.017200874164700508, "test_error": 0.9}, {"epoch": 236, "train_loss": 2.2038237541715304, "grad_norm": 0.356964111328125, "test_error": 0.8116666666666666}, {"epoch": 237, "train_loss": 2.0689923915266992, "grad_norm": 0.026452958583831787, "test_error": 0.9}, {"epoch": 238, "train_loss": 2.261739409804344, "grad_norm": 0.3669969141483307, "test_error": 0.7670166666666667}, {"epoch": 239, "train_loss": 1.9592977019051712, "grad_norm": 1.6036479473114014, "test_error": 0.79225}, {"epoch": 240, "train_loss": 2.120012418617805, "grad_norm": 0.02693338319659233, "test_error": 0.8999833333333334}, {"epoch": 241, "train_loss": 2.1519072657525538, "grad_norm": 0.08554451912641525, "test_error": 0.8019166666666667}, {"epoch": 242, "train_loss": 2.275540394584338, "grad_norm": 0.02767493575811386, "test_error": 0.9}, {"epoch": 243, "train_loss": 2.3083873746792474, "grad_norm": 0.03090766817331314, "test_error": 0.9}, {"epoch": 244, "train_loss": 2.3083168581724167, "grad_norm": 0.03717416152358055, "test_error": 0.9}, {"epoch": 245, "train_loss": 2.308082985520363, "grad_norm": 0.03123728558421135, "test_error": 0.9}, {"epoch": 246, "train_loss": 2.308654137015343, "grad_norm": 0.0323885977268219, "test_error": 0.9}, {"epoch": 247, "train_loss": 2.308389970262845, "grad_norm": 0.03428729996085167, "test_error": 0.9}, {"epoch": 248, "train_loss": 2.3083850380976996, "grad_norm": 0.03918896242976189, "test_error": 0.9}, {"epoch": 249, "train_loss": 2.308433793306351, "grad_norm": 0.0359879806637764, "test_error": 0.9}, {"epoch": 250, "train_loss": 2.3082271419763565, "grad_norm": 0.03209169954061508, "test_error": 0.9}, {"epoch": 251, "train_loss": 2.308684837818146, "grad_norm": 0.04794557765126228, "test_error": 0.9}, {"epoch": 252, "train_loss": 2.3086111165682475, "grad_norm": 0.027112960815429688, "test_error": 0.9}, {"epoch": 253, "train_loss": 2.308297769943873, "grad_norm": 0.025530969724059105, "test_error": 0.9}, {"epoch": 254, "train_loss": 2.3083590075969695, "grad_norm": 0.04251145198941231, "test_error": 0.9}, {"epoch": 255, "train_loss": 2.3081502024730045, "grad_norm": 0.026955632492899895, "test_error": 0.9}, {"epoch": 256, "train_loss": 2.307746619025866, "grad_norm": 0.03205498307943344, "test_error": 0.9}, {"epoch": 257, "train_loss": 2.3085925486882526, "grad_norm": 0.041397593915462494, "test_error": 0.9}, {"epoch": 258, "train_loss": 2.3083069356282553, "grad_norm": 0.030661500990390778, "test_error": 0.9}, {"epoch": 259, "train_loss": 2.308190865119298, "grad_norm": 0.03840193897485733, "test_error": 0.9}, {"epoch": 260, "train_loss": 2.3079647184610366, "grad_norm": 0.037744905799627304, "test_error": 0.9}, {"epoch": 261, "train_loss": 2.3084699771404265, "grad_norm": 0.02380439080297947, "test_error": 0.9}, {"epoch": 262, "train_loss": 2.3081751408179603, "grad_norm": 0.024537166580557823, "test_error": 0.9}, {"epoch": 263, "train_loss": 2.3081071436405183, "grad_norm": 0.026787646114826202, "test_error": 0.9}, {"epoch": 264, "train_loss": 2.30838085325559, "grad_norm": 0.024308647960424423, "test_error": 0.9}, {"epoch": 265, "train_loss": 2.3081030549605686, "grad_norm": 0.01999581977725029, "test_error": 0.9}, {"epoch": 266, "train_loss": 2.3082761051654814, "grad_norm": 0.025277001783251762, "test_error": 0.9}, {"epoch": 267, "train_loss": 2.308571595152219, "grad_norm": 0.03114212304353714, "test_error": 0.9}, {"epoch": 268, "train_loss": 2.3085380216439564, "grad_norm": 0.04605947807431221, "test_error": 0.9}, {"epoch": 269, "train_loss": 2.308621915578842, "grad_norm": 0.0311434268951416, "test_error": 0.9}, {"epoch": 270, "train_loss": 2.3083464012145996, "grad_norm": 0.02330745942890644, "test_error": 0.9}, {"epoch": 271, "train_loss": 2.308692888577779, "grad_norm": 0.043079596012830734, "test_error": 0.9}, {"epoch": 272, "train_loss": 2.3086509534517923, "grad_norm": 0.022660596296191216, "test_error": 0.9}, {"epoch": 273, "train_loss": 2.3083308807611465, "grad_norm": 0.030761675909161568, "test_error": 0.9}, {"epoch": 274, "train_loss": 2.3082749668359757, "grad_norm": 0.02130381017923355, "test_error": 0.9}, {"epoch": 275, "train_loss": 2.308105985800425, "grad_norm": 0.020397339016199112, "test_error": 0.9}, {"epoch": 276, "train_loss": 2.308076979438464, "grad_norm": 0.04180217161774635, "test_error": 0.9}, {"epoch": 277, "train_loss": 2.307897365172704, "grad_norm": 0.028719445690512657, "test_error": 0.9}, {"epoch": 278, "train_loss": 2.308540297905604, "grad_norm": 0.0223170705139637, "test_error": 0.9}, {"epoch": 279, "train_loss": 2.3084416680733364, "grad_norm": 0.03355031833052635, "test_error": 0.9}, {"epoch": 280, "train_loss": 2.3084055813153586, "grad_norm": 0.023829787969589233, "test_error": 0.9}, {"epoch": 281, "train_loss": 2.308725050568581, "grad_norm": 0.04125692695379257, "test_error": 0.9}, {"epoch": 282, "train_loss": 2.308463716228803, "grad_norm": 0.04004059359431267, "test_error": 0.9}, {"epoch": 283, "train_loss": 2.3081849489212036, "grad_norm": 0.03827743977308273, "test_error": 0.9}, {"epoch": 284, "train_loss": 2.307974302172661, "grad_norm": 0.03444764018058777, "test_error": 0.9}, {"epoch": 285, "train_loss": 2.3078440839846928, "grad_norm": 0.027043260633945465, "test_error": 0.9}, {"epoch": 286, "train_loss": 2.308189332286517, "grad_norm": 0.03588022664189339, "test_error": 0.9}, {"epoch": 287, "train_loss": 2.3088277967770896, "grad_norm": 0.023632658645510674, "test_error": 0.9}, {"epoch": 288, "train_loss": 2.3085315551757812, "grad_norm": 0.024596165865659714, "test_error": 0.9}, {"epoch": 289, "train_loss": 2.308321746945381, "grad_norm": 0.02729576826095581, "test_error": 0.9}, {"epoch": 290, "train_loss": 2.30805891986688, "grad_norm": 0.03679478541016579, "test_error": 0.9}, {"epoch": 291, "train_loss": 2.3079777651627857, "grad_norm": 0.03124828450381756, "test_error": 0.9}, {"epoch": 292, "train_loss": 2.3084987011353175, "grad_norm": 0.026515310630202293, "test_error": 0.9}, {"epoch": 293, "train_loss": 2.3082963695128758, "grad_norm": 0.030894732102751732, "test_error": 0.9}, {"epoch": 294, "train_loss": 2.308381413857142, "grad_norm": 0.029984157532453537, "test_error": 0.9}, {"epoch": 295, "train_loss": 2.3082440627415974, "grad_norm": 0.02689824439585209, "test_error": 0.9}, {"epoch": 296, "train_loss": 2.308566475311915, "grad_norm": 0.044182367622852325, "test_error": 0.9}, {"epoch": 297, "train_loss": 2.3079736749331157, "grad_norm": 0.04369619861245155, "test_error": 0.9}, {"epoch": 298, "train_loss": 2.3083584175109864, "grad_norm": 0.025043847039341927, "test_error": 0.9}, {"epoch": 299, "train_loss": 2.3086391166051228, "grad_norm": 0.032698746770620346, "test_error": 0.9}, {"epoch": 300, "train_loss": 2.3084079219102858, "grad_norm": 0.042982373386621475, "test_error": 0.9}]}