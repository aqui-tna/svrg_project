{"argv": ["train.py", "--seed", "12", "--optimizer", "SGD", "--run_name", "sgd_0.5.json", "--output_path", "experiments/nonconvex_fmnist/sgd-0.5.json", "--dataset", "FMNIST", "--layer_sizes", "784", "100", "10", "--batch_size", "10", "--learning_rate", "0.5", "--weight_decay", "0.001", "--num_epochs", "300", "--download", "--device", "cuda"], "args": {"seed": 12, "optimizer": "SGD", "run_name": "sgd_0.5.json", "output_path": "experiments/nonconvex_fmnist/sgd-0.5.json", "device": "cuda", "dataset": "FMNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": true, "layer_sizes": [784, 100, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.5, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 2.203925753692786, "grad_norm": 0.06348318606615067, "test_error": 0.9}, {"epoch": 2, "train_loss": 2.3057382551630337, "grad_norm": 0.03383183106780052, "test_error": 0.9}, {"epoch": 3, "train_loss": 2.2597016938328744, "grad_norm": 0.3520197868347168, "test_error": 0.8009666666666667}, {"epoch": 4, "train_loss": 2.308452622652054, "grad_norm": 0.04897493124008179, "test_error": 0.8999833333333334}, {"epoch": 5, "train_loss": 2.306851287841797, "grad_norm": 0.058907944709062576, "test_error": 0.9}, {"epoch": 6, "train_loss": 2.3097587668498356, "grad_norm": 0.03423542156815529, "test_error": 0.9}, {"epoch": 7, "train_loss": 2.300811615983645, "grad_norm": 0.044860124588012695, "test_error": 0.9}, {"epoch": 8, "train_loss": 2.3141647992531458, "grad_norm": 0.046321455389261246, "test_error": 0.9}, {"epoch": 9, "train_loss": 2.3141095061302184, "grad_norm": 0.044996801763772964, "test_error": 0.9}, {"epoch": 10, "train_loss": 2.3138857738574345, "grad_norm": 0.04624900221824646, "test_error": 0.9}, {"epoch": 11, "train_loss": 2.3139916189511616, "grad_norm": 0.05068209022283554, "test_error": 0.9}, {"epoch": 12, "train_loss": 2.3144062063296635, "grad_norm": 0.050560589879751205, "test_error": 0.9}, {"epoch": 13, "train_loss": 2.31392969250679, "grad_norm": 0.05480657517910004, "test_error": 0.9}, {"epoch": 14, "train_loss": 2.3142585901021957, "grad_norm": 0.042667705565690994, "test_error": 0.9}, {"epoch": 15, "train_loss": 2.314135069330533, "grad_norm": 0.05351761728525162, "test_error": 0.9}, {"epoch": 16, "train_loss": 2.314827004949252, "grad_norm": 0.055169727653265, "test_error": 0.9}, {"epoch": 17, "train_loss": 2.3146623780727387, "grad_norm": 0.03443092107772827, "test_error": 0.9}, {"epoch": 18, "train_loss": 2.314542017022769, "grad_norm": 0.04827437922358513, "test_error": 0.9}, {"epoch": 19, "train_loss": 2.3135847264528273, "grad_norm": 0.054794490337371826, "test_error": 0.9}, {"epoch": 20, "train_loss": 2.3137177268266678, "grad_norm": 0.04023861140012741, "test_error": 0.9}, {"epoch": 21, "train_loss": 2.3146003798246384, "grad_norm": 0.04265737161040306, "test_error": 0.9}, {"epoch": 22, "train_loss": 2.313430853764216, "grad_norm": 0.04988884553313255, "test_error": 0.9}, {"epoch": 23, "train_loss": 2.3141863930622737, "grad_norm": 0.0492706224322319, "test_error": 0.9}, {"epoch": 24, "train_loss": 2.313908176501592, "grad_norm": 0.07763346284627914, "test_error": 0.9}, {"epoch": 25, "train_loss": 2.313655134518941, "grad_norm": 0.04582221806049347, "test_error": 0.9}, {"epoch": 26, "train_loss": 2.313767266194026, "grad_norm": 0.06146256625652313, "test_error": 0.9}, {"epoch": 27, "train_loss": 2.314398025751114, "grad_norm": 0.04408237338066101, "test_error": 0.9}, {"epoch": 28, "train_loss": 2.314079444328944, "grad_norm": 0.05279047414660454, "test_error": 0.9}, {"epoch": 29, "train_loss": 2.3144049594004947, "grad_norm": 0.05525926500558853, "test_error": 0.9}, {"epoch": 30, "train_loss": 2.3145802951256433, "grad_norm": 0.040352415293455124, "test_error": 0.9}, {"epoch": 31, "train_loss": 2.314150866945585, "grad_norm": 0.033421244472265244, "test_error": 0.9}, {"epoch": 32, "train_loss": 2.3136725700100262, "grad_norm": 0.06450598686933517, "test_error": 0.9}, {"epoch": 33, "train_loss": 2.3143085401058197, "grad_norm": 0.035731516778469086, "test_error": 0.9}, {"epoch": 34, "train_loss": 2.3137746183872223, "grad_norm": 0.05579753965139389, "test_error": 0.9}, {"epoch": 35, "train_loss": 2.3128045688072842, "grad_norm": 0.053556300699710846, "test_error": 0.9}, {"epoch": 36, "train_loss": 2.3140544780890147, "grad_norm": 0.03917882964015007, "test_error": 0.9}, {"epoch": 37, "train_loss": 2.3141203372478487, "grad_norm": 0.04729601368308067, "test_error": 0.9}, {"epoch": 38, "train_loss": 2.3142970533370972, "grad_norm": 0.06285563856363297, "test_error": 0.9}, {"epoch": 39, "train_loss": 2.313999956389268, "grad_norm": 0.02925127185881138, "test_error": 0.9}, {"epoch": 40, "train_loss": 2.314071537415187, "grad_norm": 0.05325079336762428, "test_error": 0.9}, {"epoch": 41, "train_loss": 2.313957541426023, "grad_norm": 0.02625490352511406, "test_error": 0.9}, {"epoch": 42, "train_loss": 2.314489062865575, "grad_norm": 0.04270216450095177, "test_error": 0.9}, {"epoch": 43, "train_loss": 2.3143906149466833, "grad_norm": 0.02093137800693512, "test_error": 0.9}, {"epoch": 44, "train_loss": 2.314018491983414, "grad_norm": 0.046528059989213943, "test_error": 0.9}, {"epoch": 45, "train_loss": 2.3146630127429964, "grad_norm": 0.029344776645302773, "test_error": 0.9}, {"epoch": 46, "train_loss": 2.3142563589811327, "grad_norm": 0.04911082983016968, "test_error": 0.9}, {"epoch": 47, "train_loss": 2.3140596777200697, "grad_norm": 0.026196129620075226, "test_error": 0.9}, {"epoch": 48, "train_loss": 2.314231015761693, "grad_norm": 0.03967326134443283, "test_error": 0.9}, {"epoch": 49, "train_loss": 2.3137917982737224, "grad_norm": 0.06597993522882462, "test_error": 0.9}, {"epoch": 50, "train_loss": 2.3141936452786127, "grad_norm": 0.07584121823310852, "test_error": 0.9}, {"epoch": 51, "train_loss": 2.3135531969070433, "grad_norm": 0.06920357793569565, "test_error": 0.9}, {"epoch": 52, "train_loss": 2.3139148741761844, "grad_norm": 0.045622386038303375, "test_error": 0.9}, {"epoch": 53, "train_loss": 2.3142230117321017, "grad_norm": 0.05104972794651985, "test_error": 0.9}, {"epoch": 54, "train_loss": 2.313843723217646, "grad_norm": 0.04926292225718498, "test_error": 0.9}, {"epoch": 55, "train_loss": 2.314267703215281, "grad_norm": 0.04904941841959953, "test_error": 0.9}, {"epoch": 56, "train_loss": 2.313987579862277, "grad_norm": 0.042255815118551254, "test_error": 0.9}, {"epoch": 57, "train_loss": 2.3144131519794464, "grad_norm": 0.030129067599773407, "test_error": 0.9}, {"epoch": 58, "train_loss": 2.314261113087336, "grad_norm": 0.05123501643538475, "test_error": 0.9}, {"epoch": 59, "train_loss": 2.3144312250614165, "grad_norm": 0.05140780657529831, "test_error": 0.9}, {"epoch": 60, "train_loss": 2.3138318851391473, "grad_norm": 0.03574433922767639, "test_error": 0.9}, {"epoch": 61, "train_loss": 2.3141304188569385, "grad_norm": 0.04560280963778496, "test_error": 0.9}, {"epoch": 62, "train_loss": 2.3143424489498137, "grad_norm": 0.046778589487075806, "test_error": 0.9}, {"epoch": 63, "train_loss": 2.3135011354287465, "grad_norm": 0.051354262977838516, "test_error": 0.9}, {"epoch": 64, "train_loss": 2.3133160231510796, "grad_norm": 0.06734749674797058, "test_error": 0.9}, {"epoch": 65, "train_loss": 2.314211562712987, "grad_norm": 0.05868624523282051, "test_error": 0.9}, {"epoch": 66, "train_loss": 2.31399186005195, "grad_norm": 0.05392523854970932, "test_error": 0.9}, {"epoch": 67, "train_loss": 2.3143661381403606, "grad_norm": 0.057582609355449677, "test_error": 0.9}, {"epoch": 68, "train_loss": 2.314225518544515, "grad_norm": 0.04114844650030136, "test_error": 0.9}, {"epoch": 69, "train_loss": 2.3142073210080465, "grad_norm": 0.04095958545804024, "test_error": 0.9}, {"epoch": 70, "train_loss": 2.3137422374486922, "grad_norm": 0.04768664017319679, "test_error": 0.9}, {"epoch": 71, "train_loss": 2.3144361360470453, "grad_norm": 0.058648042380809784, "test_error": 0.9}, {"epoch": 72, "train_loss": 2.314325206398964, "grad_norm": 0.04422638937830925, "test_error": 0.9}, {"epoch": 73, "train_loss": 2.3140428475141523, "grad_norm": 0.04105830937623978, "test_error": 0.9}, {"epoch": 74, "train_loss": 2.314278876900673, "grad_norm": 0.03555623069405556, "test_error": 0.9}, {"epoch": 75, "train_loss": 2.314288879195849, "grad_norm": 0.052002206444740295, "test_error": 0.9}, {"epoch": 76, "train_loss": 2.3138637918233873, "grad_norm": 0.03526744246482849, "test_error": 0.9}, {"epoch": 77, "train_loss": 2.3139684981107713, "grad_norm": 0.0244042556732893, "test_error": 0.9}, {"epoch": 78, "train_loss": 2.3144569600025813, "grad_norm": 0.04110401123762131, "test_error": 0.9}, {"epoch": 79, "train_loss": 2.3139530929724375, "grad_norm": 0.029607554897665977, "test_error": 0.9}, {"epoch": 80, "train_loss": 2.3141597021420797, "grad_norm": 0.05440931394696236, "test_error": 0.9}, {"epoch": 81, "train_loss": 2.314291956504186, "grad_norm": 0.04290885478258133, "test_error": 0.9}, {"epoch": 82, "train_loss": 2.3137935992678007, "grad_norm": 0.05608350411057472, "test_error": 0.9}, {"epoch": 83, "train_loss": 2.3141954810619354, "grad_norm": 0.04426812008023262, "test_error": 0.9}, {"epoch": 84, "train_loss": 2.314634683251381, "grad_norm": 0.04891689494252205, "test_error": 0.9}, {"epoch": 85, "train_loss": 2.314252696990967, "grad_norm": 0.05074479430913925, "test_error": 0.9}, {"epoch": 86, "train_loss": 2.3144508652687072, "grad_norm": 0.047285567969083786, "test_error": 0.9}, {"epoch": 87, "train_loss": 2.314096274693807, "grad_norm": 0.053743310272693634, "test_error": 0.9}, {"epoch": 88, "train_loss": 2.314446896115939, "grad_norm": 0.04344549775123596, "test_error": 0.9}, {"epoch": 89, "train_loss": 2.313795339425405, "grad_norm": 0.05436372756958008, "test_error": 0.9}, {"epoch": 90, "train_loss": 2.3138511863152185, "grad_norm": 0.04910425469279289, "test_error": 0.9}, {"epoch": 91, "train_loss": 2.3142131623029707, "grad_norm": 0.03244442865252495, "test_error": 0.9}, {"epoch": 92, "train_loss": 2.31372199289004, "grad_norm": 0.04232998192310333, "test_error": 0.9}, {"epoch": 93, "train_loss": 2.3132732577721278, "grad_norm": 0.036626942455768585, "test_error": 0.9}, {"epoch": 94, "train_loss": 2.314635434190432, "grad_norm": 0.021731942892074585, "test_error": 0.9}, {"epoch": 95, "train_loss": 2.3138654131889345, "grad_norm": 0.058057092130184174, "test_error": 0.9}, {"epoch": 96, "train_loss": 2.3139540947675705, "grad_norm": 0.05680704861879349, "test_error": 0.9}, {"epoch": 97, "train_loss": 2.313928779244423, "grad_norm": 0.03127063438296318, "test_error": 0.9}, {"epoch": 98, "train_loss": 2.3142528766791024, "grad_norm": 0.041056107729673386, "test_error": 0.9}, {"epoch": 99, "train_loss": 2.314410365700722, "grad_norm": 0.04018017649650574, "test_error": 0.9}, {"epoch": 100, "train_loss": 2.3136257783969243, "grad_norm": 0.054265860468149185, "test_error": 0.9}, {"epoch": 101, "train_loss": 2.3137686690092085, "grad_norm": 0.049140024930238724, "test_error": 0.9}, {"epoch": 102, "train_loss": 2.3139276726643243, "grad_norm": 0.03201625496149063, "test_error": 0.9}, {"epoch": 103, "train_loss": 2.3141956789890927, "grad_norm": 0.047428905963897705, "test_error": 0.9}, {"epoch": 104, "train_loss": 2.3139439390500387, "grad_norm": 0.03526148945093155, "test_error": 0.9}, {"epoch": 105, "train_loss": 2.31355602145195, "grad_norm": 0.07847767323255539, "test_error": 0.9}, {"epoch": 106, "train_loss": 2.3142455091873804, "grad_norm": 0.030565310269594193, "test_error": 0.9}, {"epoch": 107, "train_loss": 2.3140884535312654, "grad_norm": 0.04034387692809105, "test_error": 0.9}, {"epoch": 108, "train_loss": 2.3132708223263423, "grad_norm": 0.03875434398651123, "test_error": 0.9}, {"epoch": 109, "train_loss": 2.313678625504176, "grad_norm": 0.04802246019244194, "test_error": 0.9}, {"epoch": 110, "train_loss": 2.313810948610306, "grad_norm": 0.06506763398647308, "test_error": 0.9}, {"epoch": 111, "train_loss": 2.313813006321589, "grad_norm": 0.047509342432022095, "test_error": 0.9}, {"epoch": 112, "train_loss": 2.3144684739510217, "grad_norm": 0.01927151344716549, "test_error": 0.9}, {"epoch": 113, "train_loss": 2.3132896035512287, "grad_norm": 0.03714179992675781, "test_error": 0.9}, {"epoch": 114, "train_loss": 2.3137983876864117, "grad_norm": 0.05091241002082825, "test_error": 0.9}, {"epoch": 115, "train_loss": 2.3131131836970646, "grad_norm": 0.04045388102531433, "test_error": 0.9}, {"epoch": 116, "train_loss": 2.313895189960798, "grad_norm": 0.05599566176533699, "test_error": 0.9}, {"epoch": 117, "train_loss": 2.3140050144195556, "grad_norm": 0.026689335703849792, "test_error": 0.9}, {"epoch": 118, "train_loss": 2.313645200133324, "grad_norm": 0.05447578802704811, "test_error": 0.9}, {"epoch": 119, "train_loss": 2.3143002440134683, "grad_norm": 0.022668534889817238, "test_error": 0.9}, {"epoch": 120, "train_loss": 2.314478959997495, "grad_norm": 0.07107703387737274, "test_error": 0.9}, {"epoch": 121, "train_loss": 2.313892441987991, "grad_norm": 0.0694417804479599, "test_error": 0.9}, {"epoch": 122, "train_loss": 2.3137927393118543, "grad_norm": 0.045887384563684464, "test_error": 0.9}, {"epoch": 123, "train_loss": 2.31416144267718, "grad_norm": 0.05258423462510109, "test_error": 0.9}, {"epoch": 124, "train_loss": 2.314088876406352, "grad_norm": 0.029438093304634094, "test_error": 0.9}, {"epoch": 125, "train_loss": 2.314344998280207, "grad_norm": 0.03288505971431732, "test_error": 0.9}, {"epoch": 126, "train_loss": 2.3139908336400987, "grad_norm": 0.04521143063902855, "test_error": 0.9}, {"epoch": 127, "train_loss": 2.3136467175086337, "grad_norm": 0.04763383790850639, "test_error": 0.9}, {"epoch": 128, "train_loss": 2.3141526688337324, "grad_norm": 0.053405195474624634, "test_error": 0.9}, {"epoch": 129, "train_loss": 2.3142850833733877, "grad_norm": 0.03255392611026764, "test_error": 0.9}, {"epoch": 130, "train_loss": 2.3137943472067515, "grad_norm": 0.043852273374795914, "test_error": 0.9}, {"epoch": 131, "train_loss": 2.3138959212700527, "grad_norm": 0.051384735852479935, "test_error": 0.9}, {"epoch": 132, "train_loss": 2.3141366752386094, "grad_norm": 0.043280504643917084, "test_error": 0.9}, {"epoch": 133, "train_loss": 2.3141360694169997, "grad_norm": 0.05151194706559181, "test_error": 0.9}, {"epoch": 134, "train_loss": 2.3138989637295406, "grad_norm": 0.03905755653977394, "test_error": 0.9}, {"epoch": 135, "train_loss": 2.313779305259387, "grad_norm": 0.07454867660999298, "test_error": 0.9}, {"epoch": 136, "train_loss": 2.3143927907943724, "grad_norm": 0.04809892550110817, "test_error": 0.9}, {"epoch": 137, "train_loss": 2.31457336662213, "grad_norm": 0.03557536005973816, "test_error": 0.9}, {"epoch": 138, "train_loss": 2.3142694767713547, "grad_norm": 0.05530155822634697, "test_error": 0.9}, {"epoch": 139, "train_loss": 2.3138709794282915, "grad_norm": 0.05271143838763237, "test_error": 0.9}, {"epoch": 140, "train_loss": 2.3134064357280733, "grad_norm": 0.06178393214941025, "test_error": 0.9}, {"epoch": 141, "train_loss": 2.3142995485464732, "grad_norm": 0.07164506614208221, "test_error": 0.9}, {"epoch": 142, "train_loss": 2.3141354118188224, "grad_norm": 0.04359925910830498, "test_error": 0.9}, {"epoch": 143, "train_loss": 2.31401814186573, "grad_norm": 0.0539981834590435, "test_error": 0.9}, {"epoch": 144, "train_loss": 2.314112468957901, "grad_norm": 0.06240183860063553, "test_error": 0.9}, {"epoch": 145, "train_loss": 2.3142275711695355, "grad_norm": 0.039221059530973434, "test_error": 0.9}, {"epoch": 146, "train_loss": 2.3138209098974865, "grad_norm": 0.05547933652997017, "test_error": 0.9}, {"epoch": 147, "train_loss": 2.314398990233739, "grad_norm": 0.051402248442173004, "test_error": 0.9}, {"epoch": 148, "train_loss": 2.3140549567540485, "grad_norm": 0.029335085302591324, "test_error": 0.9}, {"epoch": 149, "train_loss": 2.3135736481348674, "grad_norm": 0.07944994419813156, "test_error": 0.9}, {"epoch": 150, "train_loss": 2.3138095741669336, "grad_norm": 0.05982140824198723, "test_error": 0.9}, {"epoch": 151, "train_loss": 2.3142028455734254, "grad_norm": 0.053675949573516846, "test_error": 0.9}, {"epoch": 152, "train_loss": 2.3140469553470613, "grad_norm": 0.04083302617073059, "test_error": 0.9}, {"epoch": 153, "train_loss": 2.3142098629077275, "grad_norm": 0.03938564285635948, "test_error": 0.9}, {"epoch": 154, "train_loss": 2.3147288430929183, "grad_norm": 0.04178675636649132, "test_error": 0.9}, {"epoch": 155, "train_loss": 2.3144899059534074, "grad_norm": 0.059051498770713806, "test_error": 0.9}, {"epoch": 156, "train_loss": 2.314643072883288, "grad_norm": 0.05191187188029289, "test_error": 0.9}, {"epoch": 157, "train_loss": 2.3139568184614183, "grad_norm": 0.06741194427013397, "test_error": 0.9}, {"epoch": 158, "train_loss": 2.313881712039312, "grad_norm": 0.03350261226296425, "test_error": 0.9}, {"epoch": 159, "train_loss": 2.314554095029831, "grad_norm": 0.04404524713754654, "test_error": 0.9}, {"epoch": 160, "train_loss": 2.313896568576495, "grad_norm": 0.07083026319742203, "test_error": 0.9}, {"epoch": 161, "train_loss": 2.3141788987318677, "grad_norm": 0.044078487902879715, "test_error": 0.9}, {"epoch": 162, "train_loss": 2.3139156584739684, "grad_norm": 0.04717376455664635, "test_error": 0.9}, {"epoch": 163, "train_loss": 2.3147694505055747, "grad_norm": 0.04744052141904831, "test_error": 0.9}, {"epoch": 164, "train_loss": 2.313815985918045, "grad_norm": 0.03205423429608345, "test_error": 0.9}, {"epoch": 165, "train_loss": 2.3140122751394907, "grad_norm": 0.04041017219424248, "test_error": 0.9}, {"epoch": 166, "train_loss": 2.3141228115558623, "grad_norm": 0.04364088550209999, "test_error": 0.9}, {"epoch": 167, "train_loss": 2.314941451907158, "grad_norm": 0.05269143730401993, "test_error": 0.9}, {"epoch": 168, "train_loss": 2.314457328438759, "grad_norm": 0.031351227313280106, "test_error": 0.9}, {"epoch": 169, "train_loss": 2.3134939827124277, "grad_norm": 0.04345136880874634, "test_error": 0.9}, {"epoch": 170, "train_loss": 2.314113650361697, "grad_norm": 0.035945042967796326, "test_error": 0.9}, {"epoch": 171, "train_loss": 2.313966530243556, "grad_norm": 0.04633944854140282, "test_error": 0.9}, {"epoch": 172, "train_loss": 2.314233670671781, "grad_norm": 0.031903598457574844, "test_error": 0.9}, {"epoch": 173, "train_loss": 2.3137893826564153, "grad_norm": 0.04789193719625473, "test_error": 0.9}, {"epoch": 174, "train_loss": 2.3142516087293625, "grad_norm": 0.043967895209789276, "test_error": 0.9}, {"epoch": 175, "train_loss": 2.3136966301997504, "grad_norm": 0.0758063867688179, "test_error": 0.9}, {"epoch": 176, "train_loss": 2.314435827414195, "grad_norm": 0.04906430467963219, "test_error": 0.9}, {"epoch": 177, "train_loss": 2.3144001372655234, "grad_norm": 0.03675319626927376, "test_error": 0.9}, {"epoch": 178, "train_loss": 2.3144210028648375, "grad_norm": 0.04825131967663765, "test_error": 0.9}, {"epoch": 179, "train_loss": 2.314459356546402, "grad_norm": 0.036337364464998245, "test_error": 0.9}, {"epoch": 180, "train_loss": 2.313869484583537, "grad_norm": 0.04059627279639244, "test_error": 0.9}, {"epoch": 181, "train_loss": 2.3140096065600715, "grad_norm": 0.04950733855366707, "test_error": 0.9}, {"epoch": 182, "train_loss": 2.314298786004384, "grad_norm": 0.05206893011927605, "test_error": 0.9}, {"epoch": 183, "train_loss": 2.31375608030955, "grad_norm": 0.062012869864702225, "test_error": 0.9}, {"epoch": 184, "train_loss": 2.3141859790881476, "grad_norm": 0.05503304675221443, "test_error": 0.9}, {"epoch": 185, "train_loss": 2.3142463970581693, "grad_norm": 0.04690760746598244, "test_error": 0.9}, {"epoch": 186, "train_loss": 2.3134419029951094, "grad_norm": 0.04919452965259552, "test_error": 0.9}, {"epoch": 187, "train_loss": 2.3147509363094967, "grad_norm": 0.03261546045541763, "test_error": 0.9}, {"epoch": 188, "train_loss": 2.3143016308546067, "grad_norm": 0.04429095610976219, "test_error": 0.9}, {"epoch": 189, "train_loss": 2.3147246558268866, "grad_norm": 0.06448796391487122, "test_error": 0.9}, {"epoch": 190, "train_loss": 2.3141772454977034, "grad_norm": 0.04727781191468239, "test_error": 0.9}, {"epoch": 191, "train_loss": 2.313951179464658, "grad_norm": 0.030048562213778496, "test_error": 0.9}, {"epoch": 192, "train_loss": 2.3141619052489597, "grad_norm": 0.03907913342118263, "test_error": 0.9}, {"epoch": 193, "train_loss": 2.314327039639155, "grad_norm": 0.03935794159770012, "test_error": 0.9}, {"epoch": 194, "train_loss": 2.3141310501495997, "grad_norm": 0.031230876222252846, "test_error": 0.9}, {"epoch": 195, "train_loss": 2.313856159051259, "grad_norm": 0.043160390108823776, "test_error": 0.9}, {"epoch": 196, "train_loss": 2.314118740797043, "grad_norm": 0.043321818113327026, "test_error": 0.9}, {"epoch": 197, "train_loss": 2.313606697837512, "grad_norm": 0.06201311945915222, "test_error": 0.9}, {"epoch": 198, "train_loss": 2.3141419960657754, "grad_norm": 0.05076444149017334, "test_error": 0.9}, {"epoch": 199, "train_loss": 2.3135410915613175, "grad_norm": 0.039019595831632614, "test_error": 0.9}, {"epoch": 200, "train_loss": 2.3147181013425193, "grad_norm": 0.02936534769833088, "test_error": 0.9}, {"epoch": 201, "train_loss": 2.3142185188531874, "grad_norm": 0.03564578294754028, "test_error": 0.9}, {"epoch": 202, "train_loss": 2.3141058048009873, "grad_norm": 0.04602814465761185, "test_error": 0.9}, {"epoch": 203, "train_loss": 2.3140744655927024, "grad_norm": 0.05527167022228241, "test_error": 0.9}, {"epoch": 204, "train_loss": 2.3133248705069223, "grad_norm": 0.04711492732167244, "test_error": 0.9}, {"epoch": 205, "train_loss": 2.313975495060285, "grad_norm": 0.03643475100398064, "test_error": 0.9}, {"epoch": 206, "train_loss": 2.314095568259557, "grad_norm": 0.04055657982826233, "test_error": 0.9}, {"epoch": 207, "train_loss": 2.3138476288715997, "grad_norm": 0.05235964432358742, "test_error": 0.9}, {"epoch": 208, "train_loss": 2.3137342346111933, "grad_norm": 0.05840322747826576, "test_error": 0.9}, {"epoch": 209, "train_loss": 2.3139724817673364, "grad_norm": 0.048552051186561584, "test_error": 0.9}, {"epoch": 210, "train_loss": 2.3140147924423218, "grad_norm": 0.04765544459223747, "test_error": 0.9}, {"epoch": 211, "train_loss": 2.314370067795118, "grad_norm": 0.05863506719470024, "test_error": 0.9}, {"epoch": 212, "train_loss": 2.314152072350184, "grad_norm": 0.03538801148533821, "test_error": 0.9}, {"epoch": 213, "train_loss": 2.313908704360326, "grad_norm": 0.051668502390384674, "test_error": 0.9}, {"epoch": 214, "train_loss": 2.3141393411159514, "grad_norm": 0.03128492832183838, "test_error": 0.9}, {"epoch": 215, "train_loss": 2.314317360917727, "grad_norm": 0.038818228989839554, "test_error": 0.9}, {"epoch": 216, "train_loss": 2.3138982806603114, "grad_norm": 0.029797906056046486, "test_error": 0.9}, {"epoch": 217, "train_loss": 2.3142069048086804, "grad_norm": 0.0634438619017601, "test_error": 0.9}, {"epoch": 218, "train_loss": 2.3141695056358973, "grad_norm": 0.05220908299088478, "test_error": 0.9}, {"epoch": 219, "train_loss": 2.3138501766522723, "grad_norm": 0.04623161256313324, "test_error": 0.9}, {"epoch": 220, "train_loss": 2.313993138988813, "grad_norm": 0.04084474593400955, "test_error": 0.9}, {"epoch": 221, "train_loss": 2.313398758292198, "grad_norm": 0.05591781064867973, "test_error": 0.9}, {"epoch": 222, "train_loss": 2.3142322129408517, "grad_norm": 0.04563898220658302, "test_error": 0.9}, {"epoch": 223, "train_loss": 2.3139490227301915, "grad_norm": 0.06934813410043716, "test_error": 0.9}, {"epoch": 224, "train_loss": 2.313730429172516, "grad_norm": 0.032669682055711746, "test_error": 0.9}, {"epoch": 225, "train_loss": 2.31401055820783, "grad_norm": 0.04592287540435791, "test_error": 0.9}, {"epoch": 226, "train_loss": 2.3139686011473337, "grad_norm": 0.041881758719682693, "test_error": 0.9}, {"epoch": 227, "train_loss": 2.3142231854597726, "grad_norm": 0.035150907933712006, "test_error": 0.9}, {"epoch": 228, "train_loss": 2.3135380634069445, "grad_norm": 0.024718595668673515, "test_error": 0.9}, {"epoch": 229, "train_loss": 2.313583034992218, "grad_norm": 0.06262578070163727, "test_error": 0.9}, {"epoch": 230, "train_loss": 2.314085844039917, "grad_norm": 0.05458532273769379, "test_error": 0.9}, {"epoch": 231, "train_loss": 2.314443145831426, "grad_norm": 0.03272362798452377, "test_error": 0.9}, {"epoch": 232, "train_loss": 2.3135783966382344, "grad_norm": 0.03866802155971527, "test_error": 0.9}, {"epoch": 233, "train_loss": 2.314257217446963, "grad_norm": 0.030708279460668564, "test_error": 0.9}, {"epoch": 234, "train_loss": 2.3140253608226775, "grad_norm": 0.06400652229785919, "test_error": 0.9}, {"epoch": 235, "train_loss": 2.314205878297488, "grad_norm": 0.03483426570892334, "test_error": 0.9}, {"epoch": 236, "train_loss": 2.313770052870115, "grad_norm": 0.034309010952711105, "test_error": 0.9}, {"epoch": 237, "train_loss": 2.31371357468764, "grad_norm": 0.0355965755879879, "test_error": 0.9}, {"epoch": 238, "train_loss": 2.3145105058352153, "grad_norm": 0.05935128033161163, "test_error": 0.9}, {"epoch": 239, "train_loss": 2.314094821572304, "grad_norm": 0.03851692005991936, "test_error": 0.9}, {"epoch": 240, "train_loss": 2.314331311742465, "grad_norm": 0.041569024324417114, "test_error": 0.9}, {"epoch": 241, "train_loss": 2.3143673532803852, "grad_norm": 0.0366525873541832, "test_error": 0.9}, {"epoch": 242, "train_loss": 2.314400769551595, "grad_norm": 0.04073933884501457, "test_error": 0.9}, {"epoch": 243, "train_loss": 2.314064957698186, "grad_norm": 0.03946995735168457, "test_error": 0.9}, {"epoch": 244, "train_loss": 2.3141099342505136, "grad_norm": 0.05266350507736206, "test_error": 0.9}, {"epoch": 245, "train_loss": 2.3140056212743123, "grad_norm": 0.040217071771621704, "test_error": 0.9}, {"epoch": 246, "train_loss": 2.3146813216606774, "grad_norm": 0.04602706804871559, "test_error": 0.9}, {"epoch": 247, "train_loss": 2.31428914753596, "grad_norm": 0.04788973554968834, "test_error": 0.9}, {"epoch": 248, "train_loss": 2.314313345472018, "grad_norm": 0.054331451654434204, "test_error": 0.9}, {"epoch": 249, "train_loss": 2.31419491537412, "grad_norm": 0.06724219769239426, "test_error": 0.9}, {"epoch": 250, "train_loss": 2.314066781401634, "grad_norm": 0.050206661224365234, "test_error": 0.9}, {"epoch": 251, "train_loss": 2.314452334364255, "grad_norm": 0.0640406459569931, "test_error": 0.9}, {"epoch": 252, "train_loss": 2.314511274774869, "grad_norm": 0.04364360123872757, "test_error": 0.9}, {"epoch": 253, "train_loss": 2.3141512593428293, "grad_norm": 0.033458907157182693, "test_error": 0.9}, {"epoch": 254, "train_loss": 2.314098547101021, "grad_norm": 0.062399137765169144, "test_error": 0.9}, {"epoch": 255, "train_loss": 2.313801079551379, "grad_norm": 0.0361151248216629, "test_error": 0.9}, {"epoch": 256, "train_loss": 2.3132527083158494, "grad_norm": 0.04493878781795502, "test_error": 0.9}, {"epoch": 257, "train_loss": 2.314388687133789, "grad_norm": 0.05620764568448067, "test_error": 0.9}, {"epoch": 258, "train_loss": 2.3139895862738293, "grad_norm": 0.04657161235809326, "test_error": 0.9}, {"epoch": 259, "train_loss": 2.3139544683297477, "grad_norm": 0.05033295229077339, "test_error": 0.9}, {"epoch": 260, "train_loss": 2.313710133155187, "grad_norm": 0.05190970003604889, "test_error": 0.9}, {"epoch": 261, "train_loss": 2.3143540681997936, "grad_norm": 0.03599436208605766, "test_error": 0.9}, {"epoch": 262, "train_loss": 2.3140708516041437, "grad_norm": 0.03252238780260086, "test_error": 0.9}, {"epoch": 263, "train_loss": 2.3137166970968246, "grad_norm": 0.03440094366669655, "test_error": 0.9}, {"epoch": 264, "train_loss": 2.3144382426341377, "grad_norm": 0.03860868141055107, "test_error": 0.9}, {"epoch": 265, "train_loss": 2.3139617573420206, "grad_norm": 0.03460651636123657, "test_error": 0.9}, {"epoch": 266, "train_loss": 2.314059274196625, "grad_norm": 0.0345027782022953, "test_error": 0.9}, {"epoch": 267, "train_loss": 2.3145033106009167, "grad_norm": 0.050698742270469666, "test_error": 0.9}, {"epoch": 268, "train_loss": 2.314357518633207, "grad_norm": 0.06951139867305756, "test_error": 0.9}, {"epoch": 269, "train_loss": 2.314579462369283, "grad_norm": 0.05136134475469589, "test_error": 0.9}, {"epoch": 270, "train_loss": 2.314187055548032, "grad_norm": 0.028371527791023254, "test_error": 0.9}, {"epoch": 271, "train_loss": 2.3147594814697903, "grad_norm": 0.05865932255983353, "test_error": 0.9}, {"epoch": 272, "train_loss": 2.314425868153572, "grad_norm": 0.036056600511074066, "test_error": 0.9}, {"epoch": 273, "train_loss": 2.31395929257075, "grad_norm": 0.03812553733587265, "test_error": 0.9}, {"epoch": 274, "train_loss": 2.313957312385241, "grad_norm": 0.026290209963917732, "test_error": 0.9}, {"epoch": 275, "train_loss": 2.3136954656442006, "grad_norm": 0.036160193383693695, "test_error": 0.9}, {"epoch": 276, "train_loss": 2.3135279651880265, "grad_norm": 0.06265542656183243, "test_error": 0.9}, {"epoch": 277, "train_loss": 2.31346655189991, "grad_norm": 0.04068244248628616, "test_error": 0.9}, {"epoch": 278, "train_loss": 2.3144060534238817, "grad_norm": 0.0385015532374382, "test_error": 0.9}, {"epoch": 279, "train_loss": 2.314387008269628, "grad_norm": 0.04498385637998581, "test_error": 0.9}, {"epoch": 280, "train_loss": 2.3140999960104622, "grad_norm": 0.03974810242652893, "test_error": 0.9}, {"epoch": 281, "train_loss": 2.3146617571115495, "grad_norm": 0.057874079793691635, "test_error": 0.9}, {"epoch": 282, "train_loss": 2.3143033898274106, "grad_norm": 0.05376359075307846, "test_error": 0.9}, {"epoch": 283, "train_loss": 2.31384256986777, "grad_norm": 0.05314532294869423, "test_error": 0.9}, {"epoch": 284, "train_loss": 2.3135578713417053, "grad_norm": 0.04620715230703354, "test_error": 0.9}, {"epoch": 285, "train_loss": 2.3135422991514205, "grad_norm": 0.04327709227800369, "test_error": 0.9}, {"epoch": 286, "train_loss": 2.3137634741067887, "grad_norm": 0.059673842042684555, "test_error": 0.9}, {"epoch": 287, "train_loss": 2.3149292794466017, "grad_norm": 0.03761769458651543, "test_error": 0.9}, {"epoch": 288, "train_loss": 2.31436416276296, "grad_norm": 0.03951989859342575, "test_error": 0.9}, {"epoch": 289, "train_loss": 2.314076503356298, "grad_norm": 0.03348228707909584, "test_error": 0.9}, {"epoch": 290, "train_loss": 2.313837315917015, "grad_norm": 0.049417007714509964, "test_error": 0.9}, {"epoch": 291, "train_loss": 2.313582982738813, "grad_norm": 0.040786031633615494, "test_error": 0.9}, {"epoch": 292, "train_loss": 2.314391114115715, "grad_norm": 0.03692412003874779, "test_error": 0.9}, {"epoch": 293, "train_loss": 2.3139577230612436, "grad_norm": 0.04371260106563568, "test_error": 0.9}, {"epoch": 294, "train_loss": 2.314090279976527, "grad_norm": 0.0379645936191082, "test_error": 0.9}, {"epoch": 295, "train_loss": 2.313944753408432, "grad_norm": 0.03709255903959274, "test_error": 0.9}, {"epoch": 296, "train_loss": 2.3145539343357084, "grad_norm": 0.06954094767570496, "test_error": 0.9}, {"epoch": 297, "train_loss": 2.3137486842473347, "grad_norm": 0.053194765001535416, "test_error": 0.9}, {"epoch": 298, "train_loss": 2.3140670604308444, "grad_norm": 0.031776584684848785, "test_error": 0.9}, {"epoch": 299, "train_loss": 2.3145883082548777, "grad_norm": 0.04660958796739578, "test_error": 0.9}, {"epoch": 300, "train_loss": 2.3142438759803774, "grad_norm": 0.06066014617681503, "test_error": 0.9}]}