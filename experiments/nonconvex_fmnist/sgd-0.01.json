{"argv": ["train.py", "--seed", "12", "--optimizer", "SGD", "--run_name", "sgd_0.01.json", "--output_path", "experiments/nonconvex_fmnist/sgd-0.01.json", "--dataset", "FMNIST", "--layer_sizes", "784", "100", "10", "--batch_size", "10", "--learning_rate", "0.01", "--weight_decay", "0.001", "--num_epochs", "300", "--download", "--device", "cuda"], "args": {"seed": 12, "optimizer": "SGD", "run_name": "sgd_0.01.json", "output_path": "experiments/nonconvex_fmnist/sgd-0.01.json", "device": "cuda", "dataset": "FMNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": true, "layer_sizes": [784, 100, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.01, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 0.6704693815155576, "grad_norm": 0.6993235945701599, "test_error": 0.17113333333333333}, {"epoch": 2, "train_loss": 0.47147595829765004, "grad_norm": 0.5213921666145325, "test_error": 0.14893333333333333}, {"epoch": 3, "train_loss": 0.4313490278205524, "grad_norm": 0.9235321283340454, "test_error": 0.14863333333333334}, {"epoch": 4, "train_loss": 0.4062976682546238, "grad_norm": 0.9760746955871582, "test_error": 0.14723333333333333}, {"epoch": 5, "train_loss": 0.3897041315653672, "grad_norm": 0.8184413313865662, "test_error": 0.13738333333333333}, {"epoch": 6, "train_loss": 0.3755931604898845, "grad_norm": 0.8774158358573914, "test_error": 0.13148333333333334}, {"epoch": 7, "train_loss": 0.3634238383153764, "grad_norm": 0.38262009620666504, "test_error": 0.11971666666666667}, {"epoch": 8, "train_loss": 0.35594694098845747, "grad_norm": 0.48719337582588196, "test_error": 0.12133333333333333}, {"epoch": 9, "train_loss": 0.3480448515933628, "grad_norm": 0.5470952391624451, "test_error": 0.1207}, {"epoch": 10, "train_loss": 0.3408740118639544, "grad_norm": 0.658075213432312, "test_error": 0.12156666666666667}, {"epoch": 11, "train_loss": 0.3353650523717515, "grad_norm": 0.600338876247406, "test_error": 0.12026666666666666}, {"epoch": 12, "train_loss": 0.3298219432927047, "grad_norm": 0.7406380772590637, "test_error": 0.11451666666666667}, {"epoch": 13, "train_loss": 0.3259951606638885, "grad_norm": 0.37322476506233215, "test_error": 0.11086666666666667}, {"epoch": 14, "train_loss": 0.3213012001832637, "grad_norm": 0.49742692708969116, "test_error": 0.11015}, {"epoch": 15, "train_loss": 0.3166904463423416, "grad_norm": 1.072243094444275, "test_error": 0.12515}, {"epoch": 16, "train_loss": 0.314387940931522, "grad_norm": 0.2361655980348587, "test_error": 0.10498333333333333}, {"epoch": 17, "train_loss": 0.3109990998520516, "grad_norm": 0.24312452971935272, "test_error": 0.10393333333333334}, {"epoch": 18, "train_loss": 0.30765681639507725, "grad_norm": 0.4713471233844757, "test_error": 0.10498333333333333}, {"epoch": 19, "train_loss": 0.3052301303208806, "grad_norm": 0.8666128516197205, "test_error": 0.10981666666666667}, {"epoch": 20, "train_loss": 0.3024310405356033, "grad_norm": 0.545661449432373, "test_error": 0.10701666666666666}, {"epoch": 21, "train_loss": 0.3003557054036452, "grad_norm": 0.22473818063735962, "test_error": 0.09863333333333334}, {"epoch": 22, "train_loss": 0.29837450129616383, "grad_norm": 0.33605602383613586, "test_error": 0.09995}, {"epoch": 23, "train_loss": 0.296603538128625, "grad_norm": 0.3480619788169861, "test_error": 0.09871666666666666}, {"epoch": 24, "train_loss": 0.2935453611879299, "grad_norm": 0.7544030547142029, "test_error": 0.10726666666666666}, {"epoch": 25, "train_loss": 0.2930604690273758, "grad_norm": 0.47509974241256714, "test_error": 0.10021666666666666}, {"epoch": 26, "train_loss": 0.2912620646583382, "grad_norm": 0.3449920415878296, "test_error": 0.0962}, {"epoch": 27, "train_loss": 0.2886971123014421, "grad_norm": 0.3386559784412384, "test_error": 0.09773333333333334}, {"epoch": 28, "train_loss": 0.2880003534439796, "grad_norm": 0.4318285584449768, "test_error": 0.09676666666666667}, {"epoch": 29, "train_loss": 0.28580031864352834, "grad_norm": 0.6278296709060669, "test_error": 0.10088333333333334}, {"epoch": 30, "train_loss": 0.28521656194515527, "grad_norm": 0.5092661380767822, "test_error": 0.09641666666666666}, {"epoch": 31, "train_loss": 0.2837997070933925, "grad_norm": 0.2805711030960083, "test_error": 0.09453333333333333}, {"epoch": 32, "train_loss": 0.28289324637611085, "grad_norm": 0.4636154770851135, "test_error": 0.0975}, {"epoch": 33, "train_loss": 0.281347449134492, "grad_norm": 0.431934118270874, "test_error": 0.09398333333333334}, {"epoch": 34, "train_loss": 0.2798749124039896, "grad_norm": 0.6569331884384155, "test_error": 0.0958}, {"epoch": 35, "train_loss": 0.2794206156478419, "grad_norm": 0.5539928078651428, "test_error": 0.09701666666666667}, {"epoch": 36, "train_loss": 0.27869942497004135, "grad_norm": 0.47928860783576965, "test_error": 0.0948}, {"epoch": 37, "train_loss": 0.27742700240652385, "grad_norm": 0.3097207546234131, "test_error": 0.0929}, {"epoch": 38, "train_loss": 0.2765043802551227, "grad_norm": 0.6286592483520508, "test_error": 0.09536666666666667}, {"epoch": 39, "train_loss": 0.2752931607523933, "grad_norm": 0.42887112498283386, "test_error": 0.09343333333333333}, {"epoch": 40, "train_loss": 0.27405666427950687, "grad_norm": 0.31092748045921326, "test_error": 0.0909}, {"epoch": 41, "train_loss": 0.2740941302640519, "grad_norm": 0.26711565256118774, "test_error": 0.08831666666666667}, {"epoch": 42, "train_loss": 0.2738267593188987, "grad_norm": 0.2573879063129425, "test_error": 0.08875}, {"epoch": 43, "train_loss": 0.27305556420000116, "grad_norm": 0.6370875239372253, "test_error": 0.09381666666666667}, {"epoch": 44, "train_loss": 0.2720397618886006, "grad_norm": 0.3109845221042633, "test_error": 0.08883333333333333}, {"epoch": 45, "train_loss": 0.27164573503510714, "grad_norm": 0.23593641817569733, "test_error": 0.08858333333333333}, {"epoch": 46, "train_loss": 0.2710085229664886, "grad_norm": 0.4894702732563019, "test_error": 0.09231666666666667}, {"epoch": 47, "train_loss": 0.2704326670769757, "grad_norm": 0.3555140793323517, "test_error": 0.08958333333333333}, {"epoch": 48, "train_loss": 0.269972328598223, "grad_norm": 0.5622631907463074, "test_error": 0.09465}, {"epoch": 49, "train_loss": 0.26925952269633613, "grad_norm": 0.47376546263694763, "test_error": 0.09266666666666666}, {"epoch": 50, "train_loss": 0.2688263767271613, "grad_norm": 0.42154574394226074, "test_error": 0.08838333333333333}, {"epoch": 51, "train_loss": 0.2685709481918408, "grad_norm": 0.5182324051856995, "test_error": 0.09071666666666667}, {"epoch": 52, "train_loss": 0.2677934991674653, "grad_norm": 0.45972976088523865, "test_error": 0.09058333333333334}, {"epoch": 53, "train_loss": 0.2667599431080744, "grad_norm": 0.5783998966217041, "test_error": 0.09215}, {"epoch": 54, "train_loss": 0.26741024070694885, "grad_norm": 0.4697653353214264, "test_error": 0.09083333333333334}, {"epoch": 55, "train_loss": 0.26646695176814683, "grad_norm": 0.31301257014274597, "test_error": 0.08648333333333333}, {"epoch": 56, "train_loss": 0.26514256229336997, "grad_norm": 0.5075023174285889, "test_error": 0.09093333333333334}, {"epoch": 57, "train_loss": 0.2658962131566756, "grad_norm": 0.7563183903694153, "test_error": 0.09308333333333334}, {"epoch": 58, "train_loss": 0.26489498102309883, "grad_norm": 0.5849243998527527, "test_error": 0.09051666666666666}, {"epoch": 59, "train_loss": 0.26518572724579526, "grad_norm": 0.3678288757801056, "test_error": 0.08898333333333333}, {"epoch": 60, "train_loss": 0.2646221799820196, "grad_norm": 0.6698145866394043, "test_error": 0.09133333333333334}, {"epoch": 61, "train_loss": 0.26324908929644153, "grad_norm": 0.3731651306152344, "test_error": 0.0863}, {"epoch": 62, "train_loss": 0.2634606828163378, "grad_norm": 0.5597750544548035, "test_error": 0.09115}, {"epoch": 63, "train_loss": 0.26292202304831397, "grad_norm": 0.8217154145240784, "test_error": 0.09406666666666667}, {"epoch": 64, "train_loss": 0.2623364067575894, "grad_norm": 0.3471819758415222, "test_error": 0.08803333333333334}, {"epoch": 65, "train_loss": 0.2628411909944067, "grad_norm": 0.3560876250267029, "test_error": 0.08588333333333334}, {"epoch": 66, "train_loss": 0.2620446340649699, "grad_norm": 0.5351197719573975, "test_error": 0.08855}, {"epoch": 67, "train_loss": 0.26088059638339717, "grad_norm": 0.6765804290771484, "test_error": 0.08746666666666666}, {"epoch": 68, "train_loss": 0.2616015729433857, "grad_norm": 1.178392767906189, "test_error": 0.0979}, {"epoch": 69, "train_loss": 0.261650234396259, "grad_norm": 0.36906230449676514, "test_error": 0.08485}, {"epoch": 70, "train_loss": 0.26187362403822284, "grad_norm": 0.7470918297767639, "test_error": 0.09338333333333333}, {"epoch": 71, "train_loss": 0.2611847792225114, "grad_norm": 0.4799405038356781, "test_error": 0.08823333333333333}, {"epoch": 72, "train_loss": 0.260731986413671, "grad_norm": 0.3785945475101471, "test_error": 0.0879}, {"epoch": 73, "train_loss": 0.2601585152024636, "grad_norm": 0.4151223301887512, "test_error": 0.08561666666666666}, {"epoch": 74, "train_loss": 0.25974002966447735, "grad_norm": 1.0163893699645996, "test_error": 0.09708333333333333}, {"epoch": 75, "train_loss": 0.2604617570429885, "grad_norm": 0.864142656326294, "test_error": 0.0961}, {"epoch": 76, "train_loss": 0.2599207061630441, "grad_norm": 0.4360598921775818, "test_error": 0.08611666666666666}, {"epoch": 77, "train_loss": 0.2595486974058052, "grad_norm": 0.8420886993408203, "test_error": 0.09243333333333334}, {"epoch": 78, "train_loss": 0.25853003561457927, "grad_norm": 0.7128258347511292, "test_error": 0.09361666666666667}, {"epoch": 79, "train_loss": 0.2588797990703024, "grad_norm": 0.5975617170333862, "test_error": 0.0895}, {"epoch": 80, "train_loss": 0.25788494588489025, "grad_norm": 0.44270849227905273, "test_error": 0.08376666666666667}, {"epoch": 81, "train_loss": 0.2589504031990655, "grad_norm": 0.48841726779937744, "test_error": 0.08688333333333334}, {"epoch": 82, "train_loss": 0.258070973447136, "grad_norm": 0.6412168145179749, "test_error": 0.08895}, {"epoch": 83, "train_loss": 0.25707083006106163, "grad_norm": 0.2664714753627777, "test_error": 0.08366666666666667}, {"epoch": 84, "train_loss": 0.2582139932229184, "grad_norm": 0.699495255947113, "test_error": 0.09066666666666667}, {"epoch": 85, "train_loss": 0.25807313569293666, "grad_norm": 0.7649500370025635, "test_error": 0.09383333333333334}, {"epoch": 86, "train_loss": 0.25695864367935184, "grad_norm": 0.38086390495300293, "test_error": 0.08315}, {"epoch": 87, "train_loss": 0.2575379269391609, "grad_norm": 0.3304690420627594, "test_error": 0.0821}, {"epoch": 88, "train_loss": 0.25706366062598923, "grad_norm": 0.36049672961235046, "test_error": 0.08658333333333333}, {"epoch": 89, "train_loss": 0.25623168982755545, "grad_norm": 1.1284559965133667, "test_error": 0.10196666666666666}, {"epoch": 90, "train_loss": 0.2559860876519233, "grad_norm": 0.3011554777622223, "test_error": 0.08215}, {"epoch": 91, "train_loss": 0.2563245068535519, "grad_norm": 0.5342100858688354, "test_error": 0.0889}, {"epoch": 92, "train_loss": 0.2548566569628504, "grad_norm": 0.3806504011154175, "test_error": 0.08455}, {"epoch": 93, "train_loss": 0.2546365100479452, "grad_norm": 0.4565470218658447, "test_error": 0.08295}, {"epoch": 94, "train_loss": 0.25606737383280415, "grad_norm": 0.42775458097457886, "test_error": 0.08355}, {"epoch": 95, "train_loss": 0.2547674861511138, "grad_norm": 0.7814232707023621, "test_error": 0.08991666666666667}, {"epoch": 96, "train_loss": 0.254913346520237, "grad_norm": 0.375497967004776, "test_error": 0.08183333333333333}, {"epoch": 97, "train_loss": 0.25579780470300467, "grad_norm": 0.2639908790588379, "test_error": 0.08475}, {"epoch": 98, "train_loss": 0.2557373607809423, "grad_norm": 0.4992738664150238, "test_error": 0.08408333333333333}, {"epoch": 99, "train_loss": 0.25526958664318466, "grad_norm": 0.4597862660884857, "test_error": 0.086}, {"epoch": 100, "train_loss": 0.25441688401403373, "grad_norm": 0.37252694368362427, "test_error": 0.082}, {"epoch": 101, "train_loss": 0.2540464669405483, "grad_norm": 0.46919775009155273, "test_error": 0.08436666666666667}, {"epoch": 102, "train_loss": 0.2541010433800208, "grad_norm": 0.3981156051158905, "test_error": 0.0849}, {"epoch": 103, "train_loss": 0.2543002280134242, "grad_norm": 0.5121075510978699, "test_error": 0.08771666666666667}, {"epoch": 104, "train_loss": 0.2545273613026366, "grad_norm": 0.5916628837585449, "test_error": 0.08926666666666666}, {"epoch": 105, "train_loss": 0.25421879284859944, "grad_norm": 0.9090708494186401, "test_error": 0.0911}, {"epoch": 106, "train_loss": 0.2534013517863156, "grad_norm": 0.48783349990844727, "test_error": 0.08618333333333333}, {"epoch": 107, "train_loss": 0.2532291389658737, "grad_norm": 0.3383544385433197, "test_error": 0.0836}, {"epoch": 108, "train_loss": 0.25357458357318924, "grad_norm": 0.5151687264442444, "test_error": 0.08556666666666667}, {"epoch": 109, "train_loss": 0.25374720414122565, "grad_norm": 0.307289719581604, "test_error": 0.08143333333333333}, {"epoch": 110, "train_loss": 0.25300374699073536, "grad_norm": 0.3652060627937317, "test_error": 0.08361666666666667}, {"epoch": 111, "train_loss": 0.25320834809250664, "grad_norm": 0.5880528092384338, "test_error": 0.08506666666666667}, {"epoch": 112, "train_loss": 0.2528962545703398, "grad_norm": 0.23896166682243347, "test_error": 0.08205}, {"epoch": 113, "train_loss": 0.2527181372037933, "grad_norm": 0.7991378903388977, "test_error": 0.08925}, {"epoch": 114, "train_loss": 0.2524918270044339, "grad_norm": 1.100848913192749, "test_error": 0.09963333333333334}, {"epoch": 115, "train_loss": 0.2523774283127859, "grad_norm": 0.4831646978855133, "test_error": 0.08418333333333333}, {"epoch": 116, "train_loss": 0.252397853024692, "grad_norm": 0.7597030401229858, "test_error": 0.08665}, {"epoch": 117, "train_loss": 0.25295136174571237, "grad_norm": 0.6138967275619507, "test_error": 0.08648333333333333}, {"epoch": 118, "train_loss": 0.25217787993070667, "grad_norm": 0.666909396648407, "test_error": 0.08635}, {"epoch": 119, "train_loss": 0.25213566232100126, "grad_norm": 0.35539624094963074, "test_error": 0.083}, {"epoch": 120, "train_loss": 0.2516953047948191, "grad_norm": 0.8553456664085388, "test_error": 0.09068333333333334}, {"epoch": 121, "train_loss": 0.2534031941434757, "grad_norm": 0.7312373518943787, "test_error": 0.0898}, {"epoch": 122, "train_loss": 0.2519604082253451, "grad_norm": 0.89899742603302, "test_error": 0.09333333333333334}, {"epoch": 123, "train_loss": 0.251910863838663, "grad_norm": 0.7292777895927429, "test_error": 0.08748333333333333}, {"epoch": 124, "train_loss": 0.2511303855769414, "grad_norm": 0.47943857312202454, "test_error": 0.08046666666666667}, {"epoch": 125, "train_loss": 0.25146210386864065, "grad_norm": 0.2655884027481079, "test_error": 0.08086666666666667}, {"epoch": 126, "train_loss": 0.2509670947987276, "grad_norm": 0.6850368976593018, "test_error": 0.08825}, {"epoch": 127, "train_loss": 0.25130826627532954, "grad_norm": 1.089765191078186, "test_error": 0.09908333333333333}, {"epoch": 128, "train_loss": 0.2515805712493214, "grad_norm": 0.8410120010375977, "test_error": 0.08996666666666667}, {"epoch": 129, "train_loss": 0.2517434990160788, "grad_norm": 0.5915723443031311, "test_error": 0.08476666666666667}, {"epoch": 130, "train_loss": 0.2507309003837096, "grad_norm": 0.7799555659294128, "test_error": 0.09216666666666666}, {"epoch": 131, "train_loss": 0.2509564002316523, "grad_norm": 0.28262925148010254, "test_error": 0.07913333333333333}, {"epoch": 132, "train_loss": 0.25044735784851946, "grad_norm": 0.39001592993736267, "test_error": 0.08105}, {"epoch": 133, "train_loss": 0.2500976820182598, "grad_norm": 0.7341226935386658, "test_error": 0.09018333333333334}, {"epoch": 134, "train_loss": 0.25155739125811183, "grad_norm": 0.5854448080062866, "test_error": 0.08503333333333334}, {"epoch": 135, "train_loss": 0.2504718776443042, "grad_norm": 0.5232763886451721, "test_error": 0.0843}, {"epoch": 136, "train_loss": 0.2510582989716592, "grad_norm": 0.7546467185020447, "test_error": 0.09315}, {"epoch": 137, "train_loss": 0.25081539065767233, "grad_norm": 0.24109230935573578, "test_error": 0.07801666666666666}, {"epoch": 138, "train_loss": 0.25056924888949533, "grad_norm": 0.710175633430481, "test_error": 0.08708333333333333}, {"epoch": 139, "train_loss": 0.25012806147546507, "grad_norm": 0.5970426797866821, "test_error": 0.08588333333333334}, {"epoch": 140, "train_loss": 0.25034476051254506, "grad_norm": 0.5573800802230835, "test_error": 0.08401666666666667}, {"epoch": 141, "train_loss": 0.24985552343547654, "grad_norm": 1.0460208654403687, "test_error": 0.09771666666666666}, {"epoch": 142, "train_loss": 0.2491309389374219, "grad_norm": 0.4698983430862427, "test_error": 0.08065}, {"epoch": 143, "train_loss": 0.2502831971900693, "grad_norm": 0.9887404441833496, "test_error": 0.091}, {"epoch": 144, "train_loss": 0.24946931918842408, "grad_norm": 0.5748288035392761, "test_error": 0.087}, {"epoch": 145, "train_loss": 0.24954853117923873, "grad_norm": 0.6558545827865601, "test_error": 0.08938333333333333}, {"epoch": 146, "train_loss": 0.24998211003785642, "grad_norm": 0.43944916129112244, "test_error": 0.08323333333333334}, {"epoch": 147, "train_loss": 0.24928682579437736, "grad_norm": 0.798304557800293, "test_error": 0.08743333333333334}, {"epoch": 148, "train_loss": 0.2489321880162461, "grad_norm": 0.753801703453064, "test_error": 0.09035}, {"epoch": 149, "train_loss": 0.24953952661827983, "grad_norm": 0.5326370596885681, "test_error": 0.08228333333333333}, {"epoch": 150, "train_loss": 0.24931113943566258, "grad_norm": 0.909086287021637, "test_error": 0.09123333333333333}, {"epoch": 151, "train_loss": 0.24915818570856937, "grad_norm": 0.5436866283416748, "test_error": 0.08525}, {"epoch": 152, "train_loss": 0.24954274941096083, "grad_norm": 0.3483526408672333, "test_error": 0.08005}, {"epoch": 153, "train_loss": 0.2493541593605575, "grad_norm": 0.4476879835128784, "test_error": 0.08423333333333333}, {"epoch": 154, "train_loss": 0.24943149949703367, "grad_norm": 0.658283531665802, "test_error": 0.08416666666666667}, {"epoch": 155, "train_loss": 0.2492399583957158, "grad_norm": 0.4854263365268707, "test_error": 0.08326666666666667}, {"epoch": 156, "train_loss": 0.2497156548339602, "grad_norm": 0.6957724094390869, "test_error": 0.08656666666666667}, {"epoch": 157, "train_loss": 0.2501370586036161, "grad_norm": 1.0173590183258057, "test_error": 0.09476666666666667}, {"epoch": 158, "train_loss": 0.24813420916108103, "grad_norm": 0.41122257709503174, "test_error": 0.08238333333333334}, {"epoch": 159, "train_loss": 0.24941559247812256, "grad_norm": 0.515603244304657, "test_error": 0.0823}, {"epoch": 160, "train_loss": 0.24824697107162016, "grad_norm": 1.2907739877700806, "test_error": 0.09948333333333333}, {"epoch": 161, "train_loss": 0.24888620163096736, "grad_norm": 0.6950339674949646, "test_error": 0.08526666666666667}, {"epoch": 162, "train_loss": 0.24783928678945327, "grad_norm": 0.632564127445221, "test_error": 0.08846666666666667}, {"epoch": 163, "train_loss": 0.24868915765398802, "grad_norm": 0.6262274384498596, "test_error": 0.08868333333333334}, {"epoch": 164, "train_loss": 0.24847249673912303, "grad_norm": 0.5974998474121094, "test_error": 0.08366666666666667}, {"epoch": 165, "train_loss": 0.24923938439212118, "grad_norm": 0.4133784770965576, "test_error": 0.08235}, {"epoch": 166, "train_loss": 0.24936560106836259, "grad_norm": 0.4768107831478119, "test_error": 0.08098333333333334}, {"epoch": 167, "train_loss": 0.24900616246795593, "grad_norm": 0.6672871708869934, "test_error": 0.08755}, {"epoch": 168, "train_loss": 0.2481171726474228, "grad_norm": 0.5988225936889648, "test_error": 0.0834}, {"epoch": 169, "train_loss": 0.24817544321347182, "grad_norm": 0.47871026396751404, "test_error": 0.08056666666666666}, {"epoch": 170, "train_loss": 0.24849038722439823, "grad_norm": 0.3847666382789612, "test_error": 0.07931666666666666}, {"epoch": 171, "train_loss": 0.24876623745709853, "grad_norm": 0.3550105690956116, "test_error": 0.08191666666666667}, {"epoch": 172, "train_loss": 0.24910355295039094, "grad_norm": 0.7480455040931702, "test_error": 0.08406666666666666}, {"epoch": 173, "train_loss": 0.24881993355450685, "grad_norm": 0.7892814874649048, "test_error": 0.0881}, {"epoch": 174, "train_loss": 0.24883790483962123, "grad_norm": 0.39835602045059204, "test_error": 0.07798333333333334}, {"epoch": 175, "train_loss": 0.24755711416566434, "grad_norm": 0.492669939994812, "test_error": 0.08235}, {"epoch": 176, "train_loss": 0.24746315255473988, "grad_norm": 0.5641461610794067, "test_error": 0.08281666666666666}, {"epoch": 177, "train_loss": 0.2481208991036789, "grad_norm": 0.46044251322746277, "test_error": 0.08041666666666666}, {"epoch": 178, "train_loss": 0.2485344542321594, "grad_norm": 0.947542667388916, "test_error": 0.09275}, {"epoch": 179, "train_loss": 0.2481604094192541, "grad_norm": 0.5784948468208313, "test_error": 0.08618333333333333}, {"epoch": 180, "train_loss": 0.24760081451768443, "grad_norm": 0.4359748363494873, "test_error": 0.08216666666666667}, {"epoch": 181, "train_loss": 0.24821030707354658, "grad_norm": 0.7800484299659729, "test_error": 0.08563333333333334}, {"epoch": 182, "train_loss": 0.2477371397691313, "grad_norm": 0.3601530194282532, "test_error": 0.08038333333333333}, {"epoch": 183, "train_loss": 0.24860403679978724, "grad_norm": 0.5323407053947449, "test_error": 0.0812}, {"epoch": 184, "train_loss": 0.24690720778835626, "grad_norm": 0.7001968622207642, "test_error": 0.08518333333333333}, {"epoch": 185, "train_loss": 0.2473275553737379, "grad_norm": 0.6098945140838623, "test_error": 0.0835}, {"epoch": 186, "train_loss": 0.24767051678158652, "grad_norm": 0.5723873972892761, "test_error": 0.08261666666666667}, {"epoch": 187, "train_loss": 0.24812384656622696, "grad_norm": 0.2581820785999298, "test_error": 0.07975}, {"epoch": 188, "train_loss": 0.24678748431642694, "grad_norm": 0.4072485566139221, "test_error": 0.07958333333333334}, {"epoch": 189, "train_loss": 0.247687214901438, "grad_norm": 0.4537101089954376, "test_error": 0.08025}, {"epoch": 190, "train_loss": 0.2477272101492466, "grad_norm": 0.9919168949127197, "test_error": 0.0927}, {"epoch": 191, "train_loss": 0.2476147748544269, "grad_norm": 0.6286142468452454, "test_error": 0.08598333333333333}, {"epoch": 192, "train_loss": 0.2478073918625402, "grad_norm": 0.5054067373275757, "test_error": 0.0823}, {"epoch": 193, "train_loss": 0.2471560227086496, "grad_norm": 0.6086762547492981, "test_error": 0.08775}, {"epoch": 194, "train_loss": 0.24682191623351538, "grad_norm": 0.45207011699676514, "test_error": 0.08131666666666666}, {"epoch": 195, "train_loss": 0.24714914462808518, "grad_norm": 0.6716901659965515, "test_error": 0.08615}, {"epoch": 196, "train_loss": 0.24754167539653524, "grad_norm": 0.4354894459247589, "test_error": 0.07898333333333334}, {"epoch": 197, "train_loss": 0.24732208961756744, "grad_norm": 0.5478924512863159, "test_error": 0.08048333333333334}, {"epoch": 198, "train_loss": 0.24698981468200995, "grad_norm": 0.3559434115886688, "test_error": 0.07958333333333334}, {"epoch": 199, "train_loss": 0.2473029805847133, "grad_norm": 0.2667061686515808, "test_error": 0.07865}, {"epoch": 200, "train_loss": 0.24754021814011504, "grad_norm": 0.8539698123931885, "test_error": 0.08528333333333334}, {"epoch": 201, "train_loss": 0.24675658125003488, "grad_norm": 0.34855541586875916, "test_error": 0.08133333333333333}, {"epoch": 202, "train_loss": 0.24655864823663917, "grad_norm": 0.6352313756942749, "test_error": 0.08671666666666666}, {"epoch": 203, "train_loss": 0.24699348514992744, "grad_norm": 0.516671895980835, "test_error": 0.08345}, {"epoch": 204, "train_loss": 0.24625228668951119, "grad_norm": 0.5103127360343933, "test_error": 0.08098333333333334}, {"epoch": 205, "train_loss": 0.24699302180522742, "grad_norm": 0.35933718085289, "test_error": 0.08056666666666666}, {"epoch": 206, "train_loss": 0.246996466074915, "grad_norm": 0.30588313937187195, "test_error": 0.07875}, {"epoch": 207, "train_loss": 0.24591908479381042, "grad_norm": 0.6635884642601013, "test_error": 0.08725}, {"epoch": 208, "train_loss": 0.2477451791150185, "grad_norm": 0.6608531475067139, "test_error": 0.08503333333333334}, {"epoch": 209, "train_loss": 0.24774649390322157, "grad_norm": 0.37887611985206604, "test_error": 0.07891666666666666}, {"epoch": 210, "train_loss": 0.24639720854182573, "grad_norm": 0.8237814903259277, "test_error": 0.08891666666666667}, {"epoch": 211, "train_loss": 0.24671797621378208, "grad_norm": 0.33387747406959534, "test_error": 0.0797}, {"epoch": 212, "train_loss": 0.24646666622666333, "grad_norm": 0.35743802785873413, "test_error": 0.07903333333333333}, {"epoch": 213, "train_loss": 0.24720766131098693, "grad_norm": 0.28379562497138977, "test_error": 0.08113333333333334}, {"epoch": 214, "train_loss": 0.24696855848220486, "grad_norm": 0.3145143985748291, "test_error": 0.07793333333333333}, {"epoch": 215, "train_loss": 0.24715287461170615, "grad_norm": 0.3561137020587921, "test_error": 0.08086666666666667}, {"epoch": 216, "train_loss": 0.24659234368948577, "grad_norm": 0.6046021580696106, "test_error": 0.0839}, {"epoch": 217, "train_loss": 0.24679906634466411, "grad_norm": 0.5961149334907532, "test_error": 0.0823}, {"epoch": 218, "train_loss": 0.24621936009793233, "grad_norm": 0.399739146232605, "test_error": 0.0804}, {"epoch": 219, "train_loss": 0.24617069215366305, "grad_norm": 0.3370136618614197, "test_error": 0.08135}, {"epoch": 220, "train_loss": 0.2457452429916399, "grad_norm": 0.40871602296829224, "test_error": 0.0798}, {"epoch": 221, "train_loss": 0.24580640889576172, "grad_norm": 0.7105613350868225, "test_error": 0.08743333333333334}, {"epoch": 222, "train_loss": 0.24629439345083665, "grad_norm": 0.5983086228370667, "test_error": 0.08321666666666666}, {"epoch": 223, "train_loss": 0.24600017560871007, "grad_norm": 0.3583865761756897, "test_error": 0.0799}, {"epoch": 224, "train_loss": 0.24549583076367465, "grad_norm": 0.527330756187439, "test_error": 0.08151666666666667}, {"epoch": 225, "train_loss": 0.2462223114525744, "grad_norm": 0.4148034155368805, "test_error": 0.07843333333333333}, {"epoch": 226, "train_loss": 0.2463710113603156, "grad_norm": 0.3918555974960327, "test_error": 0.08048333333333334}, {"epoch": 227, "train_loss": 0.24633939965205112, "grad_norm": 0.5382734537124634, "test_error": 0.08285}, {"epoch": 228, "train_loss": 0.24611429855592237, "grad_norm": 0.49608197808265686, "test_error": 0.08423333333333333}, {"epoch": 229, "train_loss": 0.2464479164406269, "grad_norm": 0.4574095904827118, "test_error": 0.08186666666666667}, {"epoch": 230, "train_loss": 0.2473376633923811, "grad_norm": 0.3439171314239502, "test_error": 0.08101666666666667}, {"epoch": 231, "train_loss": 0.24598500778968446, "grad_norm": 0.6568715572357178, "test_error": 0.08521666666666666}, {"epoch": 232, "train_loss": 0.24639020975937212, "grad_norm": 0.7058820128440857, "test_error": 0.085}, {"epoch": 233, "train_loss": 0.24539742555535243, "grad_norm": 0.3340573310852051, "test_error": 0.07923333333333334}, {"epoch": 234, "train_loss": 0.24565338356156524, "grad_norm": 0.33103859424591064, "test_error": 0.07936666666666667}, {"epoch": 235, "train_loss": 0.24634667730533208, "grad_norm": 0.4292392432689667, "test_error": 0.08301666666666667}, {"epoch": 236, "train_loss": 0.24557943363619658, "grad_norm": 0.4426431953907013, "test_error": 0.07745}, {"epoch": 237, "train_loss": 0.24571020588011014, "grad_norm": 0.33752691745758057, "test_error": 0.0797}, {"epoch": 238, "train_loss": 0.24630802249229358, "grad_norm": 0.5081164240837097, "test_error": 0.0824}, {"epoch": 239, "train_loss": 0.24590525654004886, "grad_norm": 0.3734658658504486, "test_error": 0.07996666666666667}, {"epoch": 240, "train_loss": 0.24627202061230005, "grad_norm": 0.5954222679138184, "test_error": 0.08716666666666667}, {"epoch": 241, "train_loss": 0.24552135608981673, "grad_norm": 0.6291361451148987, "test_error": 0.08228333333333333}, {"epoch": 242, "train_loss": 0.24486638546711764, "grad_norm": 0.3173585832118988, "test_error": 0.07883333333333334}, {"epoch": 243, "train_loss": 0.24536496483992476, "grad_norm": 0.2755183279514313, "test_error": 0.07953333333333333}, {"epoch": 244, "train_loss": 0.2453506023664959, "grad_norm": 0.6219767332077026, "test_error": 0.08443333333333333}, {"epoch": 245, "train_loss": 0.24594140302451947, "grad_norm": 0.6178914308547974, "test_error": 0.0873}, {"epoch": 246, "train_loss": 0.24576990050636233, "grad_norm": 1.0136135816574097, "test_error": 0.09513333333333333}, {"epoch": 247, "train_loss": 0.2454299673913823, "grad_norm": 0.40018337965011597, "test_error": 0.08058333333333334}, {"epoch": 248, "train_loss": 0.24525570406306846, "grad_norm": 0.8195238709449768, "test_error": 0.09175}, {"epoch": 249, "train_loss": 0.24529364272164336, "grad_norm": 0.48480328917503357, "test_error": 0.08276666666666667}, {"epoch": 250, "train_loss": 0.24519305714572934, "grad_norm": 0.5085046887397766, "test_error": 0.08351666666666667}, {"epoch": 251, "train_loss": 0.24646752729305688, "grad_norm": 0.5801547765731812, "test_error": 0.08223333333333334}, {"epoch": 252, "train_loss": 0.24542397742415778, "grad_norm": 0.5568374991416931, "test_error": 0.08343333333333333}, {"epoch": 253, "train_loss": 0.24507118055825897, "grad_norm": 0.4495778977870941, "test_error": 0.07878333333333333}, {"epoch": 254, "train_loss": 0.24639426965239303, "grad_norm": 0.7357260584831238, "test_error": 0.08503333333333334}, {"epoch": 255, "train_loss": 0.245384092847351, "grad_norm": 0.5716841816902161, "test_error": 0.0826}, {"epoch": 256, "train_loss": 0.24518136108938293, "grad_norm": 0.6696605682373047, "test_error": 0.08741666666666667}, {"epoch": 257, "train_loss": 0.24501510952141448, "grad_norm": 0.8166517019271851, "test_error": 0.08918333333333334}, {"epoch": 258, "train_loss": 0.24551105875948753, "grad_norm": 0.6348298788070679, "test_error": 0.0848}, {"epoch": 259, "train_loss": 0.24582899639615788, "grad_norm": 0.39346301555633545, "test_error": 0.08143333333333333}, {"epoch": 260, "train_loss": 0.2445172313390455, "grad_norm": 0.8630303144454956, "test_error": 0.08653333333333334}, {"epoch": 261, "train_loss": 0.24471339507858889, "grad_norm": 0.5659418106079102, "test_error": 0.07961666666666667}, {"epoch": 262, "train_loss": 0.2459193273615868, "grad_norm": 0.4543100893497467, "test_error": 0.0793}, {"epoch": 263, "train_loss": 0.24471694940592473, "grad_norm": 0.8707377910614014, "test_error": 0.08978333333333334}, {"epoch": 264, "train_loss": 0.24501628840109332, "grad_norm": 0.7303667664527893, "test_error": 0.08845}, {"epoch": 265, "train_loss": 0.24455070434328324, "grad_norm": 0.9639779925346375, "test_error": 0.0885}, {"epoch": 266, "train_loss": 0.244728127654021, "grad_norm": 0.9033214449882507, "test_error": 0.09}, {"epoch": 267, "train_loss": 0.2444022770601247, "grad_norm": 0.31961509585380554, "test_error": 0.07961666666666667}, {"epoch": 268, "train_loss": 0.24511350071804675, "grad_norm": 0.6491293907165527, "test_error": 0.08308333333333333}, {"epoch": 269, "train_loss": 0.2450755032543093, "grad_norm": 1.0099411010742188, "test_error": 0.0927}, {"epoch": 270, "train_loss": 0.24468909143831116, "grad_norm": 0.9387180805206299, "test_error": 0.09435}, {"epoch": 271, "train_loss": 0.2449295389627417, "grad_norm": 0.9484252333641052, "test_error": 0.09606666666666666}, {"epoch": 272, "train_loss": 0.24511096445168368, "grad_norm": 0.5752796530723572, "test_error": 0.08286666666666667}, {"epoch": 273, "train_loss": 0.24445982910025243, "grad_norm": 0.43017151951789856, "test_error": 0.08305}, {"epoch": 274, "train_loss": 0.24437267895011852, "grad_norm": 0.2869199812412262, "test_error": 0.07793333333333333}, {"epoch": 275, "train_loss": 0.2438363131232909, "grad_norm": 0.5340161919593811, "test_error": 0.08181666666666666}, {"epoch": 276, "train_loss": 0.24404745773916753, "grad_norm": 0.5910305380821228, "test_error": 0.084}, {"epoch": 277, "train_loss": 0.244178576697479, "grad_norm": 0.6546342372894287, "test_error": 0.08158333333333333}, {"epoch": 278, "train_loss": 0.24440177387588968, "grad_norm": 0.7609721422195435, "test_error": 0.08798333333333333}, {"epoch": 279, "train_loss": 0.2441406159203034, "grad_norm": 0.8172097206115723, "test_error": 0.08461666666666667}, {"epoch": 280, "train_loss": 0.2448798467256129, "grad_norm": 0.34605252742767334, "test_error": 0.07965}, {"epoch": 281, "train_loss": 0.24451518507278525, "grad_norm": 0.6609296202659607, "test_error": 0.08385}, {"epoch": 282, "train_loss": 0.2444825356444344, "grad_norm": 0.8573518395423889, "test_error": 0.08876666666666666}, {"epoch": 283, "train_loss": 0.24392530764724749, "grad_norm": 0.2935040295124054, "test_error": 0.07845}, {"epoch": 284, "train_loss": 0.24448493273924882, "grad_norm": 0.5412739515304565, "test_error": 0.081}, {"epoch": 285, "train_loss": 0.244142618488792, "grad_norm": 0.41789498925209045, "test_error": 0.07948333333333334}, {"epoch": 286, "train_loss": 0.24448514029166352, "grad_norm": 0.32859811186790466, "test_error": 0.078}, {"epoch": 287, "train_loss": 0.24475583939956658, "grad_norm": 0.4969848394393921, "test_error": 0.08116666666666666}, {"epoch": 288, "train_loss": 0.24453320949862245, "grad_norm": 0.3729969263076782, "test_error": 0.07861666666666667}, {"epoch": 289, "train_loss": 0.2440418908734185, "grad_norm": 0.5417718291282654, "test_error": 0.0804}, {"epoch": 290, "train_loss": 0.24439592970500235, "grad_norm": 0.47136518359184265, "test_error": 0.08076666666666667}, {"epoch": 291, "train_loss": 0.2447683631061421, "grad_norm": 0.43562552332878113, "test_error": 0.08113333333333334}, {"epoch": 292, "train_loss": 0.24411037798730345, "grad_norm": 0.6617643237113953, "test_error": 0.08298333333333334}, {"epoch": 293, "train_loss": 0.24373431102884932, "grad_norm": 0.5532281398773193, "test_error": 0.08323333333333334}, {"epoch": 294, "train_loss": 0.24332431664554557, "grad_norm": 0.26012927293777466, "test_error": 0.07951666666666667}, {"epoch": 295, "train_loss": 0.24434134910216865, "grad_norm": 0.4105246365070343, "test_error": 0.07933333333333334}, {"epoch": 296, "train_loss": 0.24382508339740647, "grad_norm": 0.9679091572761536, "test_error": 0.09551666666666667}, {"epoch": 297, "train_loss": 0.24404002292318425, "grad_norm": 0.3656928837299347, "test_error": 0.08068333333333333}, {"epoch": 298, "train_loss": 0.24410038827518776, "grad_norm": 0.2779265344142914, "test_error": 0.0785}, {"epoch": 299, "train_loss": 0.24413629864606384, "grad_norm": 0.35001853108406067, "test_error": 0.07946666666666667}, {"epoch": 300, "train_loss": 0.24454171602839295, "grad_norm": 0.6656365394592285, "test_error": 0.08453333333333334}]}