{"argv": ["train.py", "--seed", "79", "--optimizer", "SGD", "--run_name", "sgd_0.001.json", "--output_path", "experiments/nonconvex_fmnist/sgd-0.001.json", "--dataset", "FMNIST", "--layer_sizes", "784", "100", "10", "--batch_size", "10", "--learning_rate", "0.001", "--weight_decay", "0.001", "--num_epochs", "300", "--download", "--device", "cuda"], "args": {"seed": 79, "optimizer": "SGD", "run_name": "sgd_0.001.json", "output_path": "experiments/nonconvex_fmnist/sgd-0.001.json", "device": "cuda", "dataset": "FMNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": true, "layer_sizes": [784, 100, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.001, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 1.3134893898765245, "grad_norm": 0.3155260980129242, "test_error": 0.2975833333333333}, {"epoch": 2, "train_loss": 0.7677224623511235, "grad_norm": 0.2516903877258301, "test_error": 0.23818333333333333}, {"epoch": 3, "train_loss": 0.6558029306506117, "grad_norm": 0.23912447690963745, "test_error": 0.20628333333333335}, {"epoch": 4, "train_loss": 0.5949821317009628, "grad_norm": 0.38646939396858215, "test_error": 0.1918}, {"epoch": 5, "train_loss": 0.5569496365897357, "grad_norm": 0.1987191140651703, "test_error": 0.17923333333333333}, {"epoch": 6, "train_loss": 0.5305215606453518, "grad_norm": 0.16853055357933044, "test_error": 0.1726}, {"epoch": 7, "train_loss": 0.5113203584471097, "grad_norm": 0.41294464468955994, "test_error": 0.17136666666666667}, {"epoch": 8, "train_loss": 0.49649660335294904, "grad_norm": 0.3227049708366394, "test_error": 0.16581666666666667}, {"epoch": 9, "train_loss": 0.4852271681462104, "grad_norm": 0.21643748879432678, "test_error": 0.16255}, {"epoch": 10, "train_loss": 0.4754442789213111, "grad_norm": 0.34341737627983093, "test_error": 0.16131666666666666}, {"epoch": 11, "train_loss": 0.46747158711217346, "grad_norm": 0.43432310223579407, "test_error": 0.15825}, {"epoch": 12, "train_loss": 0.46041071286269775, "grad_norm": 0.35111868381500244, "test_error": 0.15608333333333332}, {"epoch": 13, "train_loss": 0.45410491657288127, "grad_norm": 0.2619931399822235, "test_error": 0.1548}, {"epoch": 14, "train_loss": 0.4485969397981341, "grad_norm": 0.19502682983875275, "test_error": 0.15085}, {"epoch": 15, "train_loss": 0.443680324747848, "grad_norm": 0.2672627866268158, "test_error": 0.15026666666666666}, {"epoch": 16, "train_loss": 0.4393954055166493, "grad_norm": 0.5453091263771057, "test_error": 0.15101666666666666}, {"epoch": 17, "train_loss": 0.43515483749316386, "grad_norm": 0.3457663357257843, "test_error": 0.1491}, {"epoch": 18, "train_loss": 0.4311088424396391, "grad_norm": 0.530426561832428, "test_error": 0.1491}, {"epoch": 19, "train_loss": 0.42734514916595073, "grad_norm": 0.290785014629364, "test_error": 0.14546666666666666}, {"epoch": 20, "train_loss": 0.424172657629475, "grad_norm": 0.32814809679985046, "test_error": 0.14345}, {"epoch": 21, "train_loss": 0.42114152304517727, "grad_norm": 0.29022496938705444, "test_error": 0.14455}, {"epoch": 22, "train_loss": 0.41809626427913704, "grad_norm": 0.16176337003707886, "test_error": 0.14193333333333333}, {"epoch": 23, "train_loss": 0.4151981940277231, "grad_norm": 0.29046133160591125, "test_error": 0.14238333333333333}, {"epoch": 24, "train_loss": 0.41245849355651687, "grad_norm": 0.5659624934196472, "test_error": 0.14223333333333332}, {"epoch": 25, "train_loss": 0.40976136471610514, "grad_norm": 0.412075012922287, "test_error": 0.14145}, {"epoch": 26, "train_loss": 0.40728876771498473, "grad_norm": 0.6336096525192261, "test_error": 0.14036666666666667}, {"epoch": 27, "train_loss": 0.40447029802855106, "grad_norm": 0.542668342590332, "test_error": 0.13935}, {"epoch": 28, "train_loss": 0.40228507671846697, "grad_norm": 0.7754850387573242, "test_error": 0.14123333333333332}, {"epoch": 29, "train_loss": 0.4001183464859302, "grad_norm": 0.4491896629333496, "test_error": 0.1369}, {"epoch": 30, "train_loss": 0.39754831659436846, "grad_norm": 0.34890368580818176, "test_error": 0.13676666666666668}, {"epoch": 31, "train_loss": 0.39557395995004724, "grad_norm": 0.4417825937271118, "test_error": 0.13595}, {"epoch": 32, "train_loss": 0.39341122543121065, "grad_norm": 0.7849405407905579, "test_error": 0.13668333333333332}, {"epoch": 33, "train_loss": 0.39144840224816774, "grad_norm": 0.4256421625614166, "test_error": 0.13496666666666668}, {"epoch": 34, "train_loss": 0.3893689156047379, "grad_norm": 0.22254294157028198, "test_error": 0.13273333333333334}, {"epoch": 35, "train_loss": 0.38746064449412126, "grad_norm": 0.5662848949432373, "test_error": 0.13261666666666666}, {"epoch": 36, "train_loss": 0.38567457788717, "grad_norm": 0.39750784635543823, "test_error": 0.13175}, {"epoch": 37, "train_loss": 0.3839125315742567, "grad_norm": 0.8216213583946228, "test_error": 0.13238333333333333}, {"epoch": 38, "train_loss": 0.3818779225377366, "grad_norm": 0.23350578546524048, "test_error": 0.12918333333333334}, {"epoch": 39, "train_loss": 0.3800478105240812, "grad_norm": 0.404366672039032, "test_error": 0.12961666666666666}, {"epoch": 40, "train_loss": 0.3788125462050084, "grad_norm": 0.16774143278598785, "test_error": 0.12863333333333332}, {"epoch": 41, "train_loss": 0.377088570058501, "grad_norm": 0.11643220484256744, "test_error": 0.1281}, {"epoch": 42, "train_loss": 0.3758209648380677, "grad_norm": 0.32637450098991394, "test_error": 0.12743333333333334}, {"epoch": 43, "train_loss": 0.3739891221554329, "grad_norm": 0.21290557086467743, "test_error": 0.12673333333333334}, {"epoch": 44, "train_loss": 0.37259426232908543, "grad_norm": 0.278568297624588, "test_error": 0.1271}, {"epoch": 45, "train_loss": 0.3712519867065518, "grad_norm": 0.27634096145629883, "test_error": 0.12758333333333333}, {"epoch": 46, "train_loss": 0.36956383217219263, "grad_norm": 0.34685418009757996, "test_error": 0.12785}, {"epoch": 47, "train_loss": 0.36796141012152656, "grad_norm": 0.48710155487060547, "test_error": 0.12636666666666665}, {"epoch": 48, "train_loss": 0.3671300856115607, "grad_norm": 0.2513868510723114, "test_error": 0.12488333333333333}, {"epoch": 49, "train_loss": 0.3658301378360484, "grad_norm": 0.3538782298564911, "test_error": 0.12366666666666666}, {"epoch": 50, "train_loss": 0.36440345940738916, "grad_norm": 0.5626215934753418, "test_error": 0.12441666666666666}, {"epoch": 51, "train_loss": 0.3630090959773709, "grad_norm": 0.5304756164550781, "test_error": 0.12351666666666666}, {"epoch": 52, "train_loss": 0.36175003557372837, "grad_norm": 0.2901630103588104, "test_error": 0.12358333333333334}, {"epoch": 53, "train_loss": 0.3604777511039671, "grad_norm": 0.19668082892894745, "test_error": 0.1225}, {"epoch": 54, "train_loss": 0.35928775879709673, "grad_norm": 0.4381474256515503, "test_error": 0.12351666666666666}, {"epoch": 55, "train_loss": 0.35809778861002994, "grad_norm": 0.4246904253959656, "test_error": 0.1227}, {"epoch": 56, "train_loss": 0.35702181111167497, "grad_norm": 0.2597113847732544, "test_error": 0.12125}, {"epoch": 57, "train_loss": 0.3558551775611316, "grad_norm": 0.4424539804458618, "test_error": 0.12233333333333334}, {"epoch": 58, "train_loss": 0.3549135125276322, "grad_norm": 0.15566669404506683, "test_error": 0.12033333333333333}, {"epoch": 59, "train_loss": 0.35392991320129175, "grad_norm": 0.22504331171512604, "test_error": 0.12043333333333334}, {"epoch": 60, "train_loss": 0.35255051949375776, "grad_norm": 0.28208059072494507, "test_error": 0.11993333333333334}, {"epoch": 61, "train_loss": 0.35173875937145205, "grad_norm": 0.2357490360736847, "test_error": 0.1196}, {"epoch": 62, "train_loss": 0.3507571702750089, "grad_norm": 0.18303976953029633, "test_error": 0.11948333333333333}, {"epoch": 63, "train_loss": 0.349578091834827, "grad_norm": 0.20800736546516418, "test_error": 0.11938333333333333}, {"epoch": 64, "train_loss": 0.3485811913223006, "grad_norm": 0.3770703375339508, "test_error": 0.1184}, {"epoch": 65, "train_loss": 0.34762809286483876, "grad_norm": 0.1978745460510254, "test_error": 0.11791666666666667}, {"epoch": 66, "train_loss": 0.3462868505073711, "grad_norm": 0.5952035188674927, "test_error": 0.1187}, {"epoch": 67, "train_loss": 0.34556944741324214, "grad_norm": 0.35642221570014954, "test_error": 0.11795}, {"epoch": 68, "train_loss": 0.3443404640513472, "grad_norm": 0.5940807461738586, "test_error": 0.11795}, {"epoch": 69, "train_loss": 0.343444136117585, "grad_norm": 0.7470232844352722, "test_error": 0.11938333333333333}, {"epoch": 70, "train_loss": 0.34275954266202946, "grad_norm": 0.18303552269935608, "test_error": 0.11668333333333333}, {"epoch": 71, "train_loss": 0.34219869932113217, "grad_norm": 0.532926619052887, "test_error": 0.11758333333333333}, {"epoch": 72, "train_loss": 0.34095062233616286, "grad_norm": 0.5202105045318604, "test_error": 0.11726666666666667}, {"epoch": 73, "train_loss": 0.33994543124036863, "grad_norm": 0.44930946826934814, "test_error": 0.11743333333333333}, {"epoch": 74, "train_loss": 0.33942214915847096, "grad_norm": 0.5085509419441223, "test_error": 0.11626666666666667}, {"epoch": 75, "train_loss": 0.33805619688409694, "grad_norm": 0.308912068605423, "test_error": 0.1149}, {"epoch": 76, "train_loss": 0.3375801891956168, "grad_norm": 0.2583228647708893, "test_error": 0.11506666666666666}, {"epoch": 77, "train_loss": 0.3363473494906599, "grad_norm": 0.3774179518222809, "test_error": 0.11505}, {"epoch": 78, "train_loss": 0.33598768477824825, "grad_norm": 0.2863435447216034, "test_error": 0.1148}, {"epoch": 79, "train_loss": 0.3350269885075589, "grad_norm": 0.33040904998779297, "test_error": 0.11303333333333333}, {"epoch": 80, "train_loss": 0.3340506871356629, "grad_norm": 0.4330166280269623, "test_error": 0.11426666666666667}, {"epoch": 81, "train_loss": 0.33372966964698086, "grad_norm": 0.4657990038394928, "test_error": 0.11406666666666666}, {"epoch": 82, "train_loss": 0.332699602064987, "grad_norm": 0.38300642371177673, "test_error": 0.11338333333333334}, {"epoch": 83, "train_loss": 0.3320630678401018, "grad_norm": 0.3987947702407837, "test_error": 0.11295}, {"epoch": 84, "train_loss": 0.3311086003985256, "grad_norm": 0.3301467299461365, "test_error": 0.11238333333333334}, {"epoch": 85, "train_loss": 0.3304978167668063, "grad_norm": 0.14395956695079803, "test_error": 0.1116}, {"epoch": 86, "train_loss": 0.3293260400680204, "grad_norm": 0.3345196843147278, "test_error": 0.1128}, {"epoch": 87, "train_loss": 0.32920722281723286, "grad_norm": 0.25596365332603455, "test_error": 0.11193333333333333}, {"epoch": 88, "train_loss": 0.3281795376061151, "grad_norm": 0.23765526711940765, "test_error": 0.11191666666666666}, {"epoch": 89, "train_loss": 0.32792062825026613, "grad_norm": 0.3034643828868866, "test_error": 0.11165}, {"epoch": 90, "train_loss": 0.3273229991431193, "grad_norm": 0.1672627031803131, "test_error": 0.11088333333333333}, {"epoch": 91, "train_loss": 0.32649848390836267, "grad_norm": 0.2743995487689972, "test_error": 0.1103}, {"epoch": 92, "train_loss": 0.3256587355521818, "grad_norm": 0.4032791554927826, "test_error": 0.11085}, {"epoch": 93, "train_loss": 0.3252625188502328, "grad_norm": 0.38805097341537476, "test_error": 0.11176666666666667}, {"epoch": 94, "train_loss": 0.32465551189069325, "grad_norm": 0.382512629032135, "test_error": 0.11091666666666666}, {"epoch": 95, "train_loss": 0.32374948226256917, "grad_norm": 0.24016247689723969, "test_error": 0.1096}, {"epoch": 96, "train_loss": 0.3232693714594158, "grad_norm": 0.5667294859886169, "test_error": 0.11201666666666667}, {"epoch": 97, "train_loss": 0.32232278103226175, "grad_norm": 0.4330769181251526, "test_error": 0.11013333333333333}, {"epoch": 98, "train_loss": 0.3219600410019824, "grad_norm": 0.2753031253814697, "test_error": 0.10905}, {"epoch": 99, "train_loss": 0.3213734190305307, "grad_norm": 0.33244892954826355, "test_error": 0.10955}, {"epoch": 100, "train_loss": 0.3206751450712327, "grad_norm": 0.3287922441959381, "test_error": 0.1088}, {"epoch": 101, "train_loss": 0.3200022209440358, "grad_norm": 0.3991815745830536, "test_error": 0.10878333333333333}, {"epoch": 102, "train_loss": 0.31900594144454225, "grad_norm": 0.27254343032836914, "test_error": 0.10835}, {"epoch": 103, "train_loss": 0.3187351911024501, "grad_norm": 0.2811375856399536, "test_error": 0.10748333333333333}, {"epoch": 104, "train_loss": 0.3179144735248604, "grad_norm": 0.28366217017173767, "test_error": 0.10805}, {"epoch": 105, "train_loss": 0.3177824604120882, "grad_norm": 0.310300350189209, "test_error": 0.10758333333333334}, {"epoch": 106, "train_loss": 0.3167030531906057, "grad_norm": 0.5889165997505188, "test_error": 0.10873333333333333}, {"epoch": 107, "train_loss": 0.316510062021669, "grad_norm": 0.31998878717422485, "test_error": 0.10766666666666666}, {"epoch": 108, "train_loss": 0.3156477808272466, "grad_norm": 0.42007917165756226, "test_error": 0.10723333333333333}, {"epoch": 109, "train_loss": 0.3152736538061096, "grad_norm": 0.5360834002494812, "test_error": 0.10875}, {"epoch": 110, "train_loss": 0.3142546257606397, "grad_norm": 0.30110815167427063, "test_error": 0.10701666666666666}, {"epoch": 111, "train_loss": 0.3139604632551006, "grad_norm": 0.5529352426528931, "test_error": 0.10738333333333333}, {"epoch": 112, "train_loss": 0.3135508493663122, "grad_norm": 0.2307014912366867, "test_error": 0.10585}, {"epoch": 113, "train_loss": 0.31294403578465185, "grad_norm": 0.6336431503295898, "test_error": 0.1089}, {"epoch": 114, "train_loss": 0.31249845364348344, "grad_norm": 0.3138647973537445, "test_error": 0.10608333333333334}, {"epoch": 115, "train_loss": 0.3121570961465283, "grad_norm": 0.26825061440467834, "test_error": 0.10463333333333333}, {"epoch": 116, "train_loss": 0.3110710307904519, "grad_norm": 0.47210952639579773, "test_error": 0.10723333333333333}, {"epoch": 117, "train_loss": 0.31070887118019164, "grad_norm": 0.4015825688838959, "test_error": 0.10568333333333334}, {"epoch": 118, "train_loss": 0.3105691913024057, "grad_norm": 0.4936753213405609, "test_error": 0.1056}, {"epoch": 119, "train_loss": 0.30998947931461346, "grad_norm": 0.5804320573806763, "test_error": 0.10533333333333333}, {"epoch": 120, "train_loss": 0.30924640034108114, "grad_norm": 0.45969104766845703, "test_error": 0.10566666666666667}, {"epoch": 121, "train_loss": 0.3086832196650406, "grad_norm": 0.5094661116600037, "test_error": 0.10635}, {"epoch": 122, "train_loss": 0.3084259209188943, "grad_norm": 0.6030294299125671, "test_error": 0.1073}, {"epoch": 123, "train_loss": 0.30765417505792964, "grad_norm": 0.48064056038856506, "test_error": 0.10535}, {"epoch": 124, "train_loss": 0.3070370697705075, "grad_norm": 0.7773115038871765, "test_error": 0.10795}, {"epoch": 125, "train_loss": 0.30665621381253005, "grad_norm": 0.27219030261039734, "test_error": 0.10353333333333334}, {"epoch": 126, "train_loss": 0.30611484109424053, "grad_norm": 0.4049675464630127, "test_error": 0.10431666666666667}, {"epoch": 127, "train_loss": 0.30600036094311506, "grad_norm": 0.27083301544189453, "test_error": 0.1038}, {"epoch": 128, "train_loss": 0.305267817808936, "grad_norm": 0.717823326587677, "test_error": 0.10545}, {"epoch": 129, "train_loss": 0.3050025787168027, "grad_norm": 0.25099146366119385, "test_error": 0.10375}, {"epoch": 130, "train_loss": 0.30413730995853744, "grad_norm": 0.6334813833236694, "test_error": 0.10506666666666667}, {"epoch": 131, "train_loss": 0.30392420485429467, "grad_norm": 0.168397918343544, "test_error": 0.10331666666666667}, {"epoch": 132, "train_loss": 0.30313874418816217, "grad_norm": 0.48721086978912354, "test_error": 0.10341666666666667}, {"epoch": 133, "train_loss": 0.30278489528239394, "grad_norm": 0.2668476104736328, "test_error": 0.10351666666666667}, {"epoch": 134, "train_loss": 0.3025544136928705, "grad_norm": 0.3159441649913788, "test_error": 0.10253333333333334}, {"epoch": 135, "train_loss": 0.30195217777982664, "grad_norm": 0.3623620271682739, "test_error": 0.10236666666666666}, {"epoch": 136, "train_loss": 0.30133595010840025, "grad_norm": 0.21252106130123138, "test_error": 0.10271666666666666}, {"epoch": 137, "train_loss": 0.30121216206702717, "grad_norm": 0.25016313791275024, "test_error": 0.10215}, {"epoch": 138, "train_loss": 0.30059775455179627, "grad_norm": 0.2466115951538086, "test_error": 0.10236666666666666}, {"epoch": 139, "train_loss": 0.3004596109013073, "grad_norm": 0.2658956050872803, "test_error": 0.10156666666666667}, {"epoch": 140, "train_loss": 0.29967335524689404, "grad_norm": 0.6221634149551392, "test_error": 0.10366666666666667}, {"epoch": 141, "train_loss": 0.29911029146254686, "grad_norm": 0.4454159736633301, "test_error": 0.10191666666666667}, {"epoch": 142, "train_loss": 0.29872142659073386, "grad_norm": 0.3803052604198456, "test_error": 0.1022}, {"epoch": 143, "train_loss": 0.29857747112750077, "grad_norm": 0.2660878598690033, "test_error": 0.10076666666666667}, {"epoch": 144, "train_loss": 0.2979463500645943, "grad_norm": 0.5782821774482727, "test_error": 0.10213333333333334}, {"epoch": 145, "train_loss": 0.29765607381860415, "grad_norm": 0.30709707736968994, "test_error": 0.10148333333333333}, {"epoch": 146, "train_loss": 0.29705469150297964, "grad_norm": 0.672168493270874, "test_error": 0.10303333333333334}, {"epoch": 147, "train_loss": 0.2968430256671272, "grad_norm": 0.6385711431503296, "test_error": 0.10418333333333334}, {"epoch": 148, "train_loss": 0.2964622110809044, "grad_norm": 0.3330937623977661, "test_error": 0.10098333333333333}, {"epoch": 149, "train_loss": 0.29592925279971677, "grad_norm": 0.3723650276660919, "test_error": 0.10133333333333333}, {"epoch": 150, "train_loss": 0.2955940753024382, "grad_norm": 0.7881608605384827, "test_error": 0.10235}, {"epoch": 151, "train_loss": 0.29501770236397473, "grad_norm": 0.13722392916679382, "test_error": 0.10003333333333334}, {"epoch": 152, "train_loss": 0.2944211279905867, "grad_norm": 0.4164271950721741, "test_error": 0.10051666666666667}, {"epoch": 153, "train_loss": 0.29442665962680864, "grad_norm": 0.2961277961730957, "test_error": 0.09993333333333333}, {"epoch": 154, "train_loss": 0.2939644048857347, "grad_norm": 0.20559395849704742, "test_error": 0.09921666666666666}, {"epoch": 155, "train_loss": 0.29333934529327477, "grad_norm": 0.37776562571525574, "test_error": 0.09991666666666667}, {"epoch": 156, "train_loss": 0.2931119113010354, "grad_norm": 0.3406643271446228, "test_error": 0.09891666666666667}, {"epoch": 157, "train_loss": 0.2927781657578113, "grad_norm": 0.5427293181419373, "test_error": 0.1013}, {"epoch": 158, "train_loss": 0.29234546451208493, "grad_norm": 0.20319387316703796, "test_error": 0.0991}, {"epoch": 159, "train_loss": 0.29207668025163, "grad_norm": 0.44754645228385925, "test_error": 0.09975}, {"epoch": 160, "train_loss": 0.2917682371174451, "grad_norm": 0.44574013352394104, "test_error": 0.09923333333333334}, {"epoch": 161, "train_loss": 0.2911761742153515, "grad_norm": 0.18742014467716217, "test_error": 0.09826666666666667}, {"epoch": 162, "train_loss": 0.2906454450484986, "grad_norm": 0.39654994010925293, "test_error": 0.09908333333333333}, {"epoch": 163, "train_loss": 0.2903137790954206, "grad_norm": 0.24828192591667175, "test_error": 0.09886666666666667}, {"epoch": 164, "train_loss": 0.2900691029559045, "grad_norm": 0.6288737654685974, "test_error": 0.10011666666666667}, {"epoch": 165, "train_loss": 0.2896896394715489, "grad_norm": 0.30351167917251587, "test_error": 0.09863333333333334}, {"epoch": 166, "train_loss": 0.28941395797413616, "grad_norm": 0.3350057303905487, "test_error": 0.09838333333333334}, {"epoch": 167, "train_loss": 0.2890965662486851, "grad_norm": 0.4944411516189575, "test_error": 0.09931666666666666}, {"epoch": 168, "train_loss": 0.2886945945378781, "grad_norm": 0.579532265663147, "test_error": 0.09955}, {"epoch": 169, "train_loss": 0.2883903579960267, "grad_norm": 0.24499480426311493, "test_error": 0.09731666666666666}, {"epoch": 170, "train_loss": 0.28790883799362926, "grad_norm": 0.4191438853740692, "test_error": 0.09761666666666667}, {"epoch": 171, "train_loss": 0.28766699196297363, "grad_norm": 0.37584105134010315, "test_error": 0.0978}, {"epoch": 172, "train_loss": 0.2871916775609522, "grad_norm": 0.23480169475078583, "test_error": 0.09768333333333333}, {"epoch": 173, "train_loss": 0.2870130281282278, "grad_norm": 0.4250974655151367, "test_error": 0.09726666666666667}, {"epoch": 174, "train_loss": 0.2869387365094541, "grad_norm": 0.4989977777004242, "test_error": 0.09803333333333333}, {"epoch": 175, "train_loss": 0.2866448776409185, "grad_norm": 0.42396286129951477, "test_error": 0.09755}, {"epoch": 176, "train_loss": 0.2861004352437643, "grad_norm": 0.5000320672988892, "test_error": 0.0968}, {"epoch": 177, "train_loss": 0.2854751099117954, "grad_norm": 0.25278785824775696, "test_error": 0.097}, {"epoch": 178, "train_loss": 0.2856718098949641, "grad_norm": 0.5667650699615479, "test_error": 0.09796666666666666}, {"epoch": 179, "train_loss": 0.2851532194639634, "grad_norm": 0.38822466135025024, "test_error": 0.09668333333333333}, {"epoch": 180, "train_loss": 0.2846849976234759, "grad_norm": 0.39179959893226624, "test_error": 0.09661666666666667}, {"epoch": 181, "train_loss": 0.28425856703085206, "grad_norm": 0.37665751576423645, "test_error": 0.09691666666666666}, {"epoch": 182, "train_loss": 0.2839607265780214, "grad_norm": 0.3765760362148285, "test_error": 0.09613333333333333}, {"epoch": 183, "train_loss": 0.2839264988382347, "grad_norm": 0.36469197273254395, "test_error": 0.09608333333333334}, {"epoch": 184, "train_loss": 0.28358499680207266, "grad_norm": 0.3283773362636566, "test_error": 0.0956}, {"epoch": 185, "train_loss": 0.2829252607308639, "grad_norm": 0.572201132774353, "test_error": 0.098}, {"epoch": 186, "train_loss": 0.2827734015501725, "grad_norm": 0.23479793965816498, "test_error": 0.09473333333333334}, {"epoch": 187, "train_loss": 0.28231488649104725, "grad_norm": 0.2254488617181778, "test_error": 0.09545}, {"epoch": 188, "train_loss": 0.2822598823340765, "grad_norm": 0.3817150592803955, "test_error": 0.09593333333333333}, {"epoch": 189, "train_loss": 0.2818609752706252, "grad_norm": 0.2771325707435608, "test_error": 0.095}, {"epoch": 190, "train_loss": 0.28127576945500915, "grad_norm": 0.4322972595691681, "test_error": 0.09576666666666667}, {"epoch": 191, "train_loss": 0.28141868018688787, "grad_norm": 0.14300048351287842, "test_error": 0.09485}, {"epoch": 192, "train_loss": 0.2808063590126888, "grad_norm": 0.14211569726467133, "test_error": 0.0948}, {"epoch": 193, "train_loss": 0.28069275061809457, "grad_norm": 0.23993027210235596, "test_error": 0.09465}, {"epoch": 194, "train_loss": 0.2804220604212023, "grad_norm": 0.17818237841129303, "test_error": 0.09395}, {"epoch": 195, "train_loss": 0.2801762674998802, "grad_norm": 0.25144535303115845, "test_error": 0.0942}, {"epoch": 196, "train_loss": 0.27978063488720606, "grad_norm": 0.42289412021636963, "test_error": 0.09508333333333334}, {"epoch": 197, "train_loss": 0.27917609552278494, "grad_norm": 0.5170983672142029, "test_error": 0.09513333333333333}, {"epoch": 198, "train_loss": 0.2794854789519062, "grad_norm": 0.6030092239379883, "test_error": 0.09513333333333333}, {"epoch": 199, "train_loss": 0.27859742881303345, "grad_norm": 0.5996164083480835, "test_error": 0.09661666666666667}, {"epoch": 200, "train_loss": 0.2789011855549179, "grad_norm": 0.39773958921432495, "test_error": 0.09343333333333333}, {"epoch": 201, "train_loss": 0.2785889352534432, "grad_norm": 0.4947941303253174, "test_error": 0.09628333333333333}, {"epoch": 202, "train_loss": 0.2784295168685882, "grad_norm": 0.30636876821517944, "test_error": 0.09383333333333334}, {"epoch": 203, "train_loss": 0.277673576602169, "grad_norm": 0.19056697189807892, "test_error": 0.09333333333333334}, {"epoch": 204, "train_loss": 0.27774130099272587, "grad_norm": 0.2389710694551468, "test_error": 0.09373333333333334}, {"epoch": 205, "train_loss": 0.2776776389196748, "grad_norm": 0.6466853022575378, "test_error": 0.09583333333333334}, {"epoch": 206, "train_loss": 0.27718536245559033, "grad_norm": 0.49989691376686096, "test_error": 0.09471666666666667}, {"epoch": 207, "train_loss": 0.2768138614786634, "grad_norm": 0.2062956988811493, "test_error": 0.09336666666666667}, {"epoch": 208, "train_loss": 0.27631087719028197, "grad_norm": 0.19947940111160278, "test_error": 0.09318333333333334}, {"epoch": 209, "train_loss": 0.275915052298534, "grad_norm": 0.6710230112075806, "test_error": 0.09523333333333334}, {"epoch": 210, "train_loss": 0.2759632694084818, "grad_norm": 0.7876386046409607, "test_error": 0.09465}, {"epoch": 211, "train_loss": 0.2756047689444385, "grad_norm": 0.3012582063674927, "test_error": 0.0924}, {"epoch": 212, "train_loss": 0.27567123345549527, "grad_norm": 0.6779006719589233, "test_error": 0.09488333333333333}, {"epoch": 213, "train_loss": 0.2750184734329038, "grad_norm": 0.4385269582271576, "test_error": 0.0931}, {"epoch": 214, "train_loss": 0.27523187088950846, "grad_norm": 0.1992141455411911, "test_error": 0.09266666666666666}, {"epoch": 215, "train_loss": 0.27481179124016003, "grad_norm": 0.42339202761650085, "test_error": 0.09286666666666667}, {"epoch": 216, "train_loss": 0.27437136531466, "grad_norm": 0.7360569834709167, "test_error": 0.09456666666666666}, {"epoch": 217, "train_loss": 0.2742711415218655, "grad_norm": 0.3730810880661011, "test_error": 0.09303333333333333}, {"epoch": 218, "train_loss": 0.2740865850395057, "grad_norm": 0.21777066588401794, "test_error": 0.09203333333333333}, {"epoch": 219, "train_loss": 0.27401182596296225, "grad_norm": 0.34427744150161743, "test_error": 0.09196666666666667}, {"epoch": 220, "train_loss": 0.2734756369947766, "grad_norm": 0.4927710294723511, "test_error": 0.09306666666666667}, {"epoch": 221, "train_loss": 0.27335978466730254, "grad_norm": 0.3135626018047333, "test_error": 0.09133333333333334}, {"epoch": 222, "train_loss": 0.2731371746240184, "grad_norm": 0.3097028136253357, "test_error": 0.09223333333333333}, {"epoch": 223, "train_loss": 0.27313659465677725, "grad_norm": 0.3409096896648407, "test_error": 0.09145}, {"epoch": 224, "train_loss": 0.27274869265352997, "grad_norm": 0.6024158000946045, "test_error": 0.09238333333333333}, {"epoch": 225, "train_loss": 0.27240674385940655, "grad_norm": 0.32080018520355225, "test_error": 0.09131666666666667}, {"epoch": 226, "train_loss": 0.2722554727291378, "grad_norm": 0.4175986051559448, "test_error": 0.0925}, {"epoch": 227, "train_loss": 0.27171920372118863, "grad_norm": 0.27446630597114563, "test_error": 0.09076666666666666}, {"epoch": 228, "train_loss": 0.27162941156552795, "grad_norm": 0.28149041533470154, "test_error": 0.09106666666666667}, {"epoch": 229, "train_loss": 0.27144941399102873, "grad_norm": 0.47564417123794556, "test_error": 0.09243333333333334}, {"epoch": 230, "train_loss": 0.27117422022247534, "grad_norm": 0.3370688557624817, "test_error": 0.09126666666666666}, {"epoch": 231, "train_loss": 0.27122142814619776, "grad_norm": 0.26709452271461487, "test_error": 0.09143333333333334}, {"epoch": 232, "train_loss": 0.2707236228720285, "grad_norm": 0.41093114018440247, "test_error": 0.09091666666666667}, {"epoch": 233, "train_loss": 0.270701214539508, "grad_norm": 0.48866158723831177, "test_error": 0.0914}, {"epoch": 234, "train_loss": 0.27026153437506095, "grad_norm": 0.44440779089927673, "test_error": 0.09038333333333333}, {"epoch": 235, "train_loss": 0.27024489571604254, "grad_norm": 0.40930598974227905, "test_error": 0.09076666666666666}, {"epoch": 236, "train_loss": 0.2700386786884628, "grad_norm": 0.45026177167892456, "test_error": 0.0914}, {"epoch": 237, "train_loss": 0.26977253466293527, "grad_norm": 0.36325863003730774, "test_error": 0.091}, {"epoch": 238, "train_loss": 0.26981590678081074, "grad_norm": 0.4410477578639984, "test_error": 0.09133333333333334}, {"epoch": 239, "train_loss": 0.26912499123761274, "grad_norm": 0.3818770945072174, "test_error": 0.0899}, {"epoch": 240, "train_loss": 0.2690449275838522, "grad_norm": 0.4494155943393707, "test_error": 0.09046666666666667}, {"epoch": 241, "train_loss": 0.268881830535635, "grad_norm": 0.2826807200908661, "test_error": 0.0893}, {"epoch": 242, "train_loss": 0.268170509451457, "grad_norm": 0.4017679989337921, "test_error": 0.09131666666666667}, {"epoch": 243, "train_loss": 0.2683852911586873, "grad_norm": 0.33596527576446533, "test_error": 0.08923333333333333}, {"epoch": 244, "train_loss": 0.26827971210276397, "grad_norm": 0.19341731071472168, "test_error": 0.08901666666666666}, {"epoch": 245, "train_loss": 0.26786943603221636, "grad_norm": 0.4803042411804199, "test_error": 0.0906}, {"epoch": 246, "train_loss": 0.26774592002865394, "grad_norm": 0.2942976653575897, "test_error": 0.08946666666666667}, {"epoch": 247, "train_loss": 0.26776819096684146, "grad_norm": 0.1536838561296463, "test_error": 0.0893}, {"epoch": 248, "train_loss": 0.26745126877507813, "grad_norm": 0.15945352613925934, "test_error": 0.0886}, {"epoch": 249, "train_loss": 0.2673836069385676, "grad_norm": 0.2413269430398941, "test_error": 0.08988333333333333}, {"epoch": 250, "train_loss": 0.26717133007633187, "grad_norm": 0.1923474371433258, "test_error": 0.08921666666666667}, {"epoch": 251, "train_loss": 0.2668618965841209, "grad_norm": 0.5749830603599548, "test_error": 0.09065}, {"epoch": 252, "train_loss": 0.26685579801917386, "grad_norm": 0.9788993000984192, "test_error": 0.09211666666666667}, {"epoch": 253, "train_loss": 0.26665414578351193, "grad_norm": 0.45822873711586, "test_error": 0.08913333333333333}, {"epoch": 254, "train_loss": 0.2663546345335587, "grad_norm": 0.2158087193965912, "test_error": 0.08851666666666666}, {"epoch": 255, "train_loss": 0.26624199642403984, "grad_norm": 0.24263879656791687, "test_error": 0.08866666666666667}, {"epoch": 256, "train_loss": 0.26589366818980004, "grad_norm": 0.40488970279693604, "test_error": 0.0892}, {"epoch": 257, "train_loss": 0.26550771165289916, "grad_norm": 0.18089155852794647, "test_error": 0.08808333333333333}, {"epoch": 258, "train_loss": 0.2654263606496, "grad_norm": 0.24761831760406494, "test_error": 0.08825}, {"epoch": 259, "train_loss": 0.26517790292715654, "grad_norm": 0.2117391675710678, "test_error": 0.08786666666666666}, {"epoch": 260, "train_loss": 0.2649333627662466, "grad_norm": 0.6629614233970642, "test_error": 0.09106666666666667}, {"epoch": 261, "train_loss": 0.2651687617205704, "grad_norm": 0.5319689512252808, "test_error": 0.08976666666666666}, {"epoch": 262, "train_loss": 0.2645301463729702, "grad_norm": 0.3613664209842682, "test_error": 0.08875}, {"epoch": 263, "train_loss": 0.2645685365103806, "grad_norm": 0.38661661744117737, "test_error": 0.08908333333333333}, {"epoch": 264, "train_loss": 0.26435783755593, "grad_norm": 0.2710779309272766, "test_error": 0.08783333333333333}, {"epoch": 265, "train_loss": 0.26396242543131426, "grad_norm": 0.5412624478340149, "test_error": 0.08955}, {"epoch": 266, "train_loss": 0.2637861659443782, "grad_norm": 0.24647150933742523, "test_error": 0.08793333333333334}, {"epoch": 267, "train_loss": 0.26385912094878344, "grad_norm": 0.7065052390098572, "test_error": 0.09003333333333334}, {"epoch": 268, "train_loss": 0.26367673858844987, "grad_norm": 0.3959480822086334, "test_error": 0.08815}, {"epoch": 269, "train_loss": 0.26318015378620474, "grad_norm": 0.41399407386779785, "test_error": 0.08873333333333333}, {"epoch": 270, "train_loss": 0.2626528753283589, "grad_norm": 0.6740717887878418, "test_error": 0.0894}, {"epoch": 271, "train_loss": 0.2628314689028387, "grad_norm": 0.36224499344825745, "test_error": 0.08766666666666667}, {"epoch": 272, "train_loss": 0.2626354487154555, "grad_norm": 0.42494848370552063, "test_error": 0.08878333333333334}, {"epoch": 273, "train_loss": 0.26272264777997045, "grad_norm": 0.37596508860588074, "test_error": 0.0882}, {"epoch": 274, "train_loss": 0.2624797442730827, "grad_norm": 0.30115875601768494, "test_error": 0.08741666666666667}, {"epoch": 275, "train_loss": 0.2622309643299474, "grad_norm": 0.5334152579307556, "test_error": 0.08853333333333334}, {"epoch": 276, "train_loss": 0.26240385880111716, "grad_norm": 0.2758832275867462, "test_error": 0.08651666666666667}, {"epoch": 277, "train_loss": 0.2618556572967209, "grad_norm": 0.3000035881996155, "test_error": 0.08726666666666667}, {"epoch": 278, "train_loss": 0.2620046832778025, "grad_norm": 0.3722778558731079, "test_error": 0.08768333333333334}, {"epoch": 279, "train_loss": 0.2610190911918568, "grad_norm": 0.685370147228241, "test_error": 0.08931666666666667}, {"epoch": 280, "train_loss": 0.2615629937117143, "grad_norm": 0.5406850576400757, "test_error": 0.0876}, {"epoch": 281, "train_loss": 0.2611346956177925, "grad_norm": 0.39603641629219055, "test_error": 0.08726666666666667}, {"epoch": 282, "train_loss": 0.260921317165019, "grad_norm": 0.41247743368148804, "test_error": 0.08698333333333333}, {"epoch": 283, "train_loss": 0.26067514726758234, "grad_norm": 0.4337441921234131, "test_error": 0.08715}, {"epoch": 284, "train_loss": 0.2607375181762812, "grad_norm": 0.2926219701766968, "test_error": 0.08576666666666667}, {"epoch": 285, "train_loss": 0.26059165847456706, "grad_norm": 0.2696886360645294, "test_error": 0.08511666666666666}, {"epoch": 286, "train_loss": 0.2608267140183598, "grad_norm": 0.4223499298095703, "test_error": 0.08726666666666667}, {"epoch": 287, "train_loss": 0.26029340519565936, "grad_norm": 0.2999013066291809, "test_error": 0.08603333333333334}, {"epoch": 288, "train_loss": 0.26005390396372724, "grad_norm": 0.3839917778968811, "test_error": 0.08681666666666667}, {"epoch": 289, "train_loss": 0.25998433244146874, "grad_norm": 0.835922360420227, "test_error": 0.09063333333333333}, {"epoch": 290, "train_loss": 0.2596778422606294, "grad_norm": 0.36440277099609375, "test_error": 0.08656666666666667}, {"epoch": 291, "train_loss": 0.2594984056891408, "grad_norm": 0.24156272411346436, "test_error": 0.08593333333333333}, {"epoch": 292, "train_loss": 0.2596563230384685, "grad_norm": 0.26875317096710205, "test_error": 0.0855}, {"epoch": 293, "train_loss": 0.2592472330740032, "grad_norm": 0.3689427375793457, "test_error": 0.08706666666666667}, {"epoch": 294, "train_loss": 0.25907818405283617, "grad_norm": 0.2967124879360199, "test_error": 0.0861}, {"epoch": 295, "train_loss": 0.2587132837137518, "grad_norm": 0.43562400341033936, "test_error": 0.08681666666666667}, {"epoch": 296, "train_loss": 0.2589677096071343, "grad_norm": 0.4384140968322754, "test_error": 0.08746666666666666}, {"epoch": 297, "train_loss": 0.25864751168852673, "grad_norm": 0.19833801686763763, "test_error": 0.0851}, {"epoch": 298, "train_loss": 0.2583586108213834, "grad_norm": 0.3005191683769226, "test_error": 0.08551666666666667}, {"epoch": 299, "train_loss": 0.2581481015212291, "grad_norm": 0.21125392615795135, "test_error": 0.08605}, {"epoch": 300, "train_loss": 0.2583432991812782, "grad_norm": 0.6204190850257874, "test_error": 0.08663333333333334}]}