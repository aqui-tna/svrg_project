{"argv": ["train.py", "--seed", "79", "--optimizer", "SGD", "--run_name", "sgd_0.03.json", "--output_path", "experiments/nonconvex_fmnist/sgd-0.03.json", "--dataset", "FMNIST", "--layer_sizes", "784", "100", "10", "--batch_size", "10", "--learning_rate", "0.03", "--weight_decay", "0.001", "--num_epochs", "300", "--download", "--device", "cuda"], "args": {"seed": 79, "optimizer": "SGD", "run_name": "sgd_0.03.json", "output_path": "experiments/nonconvex_fmnist/sgd-0.03.json", "device": "cuda", "dataset": "FMNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": true, "layer_sizes": [784, 100, 10], "batch_size": 10, "test_batch_size": 256, "learning_rate": 0.03, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 100, "num_inner_epochs": 5, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 300}, "metrics": [{"epoch": 1, "train_loss": 0.5616080117126306, "grad_norm": 0.7533555030822754, "test_error": 0.16068333333333334}, {"epoch": 2, "train_loss": 0.42065155956863115, "grad_norm": 0.7243668437004089, "test_error": 0.14306666666666668}, {"epoch": 3, "train_loss": 0.3884334541736947, "grad_norm": 0.5267690420150757, "test_error": 0.13303333333333334}, {"epoch": 4, "train_loss": 0.36954639876734774, "grad_norm": 0.7372263073921204, "test_error": 0.13558333333333333}, {"epoch": 5, "train_loss": 0.3585435329563916, "grad_norm": 0.5277100205421448, "test_error": 0.12641666666666668}, {"epoch": 6, "train_loss": 0.34914674871205353, "grad_norm": 0.835133969783783, "test_error": 0.12816666666666668}, {"epoch": 7, "train_loss": 0.34334416152055686, "grad_norm": 0.45693114399909973, "test_error": 0.11863333333333333}, {"epoch": 8, "train_loss": 0.3368533811257221, "grad_norm": 0.3588823676109314, "test_error": 0.11755}, {"epoch": 9, "train_loss": 0.33376188287872355, "grad_norm": 0.6168709397315979, "test_error": 0.1194}, {"epoch": 10, "train_loss": 0.3293189185350978, "grad_norm": 0.46198347210884094, "test_error": 0.1124}, {"epoch": 11, "train_loss": 0.3262255238063323, "grad_norm": 0.3512941002845764, "test_error": 0.11286666666666667}, {"epoch": 12, "train_loss": 0.32389769492135384, "grad_norm": 0.6498108506202698, "test_error": 0.11851666666666667}, {"epoch": 13, "train_loss": 0.3223023423886237, "grad_norm": 0.9257192611694336, "test_error": 0.12256666666666667}, {"epoch": 14, "train_loss": 0.32009702921643235, "grad_norm": 0.47875741124153137, "test_error": 0.11286666666666667}, {"epoch": 15, "train_loss": 0.3183177193052446, "grad_norm": 0.38739919662475586, "test_error": 0.10865}, {"epoch": 16, "train_loss": 0.3163290144500012, "grad_norm": 0.5909929871559143, "test_error": 0.11103333333333333}, {"epoch": 17, "train_loss": 0.31550947498964765, "grad_norm": 0.4530263841152191, "test_error": 0.10676666666666666}, {"epoch": 18, "train_loss": 0.3145029495740309, "grad_norm": 0.3958342671394348, "test_error": 0.10505}, {"epoch": 19, "train_loss": 0.3114993109549396, "grad_norm": 0.589928925037384, "test_error": 0.11263333333333334}, {"epoch": 20, "train_loss": 0.31089034184526343, "grad_norm": 0.6683239340782166, "test_error": 0.11678333333333334}, {"epoch": 21, "train_loss": 0.31135684786139367, "grad_norm": 0.3351280689239502, "test_error": 0.10135}, {"epoch": 22, "train_loss": 0.31111336600982276, "grad_norm": 0.4197608232498169, "test_error": 0.10401666666666666}, {"epoch": 23, "train_loss": 0.3096875557031405, "grad_norm": 0.35681667923927307, "test_error": 0.10296666666666666}, {"epoch": 24, "train_loss": 0.30969357015704735, "grad_norm": 0.6806880235671997, "test_error": 0.11188333333333333}, {"epoch": 25, "train_loss": 0.3077759887103457, "grad_norm": 0.30336233973503113, "test_error": 0.10098333333333333}, {"epoch": 26, "train_loss": 0.3083380351952898, "grad_norm": 0.45717689394950867, "test_error": 0.10208333333333333}, {"epoch": 27, "train_loss": 0.307478068452018, "grad_norm": 0.42461222410202026, "test_error": 0.11093333333333333}, {"epoch": 28, "train_loss": 0.30707681229469985, "grad_norm": 0.6835926175117493, "test_error": 0.11573333333333333}, {"epoch": 29, "train_loss": 0.3064604895651573, "grad_norm": 0.5357083082199097, "test_error": 0.1044}, {"epoch": 30, "train_loss": 0.3065148092872696, "grad_norm": 0.4325535297393799, "test_error": 0.10451666666666666}, {"epoch": 31, "train_loss": 0.30494953819581616, "grad_norm": 0.427852988243103, "test_error": 0.10666666666666667}, {"epoch": 32, "train_loss": 0.3042518062358722, "grad_norm": 0.5060930848121643, "test_error": 0.10798333333333333}, {"epoch": 33, "train_loss": 0.3054803872296276, "grad_norm": 0.3320842981338501, "test_error": 0.10221666666666666}, {"epoch": 34, "train_loss": 0.30351460062502883, "grad_norm": 0.3415227234363556, "test_error": 0.10088333333333334}, {"epoch": 35, "train_loss": 0.3062260802996655, "grad_norm": 0.5251258015632629, "test_error": 0.10721666666666667}, {"epoch": 36, "train_loss": 0.3034520582046437, "grad_norm": 0.31074148416519165, "test_error": 0.10106666666666667}, {"epoch": 37, "train_loss": 0.304457828841405, "grad_norm": 0.9032521843910217, "test_error": 0.11695}, {"epoch": 38, "train_loss": 0.30476737971510737, "grad_norm": 0.3956300914287567, "test_error": 0.10031666666666667}, {"epoch": 39, "train_loss": 0.3036203849463103, "grad_norm": 0.8676361441612244, "test_error": 0.11578333333333334}, {"epoch": 40, "train_loss": 0.30372580491790235, "grad_norm": 0.34935954213142395, "test_error": 0.10246666666666666}, {"epoch": 41, "train_loss": 0.3032117449065748, "grad_norm": 0.33562442660331726, "test_error": 0.10041666666666667}, {"epoch": 42, "train_loss": 0.30287925434779994, "grad_norm": 0.271884948015213, "test_error": 0.09751666666666667}, {"epoch": 43, "train_loss": 0.3022019791615506, "grad_norm": 0.4008912444114685, "test_error": 0.10163333333333334}, {"epoch": 44, "train_loss": 0.3018884386573142, "grad_norm": 0.5216447710990906, "test_error": 0.10838333333333333}, {"epoch": 45, "train_loss": 0.3024462103536741, "grad_norm": 0.5048264861106873, "test_error": 0.1063}, {"epoch": 46, "train_loss": 0.30180242905082805, "grad_norm": 0.30569928884506226, "test_error": 0.09961666666666667}, {"epoch": 47, "train_loss": 0.3006404002328248, "grad_norm": 0.6880309581756592, "test_error": 0.11451666666666667}, {"epoch": 48, "train_loss": 0.3008863628662657, "grad_norm": 0.30951178073883057, "test_error": 0.09861666666666667}, {"epoch": 49, "train_loss": 0.3007060561858622, "grad_norm": 0.4598945081233978, "test_error": 0.10215}, {"epoch": 50, "train_loss": 0.30110443917246693, "grad_norm": 0.5060669779777527, "test_error": 0.10505}, {"epoch": 51, "train_loss": 0.30035397841370043, "grad_norm": 0.46347182989120483, "test_error": 0.10261666666666666}, {"epoch": 52, "train_loss": 0.300052905562489, "grad_norm": 0.43232041597366333, "test_error": 0.10316666666666667}, {"epoch": 53, "train_loss": 0.2996294483243255, "grad_norm": 0.6620683670043945, "test_error": 0.10941666666666666}, {"epoch": 54, "train_loss": 0.3004359334770124, "grad_norm": 0.43971118330955505, "test_error": 0.11013333333333333}, {"epoch": 55, "train_loss": 0.2993210316382659, "grad_norm": 0.3860310912132263, "test_error": 0.09955}, {"epoch": 56, "train_loss": 0.2998991705812514, "grad_norm": 0.30539074540138245, "test_error": 0.0978}, {"epoch": 57, "train_loss": 0.29990820337506013, "grad_norm": 0.3457522392272949, "test_error": 0.10316666666666667}, {"epoch": 58, "train_loss": 0.29898028795972154, "grad_norm": 0.24099181592464447, "test_error": 0.0964}, {"epoch": 59, "train_loss": 0.300009625475582, "grad_norm": 0.3689850866794586, "test_error": 0.1001}, {"epoch": 60, "train_loss": 0.2984660335503286, "grad_norm": 0.5720599293708801, "test_error": 0.10746666666666667}, {"epoch": 61, "train_loss": 0.30024268781021235, "grad_norm": 0.643856942653656, "test_error": 0.11171666666666667}, {"epoch": 62, "train_loss": 0.2994324615536413, "grad_norm": 0.3448449373245239, "test_error": 0.09666666666666666}, {"epoch": 63, "train_loss": 0.2985370134286738, "grad_norm": 0.3445984125137329, "test_error": 0.09808333333333333}, {"epoch": 64, "train_loss": 0.2983271725179899, "grad_norm": 0.5516592860221863, "test_error": 0.10721666666666667}, {"epoch": 65, "train_loss": 0.29977067105609845, "grad_norm": 0.49928566813468933, "test_error": 0.10266666666666667}, {"epoch": 66, "train_loss": 0.29881905211287085, "grad_norm": 0.37267109751701355, "test_error": 0.10103333333333334}, {"epoch": 67, "train_loss": 0.2972646101014689, "grad_norm": 0.38123270869255066, "test_error": 0.10358333333333333}, {"epoch": 68, "train_loss": 0.2977806298088593, "grad_norm": 0.7935159802436829, "test_error": 0.11616666666666667}, {"epoch": 69, "train_loss": 0.2979089704686, "grad_norm": 1.2101025581359863, "test_error": 0.13648333333333335}, {"epoch": 70, "train_loss": 0.29785780733361994, "grad_norm": 0.27584728598594666, "test_error": 0.09688333333333334}, {"epoch": 71, "train_loss": 0.29746662397558493, "grad_norm": 0.6317367553710938, "test_error": 0.11196666666666667}, {"epoch": 72, "train_loss": 0.29836960385995914, "grad_norm": 0.7952908873558044, "test_error": 0.1098}, {"epoch": 73, "train_loss": 0.29726575903237484, "grad_norm": 1.046663761138916, "test_error": 0.12471666666666667}, {"epoch": 74, "train_loss": 0.2989024300641225, "grad_norm": 0.3885413408279419, "test_error": 0.10271666666666666}, {"epoch": 75, "train_loss": 0.29649660778262965, "grad_norm": 0.35047903656959534, "test_error": 0.09828333333333333}, {"epoch": 76, "train_loss": 0.29601517937875665, "grad_norm": 0.9001764059066772, "test_error": 0.11423333333333334}, {"epoch": 77, "train_loss": 0.29643348696280736, "grad_norm": 0.5760733485221863, "test_error": 0.11061666666666667}, {"epoch": 78, "train_loss": 0.2975732715971923, "grad_norm": 0.6439641118049622, "test_error": 0.1069}, {"epoch": 79, "train_loss": 0.2969351781827087, "grad_norm": 0.6125814318656921, "test_error": 0.11093333333333333}, {"epoch": 80, "train_loss": 0.29558351043992054, "grad_norm": 0.3313988447189331, "test_error": 0.0999}, {"epoch": 81, "train_loss": 0.29654053739993835, "grad_norm": 0.5446321964263916, "test_error": 0.10663333333333333}, {"epoch": 82, "train_loss": 0.29682762460461043, "grad_norm": 0.4641270637512207, "test_error": 0.10591666666666667}, {"epoch": 83, "train_loss": 0.295012546774194, "grad_norm": 0.5053514838218689, "test_error": 0.10325}, {"epoch": 84, "train_loss": 0.2970143326513159, "grad_norm": 0.3580750823020935, "test_error": 0.10366666666666667}, {"epoch": 85, "train_loss": 0.29532004283640223, "grad_norm": 0.2660471498966217, "test_error": 0.09591666666666666}, {"epoch": 86, "train_loss": 0.2947125153637802, "grad_norm": 0.6035504341125488, "test_error": 0.10665}, {"epoch": 87, "train_loss": 0.2958458955245248, "grad_norm": 0.33212408423423767, "test_error": 0.1}, {"epoch": 88, "train_loss": 0.29525729100340203, "grad_norm": 0.2584248483181, "test_error": 0.0928}, {"epoch": 89, "train_loss": 0.2963552358350717, "grad_norm": 0.3824317753314972, "test_error": 0.10233333333333333}, {"epoch": 90, "train_loss": 0.2960288526014192, "grad_norm": 0.579444408416748, "test_error": 0.1042}, {"epoch": 91, "train_loss": 0.2960851573415954, "grad_norm": 0.5326750874519348, "test_error": 0.10761666666666667}, {"epoch": 92, "train_loss": 0.2958874452651168, "grad_norm": 0.9491478204727173, "test_error": 0.11791666666666667}, {"epoch": 93, "train_loss": 0.29521790324500763, "grad_norm": 0.7328137159347534, "test_error": 0.10878333333333333}, {"epoch": 94, "train_loss": 0.2949897719650374, "grad_norm": 0.6074943542480469, "test_error": 0.11045}, {"epoch": 95, "train_loss": 0.29572028331388717, "grad_norm": 0.5910516381263733, "test_error": 0.1046}, {"epoch": 96, "train_loss": 0.2944279102537936, "grad_norm": 0.505060613155365, "test_error": 0.10426666666666666}, {"epoch": 97, "train_loss": 0.29521761486500814, "grad_norm": 0.3520408272743225, "test_error": 0.09935}, {"epoch": 98, "train_loss": 0.2952451923727058, "grad_norm": 0.47414258122444153, "test_error": 0.10421666666666667}, {"epoch": 99, "train_loss": 0.29639898730727143, "grad_norm": 0.37639811635017395, "test_error": 0.10108333333333333}, {"epoch": 100, "train_loss": 0.29615719938728335, "grad_norm": 0.3893505036830902, "test_error": 0.09993333333333333}, {"epoch": 101, "train_loss": 0.29589815810501263, "grad_norm": 1.0294268131256104, "test_error": 0.12315}, {"epoch": 102, "train_loss": 0.295430481342366, "grad_norm": 0.3681102991104126, "test_error": 0.09763333333333334}, {"epoch": 103, "train_loss": 0.29614682870024506, "grad_norm": 0.5004655718803406, "test_error": 0.0995}, {"epoch": 104, "train_loss": 0.295248780764717, "grad_norm": 0.7233015298843384, "test_error": 0.11713333333333334}, {"epoch": 105, "train_loss": 0.2956250434486428, "grad_norm": 0.4426659345626831, "test_error": 0.09768333333333333}, {"epoch": 106, "train_loss": 0.29514395172179986, "grad_norm": 0.5223937034606934, "test_error": 0.10193333333333333}, {"epoch": 107, "train_loss": 0.2946468710526048, "grad_norm": 0.6932104825973511, "test_error": 0.10775}, {"epoch": 108, "train_loss": 0.2947958606960795, "grad_norm": 0.42072874307632446, "test_error": 0.1008}, {"epoch": 109, "train_loss": 0.29496356071976093, "grad_norm": 0.2062489092350006, "test_error": 0.09296666666666667}, {"epoch": 110, "train_loss": 0.2937036923278744, "grad_norm": 0.6709468364715576, "test_error": 0.1103}, {"epoch": 111, "train_loss": 0.29473531048721635, "grad_norm": 0.29048633575439453, "test_error": 0.09765}, {"epoch": 112, "train_loss": 0.2944963632680786, "grad_norm": 0.4207800328731537, "test_error": 0.09925}, {"epoch": 113, "train_loss": 0.29371871531793536, "grad_norm": 0.6310268044471741, "test_error": 0.11055}, {"epoch": 114, "train_loss": 0.2930631698523648, "grad_norm": 0.47428756952285767, "test_error": 0.0997}, {"epoch": 115, "train_loss": 0.2947360105998038, "grad_norm": 0.42062416672706604, "test_error": 0.1005}, {"epoch": 116, "train_loss": 0.29514965912738506, "grad_norm": 0.41620928049087524, "test_error": 0.09746666666666666}, {"epoch": 117, "train_loss": 0.2948583083312842, "grad_norm": 0.5685524344444275, "test_error": 0.10813333333333333}, {"epoch": 118, "train_loss": 0.2948877761029871, "grad_norm": 0.4655851423740387, "test_error": 0.10226666666666667}, {"epoch": 119, "train_loss": 0.29417632794201687, "grad_norm": 0.9478252530097961, "test_error": 0.11436666666666667}, {"epoch": 120, "train_loss": 0.2953205426457959, "grad_norm": 0.3658876121044159, "test_error": 0.09761666666666667}, {"epoch": 121, "train_loss": 0.2943629795218973, "grad_norm": 0.579437792301178, "test_error": 0.1068}, {"epoch": 122, "train_loss": 0.295469324471429, "grad_norm": 0.4644135534763336, "test_error": 0.1028}, {"epoch": 123, "train_loss": 0.2957861910338979, "grad_norm": 0.31047242879867554, "test_error": 0.09625}, {"epoch": 124, "train_loss": 0.29501373086792104, "grad_norm": 0.7015054225921631, "test_error": 0.10801666666666666}, {"epoch": 125, "train_loss": 0.2931400105698849, "grad_norm": 0.2808372676372528, "test_error": 0.09648333333333334}, {"epoch": 126, "train_loss": 0.2953951201962773, "grad_norm": 0.3996325135231018, "test_error": 0.09933333333333333}, {"epoch": 127, "train_loss": 0.29492970828007187, "grad_norm": 0.5206130743026733, "test_error": 0.10053333333333334}, {"epoch": 128, "train_loss": 0.2942785514264057, "grad_norm": 1.297441005706787, "test_error": 0.13048333333333334}, {"epoch": 129, "train_loss": 0.29528643587821474, "grad_norm": 0.34304431080818176, "test_error": 0.09918333333333333}, {"epoch": 130, "train_loss": 0.2949871048573405, "grad_norm": 0.4360322952270508, "test_error": 0.10128333333333334}, {"epoch": 131, "train_loss": 0.29572577760488883, "grad_norm": 0.42996206879615784, "test_error": 0.10296666666666666}, {"epoch": 132, "train_loss": 0.2933654154419589, "grad_norm": 0.7592871189117432, "test_error": 0.10828333333333333}, {"epoch": 133, "train_loss": 0.29518272865113493, "grad_norm": 0.37493738532066345, "test_error": 0.10221666666666666}, {"epoch": 134, "train_loss": 0.2948402769813159, "grad_norm": 0.5310467481613159, "test_error": 0.09866666666666667}, {"epoch": 135, "train_loss": 0.2948674957326148, "grad_norm": 0.426998108625412, "test_error": 0.10401666666666666}, {"epoch": 136, "train_loss": 0.2943130640095333, "grad_norm": 0.45120033621788025, "test_error": 0.09965}, {"epoch": 137, "train_loss": 0.29516601367581946, "grad_norm": 0.33972468972206116, "test_error": 0.0982}, {"epoch": 138, "train_loss": 0.29502962134957, "grad_norm": 0.454595685005188, "test_error": 0.09931666666666666}, {"epoch": 139, "train_loss": 0.29578228301974013, "grad_norm": 0.38379836082458496, "test_error": 0.09873333333333334}, {"epoch": 140, "train_loss": 0.2942671385665114, "grad_norm": 0.8656798601150513, "test_error": 0.11735}, {"epoch": 141, "train_loss": 0.293701051022547, "grad_norm": 0.42544668912887573, "test_error": 0.09855}, {"epoch": 142, "train_loss": 0.29460922004329043, "grad_norm": 0.4583246409893036, "test_error": 0.10136666666666666}, {"epoch": 143, "train_loss": 0.2949024212793835, "grad_norm": 0.4377359449863434, "test_error": 0.09976666666666667}, {"epoch": 144, "train_loss": 0.29448871975931495, "grad_norm": 0.8890906572341919, "test_error": 0.1109}, {"epoch": 145, "train_loss": 0.2947397378802998, "grad_norm": 0.494576632976532, "test_error": 0.09901666666666667}, {"epoch": 146, "train_loss": 0.29412580355171425, "grad_norm": 0.3399229347705841, "test_error": 0.09593333333333333}, {"epoch": 147, "train_loss": 0.2944513249769807, "grad_norm": 0.5996451377868652, "test_error": 0.1111}, {"epoch": 148, "train_loss": 0.29419186400133185, "grad_norm": 0.4519073963165283, "test_error": 0.09963333333333334}, {"epoch": 149, "train_loss": 0.2927135446264486, "grad_norm": 0.23469656705856323, "test_error": 0.09355}, {"epoch": 150, "train_loss": 0.2932939594959995, "grad_norm": 0.876658022403717, "test_error": 0.11831666666666667}, {"epoch": 151, "train_loss": 0.2947878944370896, "grad_norm": 0.34605199098587036, "test_error": 0.09856666666666666}, {"epoch": 152, "train_loss": 0.29406057158050436, "grad_norm": 0.26866504549980164, "test_error": 0.0968}, {"epoch": 153, "train_loss": 0.2951352365668863, "grad_norm": 0.5415224432945251, "test_error": 0.10126666666666667}, {"epoch": 154, "train_loss": 0.2931861482446548, "grad_norm": 0.20728947222232819, "test_error": 0.09586666666666667}, {"epoch": 155, "train_loss": 0.2948862616086844, "grad_norm": 0.42694762349128723, "test_error": 0.09963333333333334}, {"epoch": 156, "train_loss": 0.29361389559111556, "grad_norm": 0.24690717458724976, "test_error": 0.09413333333333333}, {"epoch": 157, "train_loss": 0.2950536382048158, "grad_norm": 0.7196193337440491, "test_error": 0.1083}, {"epoch": 158, "train_loss": 0.29288980388307634, "grad_norm": 0.44614726305007935, "test_error": 0.09978333333333333}, {"epoch": 159, "train_loss": 0.29544646356541976, "grad_norm": 0.27321657538414, "test_error": 0.09655}, {"epoch": 160, "train_loss": 0.2956939305078898, "grad_norm": 0.44083282351493835, "test_error": 0.10058333333333333}, {"epoch": 161, "train_loss": 0.29441862263526614, "grad_norm": 0.49372878670692444, "test_error": 0.10021666666666666}, {"epoch": 162, "train_loss": 0.29366179278628746, "grad_norm": 0.5360119342803955, "test_error": 0.10398333333333333}, {"epoch": 163, "train_loss": 0.29378468420294424, "grad_norm": 0.2541445195674896, "test_error": 0.0953}, {"epoch": 164, "train_loss": 0.2944376005512895, "grad_norm": 0.2095210999250412, "test_error": 0.09335}, {"epoch": 165, "train_loss": 0.29410773992503525, "grad_norm": 0.3832474648952484, "test_error": 0.09918333333333333}, {"epoch": 166, "train_loss": 0.2939072268458161, "grad_norm": 0.618927001953125, "test_error": 0.10801666666666666}, {"epoch": 167, "train_loss": 0.2946463249590403, "grad_norm": 0.4900676906108856, "test_error": 0.10235}, {"epoch": 168, "train_loss": 0.29415456219358993, "grad_norm": 0.5039132237434387, "test_error": 0.10243333333333333}, {"epoch": 169, "train_loss": 0.2946829749760994, "grad_norm": 0.3630720376968384, "test_error": 0.09763333333333334}, {"epoch": 170, "train_loss": 0.29405287265304164, "grad_norm": 0.49299687147140503, "test_error": 0.10466666666666667}, {"epoch": 171, "train_loss": 0.29480714502884076, "grad_norm": 0.422730952501297, "test_error": 0.10108333333333333}, {"epoch": 172, "train_loss": 0.2938849725300291, "grad_norm": 0.4439312219619751, "test_error": 0.09886666666666667}, {"epoch": 173, "train_loss": 0.2936719804292855, "grad_norm": 0.5544241070747375, "test_error": 0.10583333333333333}, {"epoch": 174, "train_loss": 0.294051280725825, "grad_norm": 0.791499137878418, "test_error": 0.11338333333333334}, {"epoch": 175, "train_loss": 0.29423505159063884, "grad_norm": 0.508415699005127, "test_error": 0.10681666666666667}, {"epoch": 176, "train_loss": 0.29447409878023123, "grad_norm": 0.23222938179969788, "test_error": 0.09273333333333333}, {"epoch": 177, "train_loss": 0.29388429431333984, "grad_norm": 0.4064902067184448, "test_error": 0.09953333333333333}, {"epoch": 178, "train_loss": 0.2944694733535095, "grad_norm": 0.6069418787956238, "test_error": 0.1073}, {"epoch": 179, "train_loss": 0.2930256701407488, "grad_norm": 0.4270387887954712, "test_error": 0.09985}, {"epoch": 180, "train_loss": 0.2932213847856813, "grad_norm": 0.5892314910888672, "test_error": 0.10406666666666667}, {"epoch": 181, "train_loss": 0.29337520757860813, "grad_norm": 0.5376812219619751, "test_error": 0.10368333333333334}, {"epoch": 182, "train_loss": 0.2937439564017113, "grad_norm": 0.31106775999069214, "test_error": 0.09638333333333333}, {"epoch": 183, "train_loss": 0.2945358331951623, "grad_norm": 0.42313238978385925, "test_error": 0.10236666666666666}, {"epoch": 184, "train_loss": 0.293128072759447, "grad_norm": 0.7081835865974426, "test_error": 0.10316666666666667}, {"epoch": 185, "train_loss": 0.2952769114859402, "grad_norm": 0.5684487819671631, "test_error": 0.10885}, {"epoch": 186, "train_loss": 0.2933181086317248, "grad_norm": 0.6037555932998657, "test_error": 0.10488333333333333}, {"epoch": 187, "train_loss": 0.2940483093711082, "grad_norm": 0.26504087448120117, "test_error": 0.09565}, {"epoch": 188, "train_loss": 0.2932727915691988, "grad_norm": 0.44057363271713257, "test_error": 0.10283333333333333}, {"epoch": 189, "train_loss": 0.2952095598515201, "grad_norm": 0.483152836561203, "test_error": 0.10405}, {"epoch": 190, "train_loss": 0.29252664138859835, "grad_norm": 0.244004026055336, "test_error": 0.09513333333333333}, {"epoch": 191, "train_loss": 0.29435737716406585, "grad_norm": 0.3992481827735901, "test_error": 0.09833333333333333}, {"epoch": 192, "train_loss": 0.2926744178708177, "grad_norm": 0.5566024780273438, "test_error": 0.10148333333333333}, {"epoch": 193, "train_loss": 0.294219923212387, "grad_norm": 0.33940765261650085, "test_error": 0.09576666666666667}, {"epoch": 194, "train_loss": 0.29362915889934327, "grad_norm": 0.3645440936088562, "test_error": 0.09473333333333334}, {"epoch": 195, "train_loss": 0.29367999790783506, "grad_norm": 0.3841225802898407, "test_error": 0.09953333333333333}, {"epoch": 196, "train_loss": 0.294413868389364, "grad_norm": 0.1938292533159256, "test_error": 0.09201666666666666}, {"epoch": 197, "train_loss": 0.2927992696859874, "grad_norm": 0.7761270999908447, "test_error": 0.10886666666666667}, {"epoch": 198, "train_loss": 0.29352303497004323, "grad_norm": 0.4725096821784973, "test_error": 0.1042}, {"epoch": 199, "train_loss": 0.29372556518460624, "grad_norm": 0.4688924551010132, "test_error": 0.10451666666666666}, {"epoch": 200, "train_loss": 0.2940413859282465, "grad_norm": 0.609386146068573, "test_error": 0.10708333333333334}, {"epoch": 201, "train_loss": 0.29473968224584435, "grad_norm": 0.38074424862861633, "test_error": 0.10193333333333333}, {"epoch": 202, "train_loss": 0.2947883314413484, "grad_norm": 0.3301633894443512, "test_error": 0.09525}, {"epoch": 203, "train_loss": 0.29299775716809867, "grad_norm": 0.36179298162460327, "test_error": 0.09853333333333333}, {"epoch": 204, "train_loss": 0.293838571310315, "grad_norm": 0.45787540078163147, "test_error": 0.10083333333333333}, {"epoch": 205, "train_loss": 0.2930127092584541, "grad_norm": 0.6019662022590637, "test_error": 0.10658333333333334}, {"epoch": 206, "train_loss": 0.29305448598457345, "grad_norm": 0.5114860534667969, "test_error": 0.10006666666666666}, {"epoch": 207, "train_loss": 0.29404306792491114, "grad_norm": 0.42680808901786804, "test_error": 0.0993}, {"epoch": 208, "train_loss": 0.2928609160974932, "grad_norm": 0.3063480257987976, "test_error": 0.09588333333333333}, {"epoch": 209, "train_loss": 0.2932038679636316, "grad_norm": 1.020078182220459, "test_error": 0.12156666666666667}, {"epoch": 210, "train_loss": 0.2933962159924364, "grad_norm": 0.5525810122489929, "test_error": 0.10363333333333333}, {"epoch": 211, "train_loss": 0.2931427705802489, "grad_norm": 0.5938305258750916, "test_error": 0.10535}, {"epoch": 212, "train_loss": 0.29254384111977805, "grad_norm": 0.4874689280986786, "test_error": 0.10341666666666667}, {"epoch": 213, "train_loss": 0.292868991752679, "grad_norm": 0.4298567473888397, "test_error": 0.09678333333333333}, {"epoch": 214, "train_loss": 0.29251430788294724, "grad_norm": 0.47341954708099365, "test_error": 0.10155}, {"epoch": 215, "train_loss": 0.29279033705972446, "grad_norm": 0.31862127780914307, "test_error": 0.09733333333333333}, {"epoch": 216, "train_loss": 0.29365065491269343, "grad_norm": 0.7291868925094604, "test_error": 0.11165}, {"epoch": 217, "train_loss": 0.2934964961064203, "grad_norm": 0.32939308881759644, "test_error": 0.09933333333333333}, {"epoch": 218, "train_loss": 0.2938593601273218, "grad_norm": 0.39426979422569275, "test_error": 0.09986666666666667}, {"epoch": 219, "train_loss": 0.29408384231703044, "grad_norm": 0.275873064994812, "test_error": 0.09528333333333333}, {"epoch": 220, "train_loss": 0.29348157162487043, "grad_norm": 0.5069203972816467, "test_error": 0.10045}, {"epoch": 221, "train_loss": 0.2934636394631816, "grad_norm": 0.47926515340805054, "test_error": 0.09996666666666666}, {"epoch": 222, "train_loss": 0.2935826951827233, "grad_norm": 0.5143407583236694, "test_error": 0.10203333333333334}, {"epoch": 223, "train_loss": 0.2951881784681076, "grad_norm": 0.5853915810585022, "test_error": 0.10536666666666666}, {"epoch": 224, "train_loss": 0.294262808483482, "grad_norm": 0.6101753115653992, "test_error": 0.1054}, {"epoch": 225, "train_loss": 0.29315686181773587, "grad_norm": 0.2973414361476898, "test_error": 0.09571666666666667}, {"epoch": 226, "train_loss": 0.2920917766564526, "grad_norm": 0.43734243512153625, "test_error": 0.09788333333333334}, {"epoch": 227, "train_loss": 0.2925632559484802, "grad_norm": 0.31354910135269165, "test_error": 0.09581666666666666}, {"epoch": 228, "train_loss": 0.2933796664071269, "grad_norm": 0.39453041553497314, "test_error": 0.10208333333333333}, {"epoch": 229, "train_loss": 0.29253248157150424, "grad_norm": 0.4112526476383209, "test_error": 0.10496666666666667}, {"epoch": 230, "train_loss": 0.29427370412950404, "grad_norm": 0.18951304256916046, "test_error": 0.09623333333333334}, {"epoch": 231, "train_loss": 0.29297542401620497, "grad_norm": 0.2961982190608978, "test_error": 0.09663333333333333}, {"epoch": 232, "train_loss": 0.29306576907332055, "grad_norm": 1.1965144872665405, "test_error": 0.12428333333333333}, {"epoch": 233, "train_loss": 0.29402371948270595, "grad_norm": 0.44196617603302, "test_error": 0.09663333333333333}, {"epoch": 234, "train_loss": 0.2931524855963459, "grad_norm": 0.3776453733444214, "test_error": 0.09828333333333333}, {"epoch": 235, "train_loss": 0.2931007325409446, "grad_norm": 0.4543500244617462, "test_error": 0.10061666666666666}, {"epoch": 236, "train_loss": 0.29406082462158517, "grad_norm": 0.8262768387794495, "test_error": 0.1159}, {"epoch": 237, "train_loss": 0.29263094131974504, "grad_norm": 0.28034210205078125, "test_error": 0.09233333333333334}, {"epoch": 238, "train_loss": 0.29495114645792636, "grad_norm": 0.3959255814552307, "test_error": 0.10065}, {"epoch": 239, "train_loss": 0.29237398083275185, "grad_norm": 0.551888644695282, "test_error": 0.10313333333333333}, {"epoch": 240, "train_loss": 0.29278438256537387, "grad_norm": 0.563487708568573, "test_error": 0.10535}, {"epoch": 241, "train_loss": 0.2934436676556943, "grad_norm": 1.0787956714630127, "test_error": 0.12583333333333332}, {"epoch": 242, "train_loss": 0.29208650259044955, "grad_norm": 0.7074758410453796, "test_error": 0.10958333333333334}, {"epoch": 243, "train_loss": 0.29260794892976993, "grad_norm": 0.3280189633369446, "test_error": 0.0973}, {"epoch": 244, "train_loss": 0.29269554883575377, "grad_norm": 0.32521507143974304, "test_error": 0.09333333333333334}, {"epoch": 245, "train_loss": 0.29269777702361655, "grad_norm": 0.5380047559738159, "test_error": 0.1037}, {"epoch": 246, "train_loss": 0.2939212060254067, "grad_norm": 1.014739751815796, "test_error": 0.12056666666666667}, {"epoch": 247, "train_loss": 0.2929801914271278, "grad_norm": 0.40113621950149536, "test_error": 0.09801666666666667}, {"epoch": 248, "train_loss": 0.2942648446202123, "grad_norm": 0.47206106781959534, "test_error": 0.09505}, {"epoch": 249, "train_loss": 0.2927183545339697, "grad_norm": 0.41780024766921997, "test_error": 0.10168333333333333}, {"epoch": 250, "train_loss": 0.29433196715676846, "grad_norm": 0.5640800595283508, "test_error": 0.10503333333333334}, {"epoch": 251, "train_loss": 0.2936284745379817, "grad_norm": 0.44444262981414795, "test_error": 0.101}, {"epoch": 252, "train_loss": 0.29347821020676446, "grad_norm": 0.7194539904594421, "test_error": 0.10971666666666667}, {"epoch": 253, "train_loss": 0.2938112754029377, "grad_norm": 0.39648595452308655, "test_error": 0.09816666666666667}, {"epoch": 254, "train_loss": 0.29446512180853945, "grad_norm": 0.45620235800743103, "test_error": 0.10016666666666667}, {"epoch": 255, "train_loss": 0.29312361190553443, "grad_norm": 0.2772585451602936, "test_error": 0.0928}, {"epoch": 256, "train_loss": 0.29309432313684375, "grad_norm": 0.5147584676742554, "test_error": 0.10203333333333334}, {"epoch": 257, "train_loss": 0.2934159806238798, "grad_norm": 0.42187392711639404, "test_error": 0.1026}, {"epoch": 258, "train_loss": 0.29226693663652986, "grad_norm": 0.28435856103897095, "test_error": 0.09441666666666666}, {"epoch": 259, "train_loss": 0.292435759804522, "grad_norm": 0.2868692874908447, "test_error": 0.09653333333333333}, {"epoch": 260, "train_loss": 0.2913959120797614, "grad_norm": 0.5211206674575806, "test_error": 0.10365}, {"epoch": 261, "train_loss": 0.2932476416964006, "grad_norm": 0.6848463416099548, "test_error": 0.10565}, {"epoch": 262, "train_loss": 0.2935822757362621, "grad_norm": 0.4920930862426758, "test_error": 0.10528333333333334}, {"epoch": 263, "train_loss": 0.29264259528322145, "grad_norm": 0.3227249085903168, "test_error": 0.0978}, {"epoch": 264, "train_loss": 0.29328375806744833, "grad_norm": 0.32887235283851624, "test_error": 0.09913333333333334}, {"epoch": 265, "train_loss": 0.29295872497430536, "grad_norm": 0.6526954770088196, "test_error": 0.1106}, {"epoch": 266, "train_loss": 0.29307265652700637, "grad_norm": 0.4861079156398773, "test_error": 0.10165}, {"epoch": 267, "train_loss": 0.2942200761314016, "grad_norm": 0.4443871080875397, "test_error": 0.0999}, {"epoch": 268, "train_loss": 0.2915959516693838, "grad_norm": 0.3136880099773407, "test_error": 0.09351666666666666}, {"epoch": 269, "train_loss": 0.29314245080513257, "grad_norm": 0.5037366151809692, "test_error": 0.1048}, {"epoch": 270, "train_loss": 0.2924221881122018, "grad_norm": 0.5228775143623352, "test_error": 0.10206666666666667}, {"epoch": 271, "train_loss": 0.29325559636950493, "grad_norm": 0.36956721544265747, "test_error": 0.09728333333333333}, {"epoch": 272, "train_loss": 0.29249351540902474, "grad_norm": 0.2708413898944855, "test_error": 0.09611666666666667}, {"epoch": 273, "train_loss": 0.29388578183395053, "grad_norm": 0.41690266132354736, "test_error": 0.10051666666666667}, {"epoch": 274, "train_loss": 0.2924894164267462, "grad_norm": 0.6045204997062683, "test_error": 0.1029}, {"epoch": 275, "train_loss": 0.29315608998694614, "grad_norm": 0.655925989151001, "test_error": 0.10513333333333333}, {"epoch": 276, "train_loss": 0.29426918215754755, "grad_norm": 0.30578354001045227, "test_error": 0.09511666666666667}, {"epoch": 277, "train_loss": 0.2928722973307595, "grad_norm": 0.4574679434299469, "test_error": 0.09845}, {"epoch": 278, "train_loss": 0.2939635966224596, "grad_norm": 0.5056399703025818, "test_error": 0.09858333333333333}, {"epoch": 279, "train_loss": 0.29163766532903534, "grad_norm": 0.37168142199516296, "test_error": 0.09568333333333333}, {"epoch": 280, "train_loss": 0.2930312250068334, "grad_norm": 0.27824991941452026, "test_error": 0.0975}, {"epoch": 281, "train_loss": 0.29364142021583395, "grad_norm": 0.5041945576667786, "test_error": 0.10348333333333333}, {"epoch": 282, "train_loss": 0.2923484975647492, "grad_norm": 1.0369268655776978, "test_error": 0.11525}, {"epoch": 283, "train_loss": 0.2915716745118067, "grad_norm": 0.5239648222923279, "test_error": 0.10218333333333333}, {"epoch": 284, "train_loss": 0.2934873788106876, "grad_norm": 0.29489508271217346, "test_error": 0.09705}, {"epoch": 285, "train_loss": 0.292935585453175, "grad_norm": 0.6292410492897034, "test_error": 0.10548333333333333}, {"epoch": 286, "train_loss": 0.294146495709739, "grad_norm": 0.38462355732917786, "test_error": 0.10033333333333333}, {"epoch": 287, "train_loss": 0.293636206417655, "grad_norm": 0.33883434534072876, "test_error": 0.09596666666666667}, {"epoch": 288, "train_loss": 0.29286802690274394, "grad_norm": 0.4821491539478302, "test_error": 0.10668333333333334}, {"epoch": 289, "train_loss": 0.2939578224698004, "grad_norm": 0.5275736451148987, "test_error": 0.09966666666666667}, {"epoch": 290, "train_loss": 0.29351582534999276, "grad_norm": 0.7742668390274048, "test_error": 0.11738333333333334}, {"epoch": 291, "train_loss": 0.2935991956355477, "grad_norm": 0.45284077525138855, "test_error": 0.1009}, {"epoch": 292, "train_loss": 0.2935204707213755, "grad_norm": 0.40029793977737427, "test_error": 0.097}, {"epoch": 293, "train_loss": 0.2924866652889177, "grad_norm": 0.4156795144081116, "test_error": 0.09868333333333333}, {"epoch": 294, "train_loss": 0.2921606631468361, "grad_norm": 0.2780728042125702, "test_error": 0.0963}, {"epoch": 295, "train_loss": 0.2928776073739088, "grad_norm": 0.5684559941291809, "test_error": 0.10215}, {"epoch": 296, "train_loss": 0.29290608247334604, "grad_norm": 0.7179414629936218, "test_error": 0.11156666666666666}, {"epoch": 297, "train_loss": 0.29401304763229563, "grad_norm": 0.2138516753911972, "test_error": 0.0909}, {"epoch": 298, "train_loss": 0.29161220729129855, "grad_norm": 0.4675169289112091, "test_error": 0.10426666666666666}, {"epoch": 299, "train_loss": 0.29246816656660907, "grad_norm": 0.46430155634880066, "test_error": 0.10575}, {"epoch": 300, "train_loss": 0.2920541606542344, "grad_norm": 0.9538647532463074, "test_error": 0.12068333333333334}]}