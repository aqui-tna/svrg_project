{"argv": ["train.py", "--dataset", "MNIST", "--optimizer", "SGD", "--output_path", "mnist_sgd_fixed001.json"], "args": {"seed": null, "optimizer": "SGD", "run_name": "SGD", "output_path": "mnist_sgd_fixed001.json", "device": "cpu", "dataset": "MNIST", "dataset_root": "~/datasets/pytorch", "dataset_size": null, "download": false, "layer_sizes": [784, 100, 10], "batch_size": 10, "test_batch_size": 10, "learning_rate": 0.001, "weight_decay": 0.001, "warmup_learning_rate": 0.01, "num_warmup_epochs": 10, "num_outer_epochs": 242, "num_inner_epochs": 1, "inner_epoch_fraction": null, "choose_random_iterate": false, "num_epochs": 280}, "metrics": [{"epoch": 1, "train_loss": 1.5348026190499464, "grad_norm": 0.35054829716682434, "test_error": 0.1698}, {"epoch": 2, "train_loss": 0.6477135935661693, "grad_norm": 0.17534080147743225, "test_error": 0.1248}, {"epoch": 3, "train_loss": 0.47571095068069796, "grad_norm": 0.1393355280160904, "test_error": 0.1088}, {"epoch": 4, "train_loss": 0.4120755565954993, "grad_norm": 0.09317323565483093, "test_error": 0.1016}, {"epoch": 5, "train_loss": 0.37792483409897737, "grad_norm": 0.08853480964899063, "test_error": 0.0972}, {"epoch": 6, "train_loss": 0.3555745913220259, "grad_norm": 0.11245544999837875, "test_error": 0.0924}, {"epoch": 7, "train_loss": 0.3390484434324317, "grad_norm": 0.07581380754709244, "test_error": 0.088}, {"epoch": 8, "train_loss": 0.32608737209097793, "grad_norm": 0.08523774892091751, "test_error": 0.0849}, {"epoch": 9, "train_loss": 0.31494305084909624, "grad_norm": 0.08054712414741516, "test_error": 0.0813}, {"epoch": 10, "train_loss": 0.30542128745342295, "grad_norm": 0.1009984016418457, "test_error": 0.0791}, {"epoch": 11, "train_loss": 0.29681998113108177, "grad_norm": 0.05576552823185921, "test_error": 0.0777}, {"epoch": 12, "train_loss": 0.2889038038336051, "grad_norm": 0.0667790025472641, "test_error": 0.076}, {"epoch": 13, "train_loss": 0.2816004406423308, "grad_norm": 0.10436556488275528, "test_error": 0.0758}, {"epoch": 14, "train_loss": 0.2749131390189286, "grad_norm": 0.061329253017902374, "test_error": 0.0734}, {"epoch": 15, "train_loss": 0.26844501425838097, "grad_norm": 0.07635155320167542, "test_error": 0.0719}, {"epoch": 16, "train_loss": 0.2625611190509517, "grad_norm": 0.0640513002872467, "test_error": 0.0706}, {"epoch": 17, "train_loss": 0.25681957928370686, "grad_norm": 0.05841994285583496, "test_error": 0.0691}, {"epoch": 18, "train_loss": 0.25149679922607415, "grad_norm": 0.04501877725124359, "test_error": 0.0686}, {"epoch": 19, "train_loss": 0.24633088982935683, "grad_norm": 0.05795101821422577, "test_error": 0.0663}, {"epoch": 20, "train_loss": 0.24157811921912556, "grad_norm": 0.05742751806974411, "test_error": 0.0654}, {"epoch": 21, "train_loss": 0.23694647664669902, "grad_norm": 0.0602748729288578, "test_error": 0.0636}, {"epoch": 22, "train_loss": 0.2323356994825881, "grad_norm": 0.08149067312479019, "test_error": 0.0645}, {"epoch": 23, "train_loss": 0.22802049231839677, "grad_norm": 0.06689333915710449, "test_error": 0.0616}, {"epoch": 24, "train_loss": 0.2239543737498267, "grad_norm": 0.07384803891181946, "test_error": 0.0622}, {"epoch": 25, "train_loss": 0.22005921282145816, "grad_norm": 0.0513874813914299, "test_error": 0.0606}, {"epoch": 26, "train_loss": 0.21630536095239222, "grad_norm": 0.04613588750362396, "test_error": 0.0595}, {"epoch": 27, "train_loss": 0.21263907590919795, "grad_norm": 0.055716194212436676, "test_error": 0.0584}, {"epoch": 28, "train_loss": 0.20923845529785223, "grad_norm": 0.05600342899560928, "test_error": 0.0573}, {"epoch": 29, "train_loss": 0.20581928995337026, "grad_norm": 0.05236029624938965, "test_error": 0.0579}, {"epoch": 30, "train_loss": 0.20263788495127422, "grad_norm": 0.043038733303546906, "test_error": 0.0558}, {"epoch": 31, "train_loss": 0.19951328608153077, "grad_norm": 0.0553722083568573, "test_error": 0.056}, {"epoch": 32, "train_loss": 0.19640574088265808, "grad_norm": 0.04261923208832741, "test_error": 0.0557}, {"epoch": 33, "train_loss": 0.1933974924320355, "grad_norm": 0.067814402282238, "test_error": 0.0537}, {"epoch": 34, "train_loss": 0.19054112082960395, "grad_norm": 0.03589940071105957, "test_error": 0.0541}, {"epoch": 35, "train_loss": 0.18785198033895964, "grad_norm": 0.047700271010398865, "test_error": 0.0537}, {"epoch": 36, "train_loss": 0.18518620736904753, "grad_norm": 0.04401087388396263, "test_error": 0.0528}, {"epoch": 37, "train_loss": 0.18257956554185753, "grad_norm": 0.038745395839214325, "test_error": 0.0524}, {"epoch": 38, "train_loss": 0.18012575754779392, "grad_norm": 0.04430995136499405, "test_error": 0.0517}, {"epoch": 39, "train_loss": 0.1777115213635843, "grad_norm": 0.04424165189266205, "test_error": 0.0506}, {"epoch": 40, "train_loss": 0.17536557854541268, "grad_norm": 0.06929280608892441, "test_error": 0.0508}, {"epoch": 41, "train_loss": 0.1731061382140033, "grad_norm": 0.04971115291118622, "test_error": 0.0495}, {"epoch": 42, "train_loss": 0.17086191056932634, "grad_norm": 0.04126464203000069, "test_error": 0.0492}, {"epoch": 43, "train_loss": 0.1688079791436515, "grad_norm": 0.044288720935583115, "test_error": 0.0495}, {"epoch": 44, "train_loss": 0.16663466867827811, "grad_norm": 0.039157215505838394, "test_error": 0.0482}, {"epoch": 45, "train_loss": 0.1646947791420389, "grad_norm": 0.04128717631101608, "test_error": 0.048}, {"epoch": 46, "train_loss": 0.16266229493004114, "grad_norm": 0.04640178754925728, "test_error": 0.0477}, {"epoch": 47, "train_loss": 0.16087725043576212, "grad_norm": 0.046202708035707474, "test_error": 0.0468}, {"epoch": 48, "train_loss": 0.1590380138452553, "grad_norm": 0.0625360831618309, "test_error": 0.0468}, {"epoch": 49, "train_loss": 0.1572256407168073, "grad_norm": 0.03522946313023567, "test_error": 0.0465}, {"epoch": 50, "train_loss": 0.15553162877152985, "grad_norm": 0.04045752063393593, "test_error": 0.0459}, {"epoch": 51, "train_loss": 0.15378135790737968, "grad_norm": 0.049174964427948, "test_error": 0.0454}, {"epoch": 52, "train_loss": 0.15213402426572672, "grad_norm": 0.041745856404304504, "test_error": 0.0453}, {"epoch": 53, "train_loss": 0.15059190093213692, "grad_norm": 0.030381595715880394, "test_error": 0.0444}, {"epoch": 54, "train_loss": 0.14902450021946181, "grad_norm": 0.04561731964349747, "test_error": 0.0449}, {"epoch": 55, "train_loss": 0.14749335935219035, "grad_norm": 0.03730692341923714, "test_error": 0.0434}, {"epoch": 56, "train_loss": 0.1461104660256921, "grad_norm": 0.02804250828921795, "test_error": 0.0434}, {"epoch": 57, "train_loss": 0.14469350421638227, "grad_norm": 0.048209793865680695, "test_error": 0.0436}, {"epoch": 58, "train_loss": 0.14327418996366517, "grad_norm": 0.04020871967077255, "test_error": 0.0428}, {"epoch": 59, "train_loss": 0.14189523506797075, "grad_norm": 0.044641267508268356, "test_error": 0.0424}, {"epoch": 60, "train_loss": 0.1405917939071854, "grad_norm": 0.04557164013385773, "test_error": 0.0423}, {"epoch": 61, "train_loss": 0.1392625405336342, "grad_norm": 0.0551799051463604, "test_error": 0.0415}, {"epoch": 62, "train_loss": 0.13802604188459616, "grad_norm": 0.04163379594683647, "test_error": 0.0413}, {"epoch": 63, "train_loss": 0.13679788148667044, "grad_norm": 0.035750288516283035, "test_error": 0.0409}, {"epoch": 64, "train_loss": 0.13561399934235185, "grad_norm": 0.044128887355327606, "test_error": 0.041}, {"epoch": 65, "train_loss": 0.134426029721663, "grad_norm": 0.04999497905373573, "test_error": 0.0403}, {"epoch": 66, "train_loss": 0.13341045630009224, "grad_norm": 0.02866668440401554, "test_error": 0.0398}, {"epoch": 67, "train_loss": 0.1322063000528142, "grad_norm": 0.049546029418706894, "test_error": 0.0393}, {"epoch": 68, "train_loss": 0.1311538130734504, "grad_norm": 0.037071481347084045, "test_error": 0.0391}, {"epoch": 69, "train_loss": 0.13015966991257544, "grad_norm": 0.029151715338230133, "test_error": 0.0388}, {"epoch": 70, "train_loss": 0.12904907554997286, "grad_norm": 0.04082442820072174, "test_error": 0.0382}, {"epoch": 71, "train_loss": 0.12805990326594716, "grad_norm": 0.044117316603660583, "test_error": 0.0382}, {"epoch": 72, "train_loss": 0.12714905919169542, "grad_norm": 0.034548334777355194, "test_error": 0.0388}, {"epoch": 73, "train_loss": 0.1260754436676701, "grad_norm": 0.04510531574487686, "test_error": 0.0372}, {"epoch": 74, "train_loss": 0.125235512948789, "grad_norm": 0.047039031982421875, "test_error": 0.037}, {"epoch": 75, "train_loss": 0.12436924306846535, "grad_norm": 0.03310585394501686, "test_error": 0.0371}, {"epoch": 76, "train_loss": 0.12342046490482365, "grad_norm": 0.046086620539426804, "test_error": 0.0365}, {"epoch": 77, "train_loss": 0.1225395144186914, "grad_norm": 0.03791177645325661, "test_error": 0.0372}, {"epoch": 78, "train_loss": 0.12168929230456706, "grad_norm": 0.026592442765831947, "test_error": 0.036}, {"epoch": 79, "train_loss": 0.12082400176352046, "grad_norm": 0.05412352830171585, "test_error": 0.0369}, {"epoch": 80, "train_loss": 0.12005909030818536, "grad_norm": 0.04019860550761223, "test_error": 0.036}, {"epoch": 81, "train_loss": 0.11920891305346352, "grad_norm": 0.03922605514526367, "test_error": 0.036}, {"epoch": 82, "train_loss": 0.11843770715908614, "grad_norm": 0.04465676471590996, "test_error": 0.0352}, {"epoch": 83, "train_loss": 0.11772526663724178, "grad_norm": 0.02982310950756073, "test_error": 0.0357}, {"epoch": 84, "train_loss": 0.11692964930739254, "grad_norm": 0.03320576995611191, "test_error": 0.0361}, {"epoch": 85, "train_loss": 0.11612421180507712, "grad_norm": 0.029911570250988007, "test_error": 0.0351}, {"epoch": 86, "train_loss": 0.1154170665316439, "grad_norm": 0.04045048728585243, "test_error": 0.0349}, {"epoch": 87, "train_loss": 0.11475884041651928, "grad_norm": 0.033926382660865784, "test_error": 0.035}, {"epoch": 88, "train_loss": 0.11403942349925637, "grad_norm": 0.03284778818488121, "test_error": 0.0345}, {"epoch": 89, "train_loss": 0.1133570768077237, "grad_norm": 0.034576285630464554, "test_error": 0.0351}, {"epoch": 90, "train_loss": 0.1126359561671658, "grad_norm": 0.04889630898833275, "test_error": 0.0352}, {"epoch": 91, "train_loss": 0.11199449355224109, "grad_norm": 0.0466499999165535, "test_error": 0.0343}, {"epoch": 92, "train_loss": 0.11132351867986533, "grad_norm": 0.03601489216089249, "test_error": 0.0342}, {"epoch": 93, "train_loss": 0.11075043215579353, "grad_norm": 0.025329524651169777, "test_error": 0.0335}, {"epoch": 94, "train_loss": 0.11016251673467924, "grad_norm": 0.020134763792157173, "test_error": 0.0336}, {"epoch": 95, "train_loss": 0.10943560300041766, "grad_norm": 0.04390271380543709, "test_error": 0.0338}, {"epoch": 96, "train_loss": 0.10889618534121352, "grad_norm": 0.03630903363227844, "test_error": 0.0335}, {"epoch": 97, "train_loss": 0.10834457935090176, "grad_norm": 0.026114070788025856, "test_error": 0.0329}, {"epoch": 98, "train_loss": 0.10771990019017054, "grad_norm": 0.03080063685774803, "test_error": 0.0332}, {"epoch": 99, "train_loss": 0.10716531190881505, "grad_norm": 0.029785625636577606, "test_error": 0.033}, {"epoch": 100, "train_loss": 0.10661413621770528, "grad_norm": 0.025460777804255486, "test_error": 0.0321}, {"epoch": 101, "train_loss": 0.10607335954590234, "grad_norm": 0.03824814036488533, "test_error": 0.0326}, {"epoch": 102, "train_loss": 0.10551351898345941, "grad_norm": 0.024647105485200882, "test_error": 0.0317}, {"epoch": 103, "train_loss": 0.10502075850367934, "grad_norm": 0.029727809131145477, "test_error": 0.0317}, {"epoch": 104, "train_loss": 0.10453175886644749, "grad_norm": 0.026941675692796707, "test_error": 0.0321}, {"epoch": 105, "train_loss": 0.10396146373652543, "grad_norm": 0.05733688175678253, "test_error": 0.032}, {"epoch": 106, "train_loss": 0.10346282931650057, "grad_norm": 0.03676867485046387, "test_error": 0.0322}, {"epoch": 107, "train_loss": 0.10302545984624885, "grad_norm": 0.03230014443397522, "test_error": 0.0314}, {"epoch": 108, "train_loss": 0.1025131407599547, "grad_norm": 0.027155227959156036, "test_error": 0.0316}, {"epoch": 109, "train_loss": 0.10207420313591138, "grad_norm": 0.02392062358558178, "test_error": 0.0316}, {"epoch": 110, "train_loss": 0.1016046174285002, "grad_norm": 0.032801225781440735, "test_error": 0.0314}, {"epoch": 111, "train_loss": 0.10113949225637285, "grad_norm": 0.033193349838256836, "test_error": 0.031}, {"epoch": 112, "train_loss": 0.1006919254597742, "grad_norm": 0.03304083272814751, "test_error": 0.0309}, {"epoch": 113, "train_loss": 0.10031007688461492, "grad_norm": 0.03041898086667061, "test_error": 0.0303}, {"epoch": 114, "train_loss": 0.09987382760543066, "grad_norm": 0.03945745900273323, "test_error": 0.0313}, {"epoch": 115, "train_loss": 0.09941902011857989, "grad_norm": 0.029972486197948456, "test_error": 0.03}, {"epoch": 116, "train_loss": 0.09903623423259705, "grad_norm": 0.030455656349658966, "test_error": 0.0302}, {"epoch": 117, "train_loss": 0.09860955673677381, "grad_norm": 0.03292698785662651, "test_error": 0.0297}, {"epoch": 118, "train_loss": 0.0982341675949283, "grad_norm": 0.03512344881892204, "test_error": 0.0305}, {"epoch": 119, "train_loss": 0.09779599065818669, "grad_norm": 0.029072778299450874, "test_error": 0.0299}, {"epoch": 120, "train_loss": 0.09741372079704888, "grad_norm": 0.023996498435735703, "test_error": 0.0303}, {"epoch": 121, "train_loss": 0.09698940824585346, "grad_norm": 0.0564664788544178, "test_error": 0.0301}, {"epoch": 122, "train_loss": 0.09668875264651919, "grad_norm": 0.03312736004590988, "test_error": 0.0298}, {"epoch": 123, "train_loss": 0.09625619163668792, "grad_norm": 0.030226506292819977, "test_error": 0.0298}, {"epoch": 124, "train_loss": 0.09587305395002477, "grad_norm": 0.02828953228890896, "test_error": 0.0296}, {"epoch": 125, "train_loss": 0.09555822691115706, "grad_norm": 0.022251788526773453, "test_error": 0.03}, {"epoch": 126, "train_loss": 0.09518706939652717, "grad_norm": 0.04810836538672447, "test_error": 0.0299}, {"epoch": 127, "train_loss": 0.09486879944164926, "grad_norm": 0.025236396118998528, "test_error": 0.0291}, {"epoch": 128, "train_loss": 0.09453443659985593, "grad_norm": 0.02552194707095623, "test_error": 0.0292}, {"epoch": 129, "train_loss": 0.0941476403461808, "grad_norm": 0.04397759586572647, "test_error": 0.0286}, {"epoch": 130, "train_loss": 0.09382705815668063, "grad_norm": 0.04016318917274475, "test_error": 0.0288}, {"epoch": 131, "train_loss": 0.09351314913671618, "grad_norm": 0.031032975763082504, "test_error": 0.029}, {"epoch": 132, "train_loss": 0.09320894641099342, "grad_norm": 0.027473896741867065, "test_error": 0.0289}, {"epoch": 133, "train_loss": 0.09284944453841308, "grad_norm": 0.02781027927994728, "test_error": 0.029}, {"epoch": 134, "train_loss": 0.09258207679982297, "grad_norm": 0.02481059916317463, "test_error": 0.0287}, {"epoch": 135, "train_loss": 0.09224933964933735, "grad_norm": 0.03313635662198067, "test_error": 0.0294}, {"epoch": 136, "train_loss": 0.09194687777990475, "grad_norm": 0.03266891464591026, "test_error": 0.0288}, {"epoch": 137, "train_loss": 0.0916852977584737, "grad_norm": 0.019260015338659286, "test_error": 0.0286}, {"epoch": 138, "train_loss": 0.09135286524532905, "grad_norm": 0.03456265479326248, "test_error": 0.0282}, {"epoch": 139, "train_loss": 0.09107017914479365, "grad_norm": 0.03560822457075119, "test_error": 0.0282}, {"epoch": 140, "train_loss": 0.09079315750589982, "grad_norm": 0.03707558289170265, "test_error": 0.0281}, {"epoch": 141, "train_loss": 0.09052064699619465, "grad_norm": 0.0283515565097332, "test_error": 0.028}, {"epoch": 142, "train_loss": 0.09026259298459627, "grad_norm": 0.020251158624887466, "test_error": 0.028}, {"epoch": 143, "train_loss": 0.08992855865733387, "grad_norm": 0.024717917665839195, "test_error": 0.0275}, {"epoch": 144, "train_loss": 0.08967371531906732, "grad_norm": 0.027905063703656197, "test_error": 0.0281}, {"epoch": 145, "train_loss": 0.08936854842464284, "grad_norm": 0.03147602453827858, "test_error": 0.028}, {"epoch": 146, "train_loss": 0.08915670095316212, "grad_norm": 0.02254171296954155, "test_error": 0.0275}, {"epoch": 147, "train_loss": 0.08890707423697071, "grad_norm": 0.029075630009174347, "test_error": 0.0275}, {"epoch": 148, "train_loss": 0.08860107162920758, "grad_norm": 0.040163006633520126, "test_error": 0.028}, {"epoch": 149, "train_loss": 0.08841431061838133, "grad_norm": 0.03112618252635002, "test_error": 0.0273}, {"epoch": 150, "train_loss": 0.08814060083398363, "grad_norm": 0.019049763679504395, "test_error": 0.0272}, {"epoch": 151, "train_loss": 0.08791875585541128, "grad_norm": 0.022651396691799164, "test_error": 0.0275}, {"epoch": 152, "train_loss": 0.08763013013254385, "grad_norm": 0.029486360028386116, "test_error": 0.027}, {"epoch": 153, "train_loss": 0.08743050713418052, "grad_norm": 0.021317942067980766, "test_error": 0.0269}, {"epoch": 154, "train_loss": 0.08715040318120737, "grad_norm": 0.026794280856847763, "test_error": 0.0274}, {"epoch": 155, "train_loss": 0.08693404594717626, "grad_norm": 0.028260251507163048, "test_error": 0.0274}, {"epoch": 156, "train_loss": 0.08674967867754943, "grad_norm": 0.0317513532936573, "test_error": 0.0271}, {"epoch": 157, "train_loss": 0.086473041234829, "grad_norm": 0.027160407975316048, "test_error": 0.0273}, {"epoch": 158, "train_loss": 0.08625563213048736, "grad_norm": 0.030309760943055153, "test_error": 0.0271}, {"epoch": 159, "train_loss": 0.0859603267259857, "grad_norm": 0.021946121007204056, "test_error": 0.0272}, {"epoch": 160, "train_loss": 0.08585561678616796, "grad_norm": 0.027657238766551018, "test_error": 0.0271}, {"epoch": 161, "train_loss": 0.08559707915969193, "grad_norm": 0.03761869668960571, "test_error": 0.0272}, {"epoch": 162, "train_loss": 0.08540000844744888, "grad_norm": 0.028844423592090607, "test_error": 0.0269}, {"epoch": 163, "train_loss": 0.08514518869866151, "grad_norm": 0.04736674204468727, "test_error": 0.0266}, {"epoch": 164, "train_loss": 0.08497957957920153, "grad_norm": 0.029552986845374107, "test_error": 0.0272}, {"epoch": 165, "train_loss": 0.08476601749714852, "grad_norm": 0.03399479761719704, "test_error": 0.0272}, {"epoch": 166, "train_loss": 0.0845549179360775, "grad_norm": 0.024526724591851234, "test_error": 0.027}, {"epoch": 167, "train_loss": 0.08434524639302012, "grad_norm": 0.04169799014925957, "test_error": 0.0265}, {"epoch": 168, "train_loss": 0.08415210447704885, "grad_norm": 0.03276952728629112, "test_error": 0.0271}, {"epoch": 169, "train_loss": 0.08397334275402439, "grad_norm": 0.02005755342543125, "test_error": 0.0267}, {"epoch": 170, "train_loss": 0.08378610784857302, "grad_norm": 0.019814152270555496, "test_error": 0.0268}, {"epoch": 171, "train_loss": 0.08352658121594383, "grad_norm": 0.02715909853577614, "test_error": 0.0271}, {"epoch": 172, "train_loss": 0.08335904606602465, "grad_norm": 0.026396969333291054, "test_error": 0.0274}, {"epoch": 173, "train_loss": 0.08315276997018373, "grad_norm": 0.03249064460396767, "test_error": 0.027}, {"epoch": 174, "train_loss": 0.08306974892308547, "grad_norm": 0.023269902914762497, "test_error": 0.0267}, {"epoch": 175, "train_loss": 0.08287637112526379, "grad_norm": 0.02402534708380699, "test_error": 0.0263}, {"epoch": 176, "train_loss": 0.08264766081711665, "grad_norm": 0.051069844514131546, "test_error": 0.027}, {"epoch": 177, "train_loss": 0.08248931217121815, "grad_norm": 0.03142056614160538, "test_error": 0.0267}, {"epoch": 178, "train_loss": 0.0823673496414752, "grad_norm": 0.02244127169251442, "test_error": 0.0264}, {"epoch": 179, "train_loss": 0.08217129280381293, "grad_norm": 0.02253938652575016, "test_error": 0.0266}, {"epoch": 180, "train_loss": 0.08196663015558928, "grad_norm": 0.028534341603517532, "test_error": 0.0267}, {"epoch": 181, "train_loss": 0.0818306449544034, "grad_norm": 0.03001786582171917, "test_error": 0.0267}, {"epoch": 182, "train_loss": 0.0816482808937241, "grad_norm": 0.02519107796251774, "test_error": 0.0267}, {"epoch": 183, "train_loss": 0.08151454201204858, "grad_norm": 0.02562716044485569, "test_error": 0.0263}, {"epoch": 184, "train_loss": 0.08129877655010205, "grad_norm": 0.01712307333946228, "test_error": 0.0266}, {"epoch": 185, "train_loss": 0.08114693292410811, "grad_norm": 0.026769718155264854, "test_error": 0.0268}, {"epoch": 186, "train_loss": 0.08099298261810327, "grad_norm": 0.0262170247733593, "test_error": 0.0266}, {"epoch": 187, "train_loss": 0.08084808707085904, "grad_norm": 0.031088372692465782, "test_error": 0.0258}, {"epoch": 188, "train_loss": 0.08069010940333829, "grad_norm": 0.03256022930145264, "test_error": 0.026}, {"epoch": 189, "train_loss": 0.0805118468227253, "grad_norm": 0.037082307040691376, "test_error": 0.0265}, {"epoch": 190, "train_loss": 0.08033947250058797, "grad_norm": 0.029860178008675575, "test_error": 0.0263}, {"epoch": 191, "train_loss": 0.08024720251901696, "grad_norm": 0.031518153846263885, "test_error": 0.0256}, {"epoch": 192, "train_loss": 0.08005703462670014, "grad_norm": 0.03075464256107807, "test_error": 0.0266}, {"epoch": 193, "train_loss": 0.07994378338641642, "grad_norm": 0.03215358406305313, "test_error": 0.0259}, {"epoch": 194, "train_loss": 0.07979758694428407, "grad_norm": 0.027575556188821793, "test_error": 0.026}, {"epoch": 195, "train_loss": 0.07962511921619686, "grad_norm": 0.04001673310995102, "test_error": 0.0255}, {"epoch": 196, "train_loss": 0.079518399344796, "grad_norm": 0.03066018410027027, "test_error": 0.026}, {"epoch": 197, "train_loss": 0.07935312076089515, "grad_norm": 0.02534499578177929, "test_error": 0.0256}, {"epoch": 198, "train_loss": 0.07921511218431018, "grad_norm": 0.024422893300652504, "test_error": 0.0258}, {"epoch": 199, "train_loss": 0.07906804877203345, "grad_norm": 0.025504743680357933, "test_error": 0.0258}, {"epoch": 200, "train_loss": 0.07900115533762922, "grad_norm": 0.02513999678194523, "test_error": 0.0264}, {"epoch": 201, "train_loss": 0.07876468447473599, "grad_norm": 0.032419852912425995, "test_error": 0.026}, {"epoch": 202, "train_loss": 0.0787149748398806, "grad_norm": 0.024835001677274704, "test_error": 0.0263}, {"epoch": 203, "train_loss": 0.07858138601387812, "grad_norm": 0.019879784435033798, "test_error": 0.026}, {"epoch": 204, "train_loss": 0.07845840891619446, "grad_norm": 0.0293356291949749, "test_error": 0.0262}, {"epoch": 205, "train_loss": 0.07832533382050072, "grad_norm": 0.028786467388272285, "test_error": 0.0257}, {"epoch": 206, "train_loss": 0.07820575713261496, "grad_norm": 0.02885407768189907, "test_error": 0.0261}, {"epoch": 207, "train_loss": 0.07802749748524124, "grad_norm": 0.03652234748005867, "test_error": 0.0254}, {"epoch": 208, "train_loss": 0.07786810923427886, "grad_norm": 0.047277357429265976, "test_error": 0.0254}, {"epoch": 209, "train_loss": 0.07780297976215177, "grad_norm": 0.03315112739801407, "test_error": 0.0262}, {"epoch": 210, "train_loss": 0.07769608242124862, "grad_norm": 0.018659841269254684, "test_error": 0.0257}, {"epoch": 211, "train_loss": 0.07757163402405179, "grad_norm": 0.027287142351269722, "test_error": 0.0255}, {"epoch": 212, "train_loss": 0.07746365025274767, "grad_norm": 0.020853886380791664, "test_error": 0.0252}, {"epoch": 213, "train_loss": 0.07733537634293317, "grad_norm": 0.022145774215459824, "test_error": 0.0257}, {"epoch": 214, "train_loss": 0.07720548390694118, "grad_norm": 0.022706888616085052, "test_error": 0.0261}, {"epoch": 215, "train_loss": 0.07710198006311354, "grad_norm": 0.027896089479327202, "test_error": 0.0252}, {"epoch": 216, "train_loss": 0.07698395836533746, "grad_norm": 0.02484130673110485, "test_error": 0.0256}, {"epoch": 217, "train_loss": 0.0768701338346582, "grad_norm": 0.027656329795718193, "test_error": 0.0258}, {"epoch": 218, "train_loss": 0.07675160229807565, "grad_norm": 0.04158979654312134, "test_error": 0.0251}, {"epoch": 219, "train_loss": 0.07667292915628059, "grad_norm": 0.027280692011117935, "test_error": 0.0259}, {"epoch": 220, "train_loss": 0.07655233793344815, "grad_norm": 0.02939727157354355, "test_error": 0.0254}, {"epoch": 221, "train_loss": 0.07642416798356377, "grad_norm": 0.028344959020614624, "test_error": 0.0248}, {"epoch": 222, "train_loss": 0.07628618124666779, "grad_norm": 0.03834331035614014, "test_error": 0.025}, {"epoch": 223, "train_loss": 0.07625694608969691, "grad_norm": 0.03077421896159649, "test_error": 0.0251}, {"epoch": 224, "train_loss": 0.07611076725456709, "grad_norm": 0.02301603928208351, "test_error": 0.0256}, {"epoch": 225, "train_loss": 0.07604255901327511, "grad_norm": 0.02282821387052536, "test_error": 0.0252}, {"epoch": 226, "train_loss": 0.07594191120925825, "grad_norm": 0.020621895790100098, "test_error": 0.0255}, {"epoch": 227, "train_loss": 0.07577583437230594, "grad_norm": 0.051586590707302094, "test_error": 0.0254}, {"epoch": 228, "train_loss": 0.0757348416938136, "grad_norm": 0.02033805660903454, "test_error": 0.0257}, {"epoch": 229, "train_loss": 0.07565621835134032, "grad_norm": 0.02083270624279976, "test_error": 0.0253}, {"epoch": 230, "train_loss": 0.0755309998424491, "grad_norm": 0.02926584891974926, "test_error": 0.0254}, {"epoch": 231, "train_loss": 0.07544853873116275, "grad_norm": 0.022624250501394272, "test_error": 0.0256}, {"epoch": 232, "train_loss": 0.07532386721175863, "grad_norm": 0.032001934945583344, "test_error": 0.0254}, {"epoch": 233, "train_loss": 0.07522559451163398, "grad_norm": 0.024454578757286072, "test_error": 0.0255}, {"epoch": 234, "train_loss": 0.07514034421340329, "grad_norm": 0.027886303141713142, "test_error": 0.0247}, {"epoch": 235, "train_loss": 0.07509935127592568, "grad_norm": 0.018190525472164154, "test_error": 0.0251}, {"epoch": 236, "train_loss": 0.07495343998914662, "grad_norm": 0.02901483327150345, "test_error": 0.0251}, {"epoch": 237, "train_loss": 0.07489506477800509, "grad_norm": 0.02101374976336956, "test_error": 0.0251}, {"epoch": 238, "train_loss": 0.07475848680932541, "grad_norm": 0.042084041982889175, "test_error": 0.0243}, {"epoch": 239, "train_loss": 0.0747220568767419, "grad_norm": 0.02275799587368965, "test_error": 0.0247}, {"epoch": 240, "train_loss": 0.07459296211984474, "grad_norm": 0.03464879095554352, "test_error": 0.0247}, {"epoch": 241, "train_loss": 0.07452204255821804, "grad_norm": 0.031097617000341415, "test_error": 0.0252}, {"epoch": 242, "train_loss": 0.07443898861196552, "grad_norm": 0.024602998048067093, "test_error": 0.0252}, {"epoch": 243, "train_loss": 0.07435051134647802, "grad_norm": 0.03311653807759285, "test_error": 0.0249}, {"epoch": 244, "train_loss": 0.07426445685166012, "grad_norm": 0.022415393963456154, "test_error": 0.0248}, {"epoch": 245, "train_loss": 0.07417734108822575, "grad_norm": 0.03589165583252907, "test_error": 0.0246}, {"epoch": 246, "train_loss": 0.07410230873342759, "grad_norm": 0.03174900636076927, "test_error": 0.0247}, {"epoch": 247, "train_loss": 0.07404048458222921, "grad_norm": 0.03389081731438637, "test_error": 0.0247}, {"epoch": 248, "train_loss": 0.07391605303649945, "grad_norm": 0.022731445729732513, "test_error": 0.0253}, {"epoch": 249, "train_loss": 0.07378314648227145, "grad_norm": 0.04320506006479263, "test_error": 0.0247}, {"epoch": 250, "train_loss": 0.07378784030701112, "grad_norm": 0.037606123834848404, "test_error": 0.025}, {"epoch": 251, "train_loss": 0.0736896833286155, "grad_norm": 0.027925241738557816, "test_error": 0.0244}, {"epoch": 252, "train_loss": 0.07364381580654299, "grad_norm": 0.024733299389481544, "test_error": 0.0254}, {"epoch": 253, "train_loss": 0.07354408143220159, "grad_norm": 0.02671213261783123, "test_error": 0.0249}, {"epoch": 254, "train_loss": 0.07345075512582358, "grad_norm": 0.024488141760230064, "test_error": 0.0247}, {"epoch": 255, "train_loss": 0.0734300277957033, "grad_norm": 0.02213195525109768, "test_error": 0.0246}, {"epoch": 256, "train_loss": 0.07330480258174552, "grad_norm": 0.02512628212571144, "test_error": 0.0247}, {"epoch": 257, "train_loss": 0.07322041509248084, "grad_norm": 0.022617556154727936, "test_error": 0.0245}, {"epoch": 258, "train_loss": 0.07316404290664165, "grad_norm": 0.025156699120998383, "test_error": 0.0246}, {"epoch": 259, "train_loss": 0.07305326338116234, "grad_norm": 0.02638891153037548, "test_error": 0.0245}, {"epoch": 260, "train_loss": 0.07303648701314039, "grad_norm": 0.02250131219625473, "test_error": 0.0242}, {"epoch": 261, "train_loss": 0.0729470288225954, "grad_norm": 0.023723458871245384, "test_error": 0.0247}, {"epoch": 262, "train_loss": 0.07284574232749097, "grad_norm": 0.029109150171279907, "test_error": 0.0254}, {"epoch": 263, "train_loss": 0.07276999171596253, "grad_norm": 0.022959716618061066, "test_error": 0.0248}, {"epoch": 264, "train_loss": 0.07273482654298034, "grad_norm": 0.0324351042509079, "test_error": 0.025}, {"epoch": 265, "train_loss": 0.0727000821576609, "grad_norm": 0.024448256939649582, "test_error": 0.0247}, {"epoch": 266, "train_loss": 0.07260927534964867, "grad_norm": 0.02162899821996689, "test_error": 0.0238}, {"epoch": 267, "train_loss": 0.07248636938078562, "grad_norm": 0.05269310250878334, "test_error": 0.0247}, {"epoch": 268, "train_loss": 0.07247737263635888, "grad_norm": 0.03062303178012371, "test_error": 0.0241}, {"epoch": 269, "train_loss": 0.07239433177921456, "grad_norm": 0.023564329370856285, "test_error": 0.0243}, {"epoch": 270, "train_loss": 0.07234139380066577, "grad_norm": 0.040859051048755646, "test_error": 0.0241}, {"epoch": 271, "train_loss": 0.07227908972489726, "grad_norm": 0.01976308412849903, "test_error": 0.0245}, {"epoch": 272, "train_loss": 0.07216803670057562, "grad_norm": 0.0396154522895813, "test_error": 0.0239}, {"epoch": 273, "train_loss": 0.07208974588904918, "grad_norm": 0.029286714270710945, "test_error": 0.0246}, {"epoch": 274, "train_loss": 0.0720694877417991, "grad_norm": 0.01956273429095745, "test_error": 0.0247}, {"epoch": 275, "train_loss": 0.07203405309992376, "grad_norm": 0.02020328864455223, "test_error": 0.0241}, {"epoch": 276, "train_loss": 0.07195768024685094, "grad_norm": 0.02074838988482952, "test_error": 0.0244}, {"epoch": 277, "train_loss": 0.07190567734296201, "grad_norm": 0.030915221199393272, "test_error": 0.0248}, {"epoch": 278, "train_loss": 0.07181657717974546, "grad_norm": 0.023840446025133133, "test_error": 0.0244}, {"epoch": 279, "train_loss": 0.07175901279041622, "grad_norm": 0.028957106173038483, "test_error": 0.0242}, {"epoch": 280, "train_loss": 0.07171382532761587, "grad_norm": 0.02901522070169449, "test_error": 0.0239}]}